{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "transformer_model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ELytCnwVmIhf",
        "r-JKljRgmIhg",
        "G3PvGh5OmIhh",
        "0vzOPa-DmIhi",
        "OJlGFrLpmIhj",
        "jdtTnRsTmIhk",
        "l_DJtsaCmIhm",
        "zi-q_IdhmIhn",
        "dIFwaKFGmIho",
        "JZhcsU8YmIho"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srRg5w1VmjFg",
        "outputId": "0d193c79-a198-4bfc-b79e-6e1c60c77ea1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K6Nm0k3m4-1"
      },
      "source": [
        "!mkdir corpus\n",
        "!cp /content/drive/MyDrive/machine-translation-data/news-commentary-v12.ru-en.en ./corpus/\n",
        "!cp /content/drive/MyDrive/machine-translation-data/news-commentary-v12.ru-en.ru ./corpus/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7Sii5pYmIhY",
        "outputId": "376dec74-5597-489a-926f-0aef14c5968d"
      },
      "source": [
        "# !pip install torchtext --upgrade >> /dev/null 2>&1\n",
        "# !pip install spacy==2.1.8 >> /dev/null 2>&1\n",
        "# !python -m spacy download en >> /dev/null 2>&1\n",
        "# !pip install git+https://github.com/aatimofeev/spacy_russian_tokenizer.git >> /dev/null 2>&1\n",
        "# !pip install pymorphy2 >> /dev/null 2>&1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.8MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 6.7MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnEQ8PIAmIha"
      },
      "source": [
        "import tqdm\n",
        "import spacy\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Dataset, Example, Field\n",
        "from torchtext.data.iterator import BucketIterator\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torchtext.datasets import TranslationDataset\n",
        "\n",
        "from spacy.lang.ru import Russian\n",
        "from spacy_russian_tokenizer import RussianTokenizer, MERGE_PATTERNS"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp66_jw-mIhb",
        "outputId": "b6d0e1c5-57ed-495c-a9b6-94fe693b0b14"
      },
      "source": [
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "SEED = 546\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13tzudnfmIhc"
      },
      "source": [
        "en_tok = spacy.load(\"en\")\n",
        "\n",
        "def tokenize_en(sentence):\n",
        "    return [tok.text for tok in en_tok.tokenizer(sentence)]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz1SR0iMmIhc"
      },
      "source": [
        "ru_nlp = Russian()\n",
        "russian_tokenizer = RussianTokenizer(ru_nlp, MERGE_PATTERNS)\n",
        "ru_nlp.add_pipe(russian_tokenizer, name='russian_tokenizer')\n",
        "\n",
        "def tokenize_ru(sentence):\n",
        "    return [tok.text for tok in ru_nlp(sentence)]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfbaqnV-mIhd"
      },
      "source": [
        "EN_TEXT = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>', lower=True, batch_first=True)\n",
        "RU_TEXT = Field(tokenize=tokenize_ru, init_token='<sos>', eos_token='<eos>', lower=True, batch_first=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laFB1JaVmIhd",
        "outputId": "8072a4f0-a122-4daa-d11a-48212d9eb7d4"
      },
      "source": [
        "tokenize_ru(\"Привет, мир!\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Привет', ',', 'мир', '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uRWdEjVmIhe"
      },
      "source": [
        "dataset = TranslationDataset(\n",
        "    path='./corpus/news-commentary-v12.ru-en', exts=('.en', '.ru'),\n",
        "    fields=(EN_TEXT, RU_TEXT))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d35zzXyRmIhe"
      },
      "source": [
        "train_data, valid_data, test_data = dataset.split(split_ratio=[0.7, 0.2, 0.1])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u39bkRa2mIhe",
        "outputId": "ff12dd68-a481-4fc4-e213-6c3817e11c82"
      },
      "source": [
        "print(f'train set size: {len(train_data.examples):,}')\n",
        "print(f'valid set size: {len(valid_data.examples):,}')\n",
        "print(f'test set size: {len(test_data.examples):,}')\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set size: 154,598\n",
            "valid set size: 22,085\n",
            "test set size: 44,171\n",
            "{'src': ['this', 'is', 'why', 'jeffrey', 'sachs', '’s', 'millennium', 'villages', 'project', 'has', 'faltered', ',', 'as', 'the', 'journalist', 'nina', 'munk', '’s', 'recent', 'book', 'shows', '.'], 'trg': ['визуальная', 'политика', 'террора', 'может', 'казаться', 'примитивной', ',', 'но', 'ее', 'практика', 'может', 'быть', 'такой', 'же', 'сложной', 'и', 'существенной', ',', 'какими', 'являются', 'ее', 'последствия', '.', 'подобно', 'древним', 'завоевателям', ',', 'которые', 'сооружали', 'новые', 'храмы', 'на', 'местах', ',', 'где', 'стояли', 'храмы', 'побежденных', ',', 'разрушители', 'башен', '-', 'близнецов', 'в', 'нью-йорке', 'использовали', 'визуальный', 'террор', ',', 'чтобы', 'нанести', 'удар', 'в', 'самое', 'сердце', 'системы', 'ценностей', 'своего', 'противника', '.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELytCnwVmIhf"
      },
      "source": [
        "### Build vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GC-fOXSmIhf",
        "outputId": "33c0939b-5e3b-47bf-ee26-a6d61b58ec2a"
      },
      "source": [
        "%%time\n",
        "MIN_COUNT = 8\n",
        "EN_TEXT.build_vocab(train_data, min_freq=MIN_COUNT)\n",
        "RU_TEXT.build_vocab(train_data, min_freq=MIN_COUNT)\n",
        "print(f'Length of EN vocabulary: {len(EN_TEXT.vocab):,}')\n",
        "print(f'Length of RU vocabulary: {len(RU_TEXT.vocab):,}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of EN vocabulary: 18,138\n",
            "Length of RU vocabulary: 30,556\n",
            "CPU times: user 3.85 s, sys: 16 ms, total: 3.87 s\n",
            "Wall time: 3.87 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kOFPHsLmIhg"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-JKljRgmIhg"
      },
      "source": [
        "### Multi Head Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbLJQzOSmIhg"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, n_heads):\n",
        "        super(MultiHeadAttentionLayer, self).__init__()\n",
        "        assert d_model % n_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_size = d_model // n_heads\n",
        "        self.fc_q = nn.Linear(d_model, d_model)\n",
        "        self.fc_k = nn.Linear(d_model, d_model)\n",
        "        self.fc_v = nn.Linear(d_model, d_model)\n",
        "        self.fc_o = nn.Linear(d_model, d_model)\n",
        "        \n",
        "    def forward(self, query, key, value, mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, q_len, d_model] query\n",
        "        :param Tensor[batch_size, k_len, d_model] key\n",
        "        :param Tensor[batch_size, v_len, d_model] value\n",
        "        :param Tensor[batch_size, ..., k_len] mask\n",
        "        :return Tensor[batch_size, q_len, d_model] context\n",
        "        :return Tensor[batch_size, n_heads, q_len, k_len] attention_weights\n",
        "        \"\"\"\n",
        "        Q = self.fc_q(query) # [batch_size, q_len, d_model]\n",
        "        K = self.fc_k(key) # [batch_size, k_len, d_model]\n",
        "        V = self.fc_v(value) # [batch_size, v_len, d_model]\n",
        "\n",
        "        Q = Q.view(Q.size(0), -1, self.n_heads, self.head_size).permute(0, 2, 1, 3) # [batch_size, n_heads, q_len, head_size]\n",
        "        K = K.view(K.size(0), -1, self.n_heads, self.head_size).permute(0, 2, 1, 3) # [batch_size, n_heads, k_len, head_size]\n",
        "        V = V.view(V.size(0), -1, self.n_heads, self.head_size).permute(0, 2, 1, 3) # [batch_size, n_heads, v_len, head_size]\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) # [batch_size, n_heads, q_len, k_len]\n",
        "        scores = scores / torch.sqrt(torch.FloatTensor([self.head_size]).to(Q.device))\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e18)\n",
        "        attention_weights = F.softmax(scores , dim=-1) # [batch_size, n_heads, q_len, k_len]                \n",
        "        \n",
        "        context = torch.matmul(attention_weights, V) # [batch_size, n_heads, q_len, v_len]\n",
        "        context = context.permute(0, 2, 1, 3).contiguous() # [batch_size, q_len, n_heads, v_len]\n",
        "        context = context.view(context.size(0), -1, self.d_model)\n",
        "        context = self.fc_o(context) # [batch_size, q_len, d_model]\n",
        "\n",
        "        return context, attention_weights"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3PvGh5OmIhh"
      },
      "source": [
        "### Position-Wise Feed-Forward Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn4tkXL-mIhi"
      },
      "source": [
        "class PositionWiseFeedForwardLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, hidden_size):\n",
        "        super(PositionWiseFeedForwardLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.fc_in = nn.Linear(d_model, hidden_size)\n",
        "        self.fc_ou = nn.Linear(hidden_size, d_model)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, seq_len, d_model] inputs\n",
        "        :return Tensor[batch_size, seq_len, d_model] outputs\n",
        "        \"\"\"\n",
        "        outputs = F.relu(self.fc_in(inputs)) # [batch_size, seq_len, hidden_size]\n",
        "        return self.fc_ou(outputs) # [batch_size, seq_len, d_model]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vzOPa-DmIhi"
      },
      "source": [
        "### Positional Encoding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efrbyw8hmIhi"
      },
      "source": [
        "class PositionalEncodingLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, max_len=100):\n",
        "        super(PositionalEncodingLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def get_angles(self, positions, indexes):\n",
        "        d_model_tensor = torch.FloatTensor([[self.d_model]]).to(positions.device)\n",
        "        angle_rates = torch.pow(10000, (2 * (indexes.to(torch.float) // 2)) / d_model_tensor)\n",
        "        return positions.to(torch.float) / angle_rates\n",
        "\n",
        "    def forward(self, input_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, seq_len] input_sequences\n",
        "        :return Tensor[batch_size, seq_len, d_model] position_encoding\n",
        "        \"\"\"\n",
        "        positions = torch.arange(input_sequences.size(1)).unsqueeze(1).to(input_sequences.device) # [seq_len, 1]\n",
        "        indexes = torch.arange(self.d_model).unsqueeze(0).to(input_sequences.device) # [1, d_model]\n",
        "        angles = self.get_angles(positions, indexes) # [seq_len, d_model]\n",
        "        angles[:, 0::2] = torch.sin(angles[:, 0::2]) # apply sin to even indices in the tensor; 2i\n",
        "        angles[:, 1::2] = torch.cos(angles[:, 1::2]) # apply cos to odd indices in the tensor; 2i\n",
        "        position_encoding = angles.unsqueeze(0).repeat(input_sequences.size(0), 1, 1) # [batch_size, seq_len, d_model]\n",
        "        return position_encoding"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJlGFrLpmIhj"
      },
      "source": [
        "### Encoder Block Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWGGlGPNmIhj"
      },
      "source": [
        "class EncoderBlockLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, n_heads, hidden_size, dropout):\n",
        "        super(EncoderBlockLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.multi_head_attention_layer = MultiHeadAttentionLayer(d_model=d_model, n_heads=n_heads)\n",
        "        self.multi_head_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.position_wise_feed_forward_layer = PositionWiseFeedForwardLayer(d_model=d_model, hidden_size=hidden_size)\n",
        "        self.position_wise_feed_forward_layer_norm = nn.LayerNorm(d_model)\n",
        "    \n",
        "    def forward(self, src_inputs, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, src_len, d_model] src_inputs\n",
        "        :param Tensor[batch_size,  src_len] src_mask\n",
        "        :return Tensor[batch_size, src_len, d_model] outputs\n",
        "        \"\"\"\n",
        "        context, _ = self.multi_head_attention_layer(query=src_inputs, key=src_inputs, value=src_inputs, mask=src_mask)\n",
        "        context = self.multi_head_attention_layer_norm(self.dropout(context) + src_inputs)\n",
        "        \n",
        "        outputs = self.position_wise_feed_forward_layer(context)\n",
        "        outputs = self.position_wise_feed_forward_layer_norm(self.dropout(outputs) + context)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdtTnRsTmIhk"
      },
      "source": [
        "### Decoder Block Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYPAhQkNmIhl"
      },
      "source": [
        "class DecoderBlockLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, n_heads, hidden_size, dropout):\n",
        "        super(DecoderBlockLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.mask_multi_head_attention_layer = MultiHeadAttentionLayer(d_model=d_model, n_heads=n_heads)\n",
        "        self.mask_multi_head_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.multi_head_attention_layer = MultiHeadAttentionLayer(d_model=d_model, n_heads=n_heads)\n",
        "        self.multi_head_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.position_wise_feed_forward_layer = PositionWiseFeedForwardLayer(d_model=d_model, hidden_size=hidden_size)\n",
        "        self.position_wise_feed_forward_layer_norm = nn.LayerNorm(d_model)\n",
        "    \n",
        "    def forward(self, dest_inputs, src_encoded, dest_mask, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, dest_len, d_model] dest_inputs\n",
        "        :param Tensor[batch_size, src_len, d_model] src_encoded\n",
        "        :param Tensor[batch_size,  dest_len] dest_mask\n",
        "        :param Tensor[batch_size,  src_len] src_mask\n",
        "        :return Tensor[batch_size, dest_len, d_model] outputs\n",
        "        :return Tensor[batch_size, n_heads, dest_len, src_len] attention_weights\n",
        "        \"\"\"\n",
        "        masked_context, _ = self.mask_multi_head_attention_layer(query=dest_inputs, key=dest_inputs, value=dest_inputs, mask=dest_mask)\n",
        "        masked_context = self.mask_multi_head_attention_layer_norm(self.dropout(masked_context) + dest_inputs)\n",
        "        \n",
        "        context, attention_weights = self.multi_head_attention_layer(query=masked_context, key=src_encoded, value=src_encoded, mask=src_mask)\n",
        "        context = self.multi_head_attention_layer_norm(self.dropout(context) + masked_context)\n",
        "        \n",
        "        outputs = self.position_wise_feed_forward_layer(context)\n",
        "        outputs = self.position_wise_feed_forward_layer_norm(self.dropout(outputs) + context)\n",
        "        \n",
        "        return outputs, attention_weights"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_DJtsaCmIhm"
      },
      "source": [
        "### Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RdteY-umIhm"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, max_len, d_model, n_heads, hidden_size, dropout, n_layers):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.n_layers = n_layers\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.position_encoding = PositionalEncodingLayer(d_model=d_model, max_len=max_len)\n",
        "        self.encoder_block_layers = nn.ModuleList([EncoderBlockLayer(d_model=d_model, n_heads=n_heads, hidden_size=hidden_size,\n",
        "                                                                     dropout=dropout) for _ in range(n_layers)])\n",
        "    \n",
        "    def forward(self, src_sequences, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, src_len] src_sequences\n",
        "        :param Tensor[batch_size, src_len] src_mask\n",
        "        :return Tensor[batch_size, src_len, d_model] outputs\n",
        "        \"\"\"\n",
        "        token_embedded = self.token_embedding(src_sequences) # [batch_size, src_len, d_model]\n",
        "        position_encoded = self.position_encoding(src_sequences) # [batch_size, src_len, d_model]\n",
        "        outputs = self.dropout(token_embedded) + position_encoded # [batch_size, src_len, d_model]\n",
        "        for layer in self.encoder_block_layers:\n",
        "            outputs = layer(src_inputs=outputs, src_mask=src_mask) # [batch_size, src_len, d_model]\n",
        "        return outputs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi-q_IdhmIhn"
      },
      "source": [
        "### Decoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6w3D0ufmIhn"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, max_len, d_model, n_heads, hidden_size, dropout, n_layers):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.n_layers = n_layers\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.position_encoding = PositionalEncodingLayer(d_model=d_model, max_len=max_len)\n",
        "        self.decoder_block_layers = nn.ModuleList([DecoderBlockLayer(d_model=d_model, n_heads=n_heads, hidden_size=hidden_size, dropout=dropout) for _ in range(n_layers)])\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "    \n",
        "    def forward(self, dest_sequences, src_encoded, dest_mask, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, dest_len] dest_sequences\n",
        "        :param Tensor[batch_size, src_len, d_model] src_encoded\n",
        "        :param Tensor[batch_size, dest_len, d_model] dest_mask\n",
        "        :param Tensor[batch_size, src_len, d_model] src_mask\n",
        "        :return Tensor[batch_size, dest_len, vocab_size] logits\n",
        "        :return Tensor[batch_size, n_heads, dest_len, src_len] attention_weights\n",
        "        \"\"\"\n",
        "        token_embedded = self.token_embedding(dest_sequences) # [batch_size, dest_len, d_model]\n",
        "        position_encoded = self.position_encoding(dest_sequences) # [batch_size, dest_len, d_model]\n",
        "        outputs = self.dropout(token_embedded) + position_encoded # [batch_size, dest_len, d_model]\n",
        "        for layer in self.decoder_block_layers:\n",
        "            outputs, attention_weights = layer(dest_inputs=outputs, src_encoded=src_encoded, dest_mask=dest_mask, src_mask=src_mask)\n",
        "        logits = self.fc(outputs)\n",
        "        return logits, attention_weights"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIFwaKFGmIho"
      },
      "source": [
        "### Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hUIswgvmIho"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    \n",
        "    def __init__(self, encoder, decoder, src_pad_index, dest_pad_index):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_index = src_pad_index\n",
        "        self.dest_pad_index = dest_pad_index\n",
        "\n",
        "    def make_src_mask(self, src_sequences):\n",
        "        \"\"\"Mask <pad> tokens.\n",
        "        :param Tensor[batch_size, src_len] src_sequences\n",
        "        :return Tensor[batch size, 1, 1, src len] src_mask\n",
        "        \"\"\"        \n",
        "        src_mask = (src_sequences != self.src_pad_index).unsqueeze(1).unsqueeze(2)\n",
        "        return src_mask\n",
        "    \n",
        "    def make_dest_mask(self, dest_sequences):\n",
        "        \"\"\"Mask <pad> tokens and futur tokens as well.\n",
        "        :param Tensor[batch_size, dest_len] dest_sequences\n",
        "        :return tensor[batch_size, 1, dest_len, dest_len] dest_mask\n",
        "        \"\"\"\n",
        "        mask = (dest_sequences != self.dest_pad_index).unsqueeze(1).unsqueeze(2).to(torch.bool) # [batch size, 1, 1, trg len]\n",
        "        sub_mask = torch.tril(torch.ones((dest_sequences.size(1), dest_sequences.size(1))).to(dest_sequences.device)).to(torch.bool) # [trg len, trg len]        \n",
        "        return mask & sub_mask\n",
        "    \n",
        "    def forward(self, src_sequences, dest_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, src_len] src_sequences\n",
        "        :param Tensor[batch_size, dest_len] dest_sequences\n",
        "        :return Tensor[batch_size, dest_len, vocab_size] logits\n",
        "        :return Tensor[batch_size, n_heads, dest_len, src_len] attention_weights\n",
        "        \"\"\"\n",
        "        src_mask, dest_mask = self.make_src_mask(src_sequences), self.make_dest_mask(dest_sequences)\n",
        "        src_encoded = self.encoder(src_sequences=src_sequences, src_mask=src_mask)\n",
        "        logits, attention_weights = self.decoder(dest_sequences=dest_sequences, src_encoded=src_encoded, dest_mask=dest_mask, src_mask=src_mask)\n",
        "        return logits, attention_weights"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZhcsU8YmIho"
      },
      "source": [
        "### Training routines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u675PFn0mIho"
      },
      "source": [
        "class AverageMeter:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def reset(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def update(self, value, n=1):\n",
        "        self.value = value\n",
        "        self.sum += value * n\n",
        "        self.count += n\n",
        "        self.average = self.sum / self.count"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqR1OqZ3mIhp"
      },
      "source": [
        "def accuracy(outputs, target_sequences, k=5):\n",
        "    \"\"\" Calculate Top-k accuracy\n",
        "    :param Tensor[batch_size, dest_seq_len, vocab_size] outputs\n",
        "    :param Tensor[batch_size, dest_seq_len] target_sequences\n",
        "    :return float Top-k accuracy\n",
        "    \"\"\"\n",
        "    # print([*map(lambda token: EN.vocab.itos[token], outputs.argmax(dim=-1)[0].tolist())])\n",
        "    # print([*map(lambda token: EN.vocab.itos[token], target_sequences[0].tolist())])\n",
        "    # print(\"=\"*100)\n",
        "    batch_size = target_sequences.size(0)\n",
        "    _, indices = outputs.topk(k, dim=2, largest=True, sorted=True) # [batch_size, dest_seq_len, 5]\n",
        "    correct = indices.eq(target_sequences.unsqueeze(-1).expand_as(indices))\n",
        "    correct_total = correct.view(-1).float().sum()  # 0D tensor\n",
        "    return correct_total.item() * (100.0 / indices.numel())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esOC3Ki8mIhp"
      },
      "source": [
        "class Trainer:\n",
        "    \n",
        "    def __init__(self, model, optimizer, criterion):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "    \n",
        "    def train_step(self, loader, epoch, grad_clip):\n",
        "        loss_tracker, acc_tracker = AverageMeter(), AverageMeter()\n",
        "        self.model.train()\n",
        "        progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "        for i, batch in progress_bar:\n",
        "            src, trg = batch.src, batch.trg\n",
        "            self.optimizer.zero_grad()\n",
        "            logits, _ = self.model(src, trg[:, :-1]) # [batch_size, dest_len, vocab_size]\n",
        "            loss = self.criterion(logits.contiguous().view(-1, self.model.decoder.vocab_size), trg[:, 1:].contiguous().view(-1))\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), grad_clip)\n",
        "            self.optimizer.step()\n",
        "            loss_tracker.update(loss.item())\n",
        "            acc_tracker.update(accuracy(logits, trg[:, 1:]))\n",
        "            loss_, ppl_, acc_ = loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "            progress_bar.set_description(f'Epoch: {epoch+1:02d} -     loss: {loss_:.3f} -     ppl: {ppl_:.3f} -     acc: {acc_:.3f}%')\n",
        "        return loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "    \n",
        "    def validate(self, loader, epoch):\n",
        "        loss_tracker, acc_tracker = AverageMeter(), AverageMeter()\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "            for i, batch in progress_bar:\n",
        "                src, trg = batch.src, batch.trg\n",
        "                logits, _ = self.model(src, trg[:, :-1]) # [batch_size, dest_len, vocab_size]\n",
        "                loss = self.criterion(logits.contiguous().view(-1, self.model.decoder.vocab_size), trg[:, 1:].contiguous().view(-1))\n",
        "                loss_tracker.update(loss.item())\n",
        "                acc_tracker.update(accuracy(logits, trg[:, 1:]))\n",
        "                loss_, ppl_, acc_ = loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "                progress_bar.set_description(f'Epoch: {epoch+1:02d} - val_loss: {loss_:.3f} - val_ppl: {ppl_:.3f} - val_acc: {acc_:.3f}%')\n",
        "        return loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "    \n",
        "    def train(self, train_loader, valid_loader, n_epochs, grad_clip):\n",
        "        history, best_loss = {'acc': [], 'loss': [], 'ppl': [], 'val_ppl': [], 'val_acc': [], 'val_loss': []}, np.inf\n",
        "        for epoch in range(n_epochs):\n",
        "            loss, ppl, acc = self.train_step(train_loader, epoch, grad_clip)\n",
        "            val_loss, val_ppl, val_acc = self.validate(valid_loader, epoch)\n",
        "            if best_loss > val_loss:\n",
        "                best_loss = val_loss\n",
        "                torch.save(self.model.state_dict(), './models/transformer.pth')\n",
        "            history['acc'].append(acc); history['val_acc'].append(val_acc)\n",
        "            history['ppl'].append(ppl); history['val_ppl'].append(val_ppl)\n",
        "            history['loss'].append(loss); history['val_loss'].append(val_loss)\n",
        "        return history"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zLK2C_OmIhp"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuNSZZ-YmIhp"
      },
      "source": [
        "D_MODEL = 32\n",
        "N_LAYERS = 2\n",
        "N_HEADS = 8\n",
        "HIDDEN_SIZE = 64\n",
        "MAX_LEN = 50\n",
        "DROPOUT = 0.25\n",
        "BATCH_SIZE = 64\n",
        "LR = 1e-3\n",
        "N_EPOCHS = 10\n",
        "GRAD_CLIP = 1.0"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XimRFwZtmIhp",
        "outputId": "27746d6b-751d-425b-89ce-6118cbb3e3c4"
      },
      "source": [
        "transformer = Transformer(\n",
        "    encoder=EncoderLayer(\n",
        "        vocab_size=len(EN_TEXT.vocab),\n",
        "        max_len=MAX_LEN,\n",
        "        d_model=D_MODEL,\n",
        "        n_heads=N_HEADS,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        dropout=DROPOUT,\n",
        "        n_layers=N_LAYERS\n",
        "    ),\n",
        "    decoder=DecoderLayer(\n",
        "        vocab_size=len(RU_TEXT.vocab),\n",
        "        max_len=MAX_LEN,\n",
        "        d_model=D_MODEL,\n",
        "        n_heads=N_HEADS,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        dropout=DROPOUT,\n",
        "        n_layers=N_LAYERS\n",
        "    ),\n",
        "    src_pad_index=EN_TEXT.vocab.stoi[EN_TEXT.pad_token],\n",
        "    dest_pad_index=RU_TEXT.vocab.stoi[RU_TEXT.pad_token]\n",
        ").to(DEVICE)\n",
        "optimizer = optim.Adam(params=transformer.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=RU_TEXT.vocab.stoi[RU_TEXT.pad_token])\n",
        "print(f'Number of parameters of the model: {sum(p.numel() for p in transformer.parameters() if p.requires_grad):,}')\n",
        "print(transformer)\n",
        "trainer = Trainer(model=transformer, optimizer=optimizer, criterion=criterion)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters of the model: 2,609,308\n",
            "Transformer(\n",
            "  (encoder): EncoderLayer(\n",
            "    (dropout): Dropout(p=0.25, inplace=False)\n",
            "    (token_embedding): Embedding(18138, 32)\n",
            "    (position_encoding): PositionalEncodingLayer()\n",
            "    (encoder_block_layers): ModuleList(\n",
            "      (0): EncoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.25, inplace=False)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=32, out_features=64, bias=True)\n",
            "          (fc_ou): Linear(in_features=64, out_features=32, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): EncoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.25, inplace=False)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=32, out_features=64, bias=True)\n",
            "          (fc_ou): Linear(in_features=64, out_features=32, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): DecoderLayer(\n",
            "    (dropout): Dropout(p=0.25, inplace=False)\n",
            "    (token_embedding): Embedding(30556, 32)\n",
            "    (position_encoding): PositionalEncodingLayer()\n",
            "    (decoder_block_layers): ModuleList(\n",
            "      (0): DecoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.25, inplace=False)\n",
            "        (mask_multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (mask_multi_head_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=32, out_features=64, bias=True)\n",
            "          (fc_ou): Linear(in_features=64, out_features=32, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): DecoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.25, inplace=False)\n",
            "        (mask_multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (mask_multi_head_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
            "          (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=32, out_features=64, bias=True)\n",
            "          (fc_ou): Linear(in_features=64, out_features=32, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (fc): Linear(in_features=32, out_features=30556, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd8AOS1vmIhq",
        "outputId": "f76089f4-992d-45ec-c6ef-7e7b070f8d1b"
      },
      "source": [
        "train_iterator, valid_iterator, _ =  BucketIterator.splits((train_data, valid_data, test_data), batch_size=BATCH_SIZE, device=DEVICE)\n",
        "history = trainer.train(train_loader=train_iterator, valid_loader=valid_iterator, n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 -     loss: 6.718 -     ppl: 826.944 -     acc: 2.114%: 100%|██████████| 2416/2416 [02:25<00:00, 16.60it/s]\n",
            "Epoch: 01 - val_loss: 6.158 - val_ppl: 472.693 - val_acc: 6.044%: 100%|██████████| 346/346 [00:06<00:00, 52.87it/s]\n",
            "Epoch: 02 -     loss: 6.150 -     ppl: 468.672 -     acc: 2.399%: 100%|██████████| 2416/2416 [02:27<00:00, 16.43it/s]\n",
            "Epoch: 02 - val_loss: 5.858 - val_ppl: 349.954 - val_acc: 6.420%: 100%|██████████| 346/346 [00:06<00:00, 53.81it/s]\n",
            "Epoch: 03 -     loss: 5.918 -     ppl: 371.496 -     acc: 2.516%: 100%|██████████| 2416/2416 [02:26<00:00, 16.50it/s]\n",
            "Epoch: 03 - val_loss: 5.683 - val_ppl: 293.744 - val_acc: 6.643%: 100%|██████████| 346/346 [00:06<00:00, 54.56it/s]\n",
            "Epoch: 04 -     loss: 5.771 -     ppl: 320.899 -     acc: 2.576%: 100%|██████████| 2416/2416 [02:26<00:00, 16.52it/s]\n",
            "Epoch: 04 - val_loss: 5.572 - val_ppl: 262.831 - val_acc: 6.794%: 100%|██████████| 346/346 [00:06<00:00, 54.36it/s]\n",
            "Epoch: 05 -     loss: 5.666 -     ppl: 288.800 -     acc: 2.632%: 100%|██████████| 2416/2416 [02:27<00:00, 16.37it/s]\n",
            "Epoch: 05 - val_loss: 5.491 - val_ppl: 242.512 - val_acc: 6.900%: 100%|██████████| 346/346 [00:06<00:00, 53.18it/s]\n",
            "Epoch: 06 -     loss: 5.585 -     ppl: 266.526 -     acc: 2.663%: 100%|██████████| 2416/2416 [02:26<00:00, 16.44it/s]\n",
            "Epoch: 06 - val_loss: 5.424 - val_ppl: 226.826 - val_acc: 6.989%: 100%|██████████| 346/346 [00:06<00:00, 52.51it/s]\n",
            "Epoch: 07 -     loss: 5.522 -     ppl: 250.251 -     acc: 2.702%: 100%|██████████| 2416/2416 [02:25<00:00, 16.55it/s]\n",
            "Epoch: 07 - val_loss: 5.384 - val_ppl: 217.938 - val_acc: 7.035%: 100%|██████████| 346/346 [00:06<00:00, 54.09it/s]\n",
            "Epoch: 08 -     loss: 5.471 -     ppl: 237.581 -     acc: 2.728%: 100%|██████████| 2416/2416 [02:26<00:00, 16.52it/s]\n",
            "Epoch: 08 - val_loss: 5.342 - val_ppl: 208.868 - val_acc: 7.099%: 100%|██████████| 346/346 [00:06<00:00, 53.41it/s]\n",
            "Epoch: 09 -     loss: 5.427 -     ppl: 227.473 -     acc: 2.741%: 100%|██████████| 2416/2416 [02:26<00:00, 16.52it/s]\n",
            "Epoch: 09 - val_loss: 5.306 - val_ppl: 201.466 - val_acc: 7.145%: 100%|██████████| 346/346 [00:06<00:00, 52.84it/s]\n",
            "Epoch: 10 -     loss: 5.390 -     ppl: 219.261 -     acc: 2.769%: 100%|██████████| 2416/2416 [02:25<00:00, 16.56it/s]\n",
            "Epoch: 10 - val_loss: 5.276 - val_ppl: 195.576 - val_acc: 7.194%: 100%|██████████| 346/346 [00:06<00:00, 53.50it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4ybctUVAYK8",
        "outputId": "96c805d6-17f1-4b81-e491-54876f369402"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Feb 21 16:16:49 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    40W / 300W |  10181MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "gFcY3q9dmIhr",
        "outputId": "05d75d82-93ea-4a7b-c831-4590e9668b88"
      },
      "source": [
        "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].plot(history['loss'], label='train')\n",
        "axes[0].plot(history['val_loss'], label='valid')\n",
        "axes[0].set_title('Loss history')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].grid(True)\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(history['ppl'], label='train')\n",
        "axes[1].plot(history['val_ppl'], label='valid')\n",
        "axes[1].set_title('Perplexity history')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Perplexity')\n",
        "axes[1].grid(True)\n",
        "axes[1].legend()\n",
        "\n",
        "axes[2].plot(history['acc'], label='train')\n",
        "axes[2].plot(history['val_acc'], label='valid')\n",
        "axes[2].set_title('Top-5 Accuracy & BLEU-4 history')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('Accuracy & BLEU-4 (%)')\n",
        "axes[2].grid(True)\n",
        "axes[2].legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_pcK8xOmIhr",
        "outputId": "f8c46920-6b92-4d9c-e6d3-fdeb8ebbb5bf"
      },
      "source": [
        "transformer.load_state_dict(torch.load('./models/transformer.pth'))\n",
        "transformer.to(DEVICE)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): EncoderLayer(\n",
              "    (dropout): Dropout(p=0.25, inplace=False)\n",
              "    (token_embedding): Embedding(18138, 32)\n",
              "    (position_encoding): PositionalEncodingLayer()\n",
              "    (encoder_block_layers): ModuleList(\n",
              "      (0): EncoderBlockLayer(\n",
              "        (dropout): Dropout(p=0.25, inplace=False)\n",
              "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (multi_head_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
              "          (fc_in): Linear(in_features=32, out_features=64, bias=True)\n",
              "          (fc_ou): Linear(in_features=64, out_features=32, bias=True)\n",
              "        )\n",
              "        (position_wise_feed_forward_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (1): EncoderBlockLayer(\n",
              "        (dropout): Dropout(p=0.25, inplace=False)\n",
              "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (multi_head_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
              "          (fc_in): Linear(in_features=32, out_features=64, bias=True)\n",
              "          (fc_ou): Linear(in_features=64, out_features=32, bias=True)\n",
              "        )\n",
              "        (position_wise_feed_forward_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): DecoderLayer(\n",
              "    (dropout): Dropout(p=0.25, inplace=False)\n",
              "    (token_embedding): Embedding(30556, 32)\n",
              "    (position_encoding): PositionalEncodingLayer()\n",
              "    (decoder_block_layers): ModuleList(\n",
              "      (0): DecoderBlockLayer(\n",
              "        (dropout): Dropout(p=0.25, inplace=False)\n",
              "        (mask_multi_head_attention_layer): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (mask_multi_head_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (multi_head_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
              "          (fc_in): Linear(in_features=32, out_features=64, bias=True)\n",
              "          (fc_ou): Linear(in_features=64, out_features=32, bias=True)\n",
              "        )\n",
              "        (position_wise_feed_forward_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (1): DecoderBlockLayer(\n",
              "        (dropout): Dropout(p=0.25, inplace=False)\n",
              "        (mask_multi_head_attention_layer): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (mask_multi_head_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_k): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_v): Linear(in_features=32, out_features=32, bias=True)\n",
              "          (fc_o): Linear(in_features=32, out_features=32, bias=True)\n",
              "        )\n",
              "        (multi_head_attention_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
              "          (fc_in): Linear(in_features=32, out_features=64, bias=True)\n",
              "          (fc_ou): Linear(in_features=64, out_features=32, bias=True)\n",
              "        )\n",
              "        (position_wise_feed_forward_layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (fc): Linear(in_features=32, out_features=30556, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8LxG1gYiwJX"
      },
      "source": [
        "def find_path(tree):\n",
        "    path = []\n",
        "    for nodes in reversed(tree):\n",
        "        if len(path) == 0:\n",
        "            path.append(nodes[0])\n",
        "        else:\n",
        "            parent_id = path[-1].parent_id\n",
        "            for node in nodes:\n",
        "                if node.id == parent_id:\n",
        "                    path.append(node)\n",
        "    return path\n",
        "\n",
        "def find_best_path(tree):\n",
        "    best = []\n",
        "    for nodes in reversed(tree):\n",
        "        if len(best) == 0:\n",
        "            best.append(nodes[0])\n",
        "        else:\n",
        "            nodes_eos = []\n",
        "            parent_id = best[-1].parent_id\n",
        "            for node in nodes:\n",
        "                if node.eos:\n",
        "                    nodes_eos.append(node)\n",
        "                if node.id == parent_id:\n",
        "                    best.append(node)\n",
        "            if len(nodes_eos) > 0:\n",
        "                candidates = sorted([best[-1], *nodes_eos],\n",
        "                                    key=lambda node: node.logps,\n",
        "                                    reverse=True)\n",
        "                candidate = candidates[0]\n",
        "                if candidate.eos:\n",
        "                    best = [candidate]\n",
        "    return best\n",
        "\n",
        "class Node:\n",
        "    id = 0\n",
        "    \n",
        "    def __init__(self, token, states, logp=0., parent=None, eos=False):\n",
        "        self.id = self.__class__.id_\n",
        "        self.token = token\n",
        "        self.states = states\n",
        "        self.logp = logp\n",
        "        self.parent_id = None if parent is None else parent.id\n",
        "        self.eos = eos\n",
        "        self.level = 0 if parent is None else parent.level + 1\n",
        "        self.logps = logp if parent is None else parent.logps + logp\n",
        "        self.__class__.id_ += 1\n",
        "        \n",
        "    def __str__(self):\n",
        "        return f'Node[id={self.__id}, ' + \\\n",
        "                    f'index={EN.vocab.itos[self.__token.cpu().item()]}, ' + \\\n",
        "                    f'logp={self.__logp}, ' + \\\n",
        "                    f'logps={self.__logps}, ' + \\\n",
        "                    f'parent_id={self.__parent_id}, ' + \\\n",
        "                    f'level={self.__level}]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScoI5AN1mIhr"
      },
      "source": [
        "def evaluate(model, data, beam_size, src_field, dest_field, max_len, device):\n",
        "    src_sentences = [*map(lambda example: example.src, data.examples)]\n",
        "    dest_sentences = [*map(lambda example: example.trg, data.examples)]\n",
        "    data = [*zip([*map(lambda word_list: src_field.process([word_list]), src_sentences)],\n",
        "                 [*map(lambda word_list: dest_field.process([word_list]), dest_sentences)])]\n",
        "    references, hypotheses, sources = [], [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (src_sequence, dest_sequence) in tqdm.tqdm(enumerate(data[:1000]), total=1000, position=0, leave=True):\n",
        "            src_sequence, dest_sequence = src_sequence.to(device), dest_sequence.to(device)\n",
        "            src_mask = model.make_src_mask(src_sequence)\n",
        "            src_encoded = model.encoder(src_sequences=src_sequence, src_mask=src_mask)\n",
        "            # Decoding\n",
        "            tree = [[Node(token=torch.LongTensor([dest_field.vocab.stoi[dest_field.init_token]]).to(device), states=None)]]\n",
        "            for _ in range(max_len):\n",
        "                next_nodes = []\n",
        "                for node in tree[-1]:\n",
        "                    if node.eos: # Skip eos token\n",
        "                        continue\n",
        "                    # Get tokens that're already translated\n",
        "                    already_translated = torch.LongTensor([*map(lambda node: node.token, find_path(tree))][::-1]).unsqueeze(0).to(device)\n",
        "                    dest_mask = model.make_dest_mask(already_translated)\n",
        "                    logit, _ = model.decoder(dest_sequences=already_translated, src_encoded=src_encoded,\n",
        "                                              dest_mask=dest_mask, src_mask=src_mask) # [1, dest_seq_len, vocab_size]                    \n",
        "                    logp = F.log_softmax(logit[:, -1, :], dim=1).squeeze(dim=0) # [vocab_size] Get scores                    \n",
        "                    topk_logps, topk_tokens = torch.topk(logp, beam_size) # Get top k tokens & logps                    \n",
        "                    for k in range(beam_size):\n",
        "                        next_nodes.append(Node(token=topk_tokens[k, None], states=None,\n",
        "                                               logp=topk_logps[k, None].cpu().item(), parent=node,\n",
        "                                               eos=topk_tokens[k].cpu().item() == dest_field.vocab[dest_field.eos_token]))\n",
        "                if len(next_nodes) == 0:\n",
        "                    break\n",
        "                next_nodes = sorted(next_nodes, key=lambda node: node.logps, reverse=True) # Sort next_nodes to get the best\n",
        "                tree.append(next_nodes[:beam_size]) # Update the tree\n",
        "            best_path = find_best_path(tree) # Find the best path of the tree\n",
        "\n",
        "            # Get the translation\n",
        "            pred_translated = [*map(lambda node: dest_field.vocab.itos[node.token], best_path)]\n",
        "            pred_translated = [*filter(lambda word: word not in [dest_field.init_token, dest_field.eos_token], pred_translated[::-1])]\n",
        "\n",
        "            hypotheses.append(pred_translated) # Update hypotheses\n",
        "\n",
        "            # Update references\n",
        "            references.append([[dest_field.vocab.itos[indice] for indice in dest_sequence[0] if indice not in (\n",
        "                dest_field.vocab.stoi[dest_field.init_token],\n",
        "                dest_field.vocab.stoi[dest_field.eos_token],\n",
        "                dest_field.vocab.stoi[dest_field.pad_token]\n",
        "            )]])\n",
        "\n",
        "            # Update sources\n",
        "            sources.append([src_field.vocab.itos[indice]  for indice in src_sequence[0] if indice not in (\n",
        "                src_field.vocab.stoi[src_field.init_token],\n",
        "                src_field.vocab.stoi[src_field.eos_token],\n",
        "                src_field.vocab.stoi[src_field.pad_token]\n",
        "            )])\n",
        "    \n",
        "        assert len(hypotheses) == len(references) == len(sources)\n",
        "        bleu4 = bleu_score(hypotheses, references, max_n=4, weights=[0.25, 0.25, 0.25, 0.25]) # Calculate BLEU-4 score\n",
        "    return hypotheses, references, sources, bleu4"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z4YL6aemIhr",
        "outputId": "b624bb6f-3215-4352-acaf-15978bccb0e8"
      },
      "source": [
        "bleu_scores = []\n",
        "for beam_size in [1, 3]:\n",
        "    for name, data in [('validation', valid_data), ('test', test_data)]:\n",
        "        _, _, _, bleu4 = evaluate(model=transformer, data=data, beam_size=beam_size, src_field=EN_TEXT, dest_field=RU_TEXT, max_len=MAX_LEN, device=DEVICE)\n",
        "        bleu_scores.append((beam_size, name, bleu4))\n",
        "        \n",
        "for score in bleu_scores:\n",
        "    print(f'BLEU-4: {score[2]*100:.3f}% with beam_size={score[0]} on {score[1]} data')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [02:41<00:00,  6.19it/s]\n",
            "100%|██████████| 1000/1000 [02:42<00:00,  6.16it/s]\n",
            "100%|██████████| 1000/1000 [07:48<00:00,  2.13it/s]\n",
            "100%|██████████| 1000/1000 [07:47<00:00,  2.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU-4: 1.276% with beam_size=1 on validation data\n",
            "BLEU-4: 1.258% with beam_size=1 on test data\n",
            "BLEU-4: 1.276% with beam_size=3 on validation data\n",
            "BLEU-4: 1.258% with beam_size=3 on test data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH6X3gMImIhs"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TzuCX4wmIhs"
      },
      "source": [
        "def translate(sentences, model, beam_size, src_field, dest_field, max_len, device):\n",
        "    if isinstance(sentences, list):\n",
        "        sentences = [*map(src_field.preprocess, sentences)]\n",
        "        targets = None\n",
        "    if isinstance(sentences, Dataset):\n",
        "        targets = [*map(lambda example: ' '.join(example.trg), sentences.examples)]\n",
        "        sentences = [*map(lambda example: example.src, sentences.examples)]\n",
        "    data = [*map(lambda word_list: src_field.process([word_list]), sentences)]\n",
        "    translated_sentences, attention_weights, pred_logps = [], [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, src_sequence in tqdm.tqdm(enumerate(data[:1000]), total=1000, position=0, leave=True):\n",
        "            src_sequence = src_sequence.to(device)\n",
        "            src_mask = model.make_src_mask(src_sequence)\n",
        "            src_encoded = model.encoder(src_sequences=src_sequence, src_mask=src_mask)\n",
        "            tree = [[Node(token=torch.LongTensor([dest_field.vocab.stoi[dest_field.init_token]]).to(device), states=())]]\n",
        "            for _ in range(max_len):\n",
        "                next_nodes = []\n",
        "                for node in tree[-1]:\n",
        "                    if node.eos: # Skip eos token\n",
        "                        continue\n",
        "                    # Get tokens that're already translated\n",
        "                    already_translated = torch.LongTensor([*map(lambda node: node.token, find_path(tree))][::-1]).unsqueeze(0).to(device)\n",
        "                    dest_mask = model.make_dest_mask(already_translated)\n",
        "                    logit, attn_weights = model.decoder(dest_sequences=already_translated, src_encoded=src_encoded,\n",
        "                                              dest_mask=dest_mask, src_mask=src_mask) # [1, dest_seq_len, vocab_size]                      \n",
        "                    logp = F.log_softmax(logit[:, -1, :], dim=1).squeeze(dim=0) # [vocab_size] Get scores                    \n",
        "                    topk_logps, topk_tokens = torch.topk(logp, beam_size) # Get top k tokens & logps                    \n",
        "                    for k in range(beam_size):\n",
        "                        next_nodes.append(Node(token=topk_tokens[k, None], states=(attn_weights,),\n",
        "                                               logp=topk_logps[k, None].cpu().item(), parent=node,\n",
        "                                               eos=topk_tokens[k].cpu().item() == dest_field.vocab[dest_field.eos_token]))\n",
        "                if len(next_nodes) == 0:\n",
        "                    break\n",
        "                next_nodes = sorted(next_nodes, key=lambda node: node.logps, reverse=True)\n",
        "                tree.append(next_nodes[:beam_size])\n",
        "            best_path = find_best_path(tree)[::-1]\n",
        "            # Get the translation\n",
        "            pred_translated = [*map(lambda node: dest_field.vocab.itos[node.token], best_path)]\n",
        "            pred_translated = [*filter(lambda word: word not in [\n",
        "                dest_field.init_token, dest_field.eos_token\n",
        "            ], pred_translated)]\n",
        "            translated_sentences.append(' '.join(pred_translated))\n",
        "            # Get probabilities\n",
        "            pred_logps.append(sum([*map(lambda node: node.logps, best_path)]))\n",
        "            # Get attention weights\n",
        "            attention_weights.append(best_path[-1].states[0].cpu().numpy())\n",
        "        sentences = [*map(lambda sentence: ' '.join(sentence), sentences)]\n",
        "    return sentences, translated_sentences, targets, attention_weights, pred_logps"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FPeU0s4mIhs",
        "outputId": "b3f06334-ae93-403b-ed19-bc14e7f04ead"
      },
      "source": [
        "sentences, translated_sentences, dest_sentences, attention_weights, pred_logps = translate(sentences=test_data, model=transformer, beam_size=1, src_field=EN_TEXT,\n",
        "                                                                                           dest_field=RU_TEXT, max_len=MAX_LEN, device=DEVICE)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [02:32<00:00,  6.55it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_keF2reemIhs",
        "outputId": "a9b2e112-30bd-4aee-eddc-54c2c0e162d2"
      },
      "source": [
        "indexes = np.random.choice(1000, size=10, replace=False)\n",
        "\n",
        "for i in indexes:\n",
        "    text = f'Source: {sentences[i]}\\n'\n",
        "    text += f'Ground truth translation: {dest_sentences[i]}\\n'\n",
        "    text += f'Predicted translation: {translated_sentences[i]}\\n'\n",
        "    print(text)\n",
        "    print()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source: to overcome the challenges we face and fulfill our promise to our children , we need active support from the international community .\n",
            "Ground truth translation: для нетаньяху , подстрекательство является мощным политическим инструментом .\n",
            "Predicted translation: в то время как <unk> <unk> , <unk> <unk> <unk> , <unk> , <unk> , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
            "\n",
            "\n",
            "Source: it was gilani who sat next to singh to watch the game ; but , ultimately , process , rather than protocol , will determine how bilateral relations move forward .\n",
            "Ground truth translation: именно гилани сел рядом с сингхом , чтобы посмотреть матч . но , в конечном счете , процесс , а не протокол , определит дальнейшее направление развития двухсторонних отношений .\n",
            "Predicted translation: в то время как <unk> <unk> , <unk> <unk> <unk> , <unk> , <unk> , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
            "\n",
            "\n",
            "Source: russia ’s relations with the eu are governed by an agreement signed in june 1994 concerning trade , business and investment , competition issues , protection of intellectual , industrial , and business property , and financial cooperation .\n",
            "Ground truth translation: важность решения индонезии ратифицировать договор о всеобъемлющем запрещении ядерных испытаний ( двзяи ) не может быть переоценена .\n",
            "Predicted translation: в то время как <unk> , <unk> <unk> <unk> , <unk> <unk> , <unk> , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
            "\n",
            "\n",
            "Source: the dreams from his father were at an end , and he was left , as he only slowly realized , with the themeless pragmatism that has become the hallmark of his administration .\n",
            "Ground truth translation: американские антидемпинговые пошлины на чилийскую лососину способны разорить фирмы , занимающиеся ее производством , в то время как чили не сможет предпринять никаких действий против сша , которые могли бы причинить серьезный урон американским компаниям .\n",
            "Predicted translation: в то время как <unk> <unk> <unk> , <unk> <unk> <unk> , <unk> , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
            "\n",
            "\n",
            "Source: as it is , the valuation of a country ’s currency is not so much determined by the performance of its economy as by the forces of supply and demand on foreign - exchange markets . for a given supply of money , an increase in the production of goods will increase the value of a currency , because each unit will buy more goods .\n",
            "Ground truth translation: тем временем , администрация обамы продолжает осуществлять свои планы по европейской про .\n",
            "Predicted translation: в то время как <unk> <unk> <unk> , <unk> <unk> <unk> , <unk> , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
            "\n",
            "\n",
            "Source: the us kept cuba under its thumb , and , in accordance with us investor interests , the export economy remained little more than sugar and tobacco plantations throughout the first half of the twentieth century .\n",
            "Ground truth translation: два фундаментальных соображения приходят на ум , и их последствия для стран латинской америки , & quot;готовых к захвату за сферы влияния&quot ; , например , сальвадор , являются особенно важными .\n",
            "Predicted translation: в то время как <unk> <unk> , <unk> <unk> <unk> , <unk> , <unk> , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
            "\n",
            "\n",
            "Source: campaigners for carbon - emission reductions regularly highlight the melting snow and ice of mount kilimanjaro .\n",
            "Ground truth translation: вопреки общепринятому мнению глобализация не гомогенизирует и не американизирует мировые культуры .\n",
            "Predicted translation: в то время как <unk> <unk> , <unk> <unk> <unk> , <unk> , <unk> , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
            "\n",
            "\n",
            "Source: northern europe ’s political elites , largely social or christian democrats , have often been dismissive of such fears , and their paternalism and condescension may be why the backlash in those liberal countries has been particularly fierce .\n",
            "Ground truth translation: настаивание на включении против желания большинства граждан европы , будет иметь привкус чего-то вроде своего рода недемократического патернализма , который уже отвернул многих европейцев от евросоюза .\n",
            "Predicted translation: в то время как <unk> <unk> , <unk> <unk> <unk> , <unk> , <unk> , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
            "\n",
            "\n",
            "Source: the way out of this dilemma is to understand what iran wants – and how to accommodate it without jeopardizing anyone ’s security .\n",
            "Ground truth translation: выход из данной ситуации заключается в том , чтобы понять , чего хочет иран - и как этого можно добиться , не ставя под угрозу чью-либо безопасность .\n",
            "Predicted translation: в то время как <unk> <unk> , <unk> <unk> <unk> , <unk> , <unk> , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
            "\n",
            "\n",
            "Source: for example , he overruled iranian nuclear negotiators who offered a compromise during the geneva negotiations in october 2009 .\n",
            "Ground truth translation: отношение молодых избирателей к карруби также не совсем положительное .\n",
            "Predicted translation: в то время как <unk> <unk> <unk> , <unk> <unk> <unk> , <unk> , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5b7pSIYoUpU"
      },
      "source": [
        "## P.S: \n",
        "The model is still being developed and improved. Seems like we need to fix some bugs or improve the model because it doesn't translate well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIZzuAaHmIhs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ABd7VsYmIht"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wLHAM4cmIht"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}