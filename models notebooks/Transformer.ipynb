{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPXZOYPTnsK3",
        "outputId": "3c04063c-954c-4f94-c569-7eb223d5481f"
      },
      "source": [
        "import os\n",
        "path_to_data = '../../datasets/Machine_translation_EN_RU/data.txt'\n",
        "if not os.path.exists(path_to_data):\n",
        "    print(\"Dataset not found locally. Downloading from github.\")\n",
        "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset not found locally. Downloading from github.\n",
            "--2021-03-07 12:37:51--  https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12905334 (12M) [text/plain]\n",
            "Saving to: ‘data.txt’\n",
            "\n",
            "data.txt            100%[===================>]  12.31M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-03-07 12:37:51 (165 MB/s) - ‘data.txt’ saved [12905334/12905334]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubJhFf5Uqrfg"
      },
      "source": [
        "# !pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnEQ8PIAmIha"
      },
      "source": [
        "import tqdm\n",
        "import spacy\n",
        "import warnings\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.data import Dataset, Example, Field, TabularDataset\n",
        "from torchtext.data.iterator import BucketIterator\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torchtext.datasets import TranslationDataset\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp66_jw-mIhb",
        "outputId": "a1f03b3f-432f-44f7-eaca-100e0c2022f6"
      },
      "source": [
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "SEED = 2021\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s55gGqFoWbh"
      },
      "source": [
        "tokenizer_W = WordPunctTokenizer()\n",
        "def tokenize(x, tokenizer=tokenizer_W):\n",
        "    return tokenizer.tokenize(x.lower())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfbaqnV-mIhd"
      },
      "source": [
        "EN_TEXT = Field(tokenize=tokenize, init_token='<sos>', eos_token='<eos>', lower=True, batch_first=True)\n",
        "RU_TEXT = Field(tokenize=tokenize, init_token='<sos>', eos_token='<eos>', lower=True, batch_first=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5WxQZIYn4KL"
      },
      "source": [
        "path_to_data = './data.txt'\n",
        "dataset = TabularDataset(\n",
        "    path=path_to_data,\n",
        "    format='tsv',\n",
        "    fields=[('src', EN_TEXT), ('trg', RU_TEXT)]\n",
        ")\n",
        "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05], random_state=random.seed(SEED))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u39bkRa2mIhe",
        "outputId": "6a672bfb-ed5e-490c-c7c0-19f7c0d8e98d"
      },
      "source": [
        "print(f'train set size: {len(train_data.examples):,}')\n",
        "print(f'valid set size: {len(valid_data.examples):,}')\n",
        "print(f'test set size: {len(test_data.examples):,}')\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set size: 40,000\n",
            "valid set size: 2,500\n",
            "test set size: 7,500\n",
            "{'src': ['other', 'facilities', 'offered', 'at', 'the', 'property', 'include', 'a', 'games', 'room', ',', 'a', 'beach', 'volley', 'court', 'and', 'a', 'children', \"'\", 's', 'playground', '.'], 'trg': ['в', 'числе', 'других', 'удобств', 'здесь', 'комната', 'для', 'игр', ',', 'площадка', 'для', 'пляжного', 'волейбола', 'и', 'детская', 'игровая', 'площадка', '.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79ned97r0M7M",
        "outputId": "5dee1351-8cc9-4814-df35-6eca51ca56a1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Mar  7 12:38:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELytCnwVmIhf"
      },
      "source": [
        "### Build vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GC-fOXSmIhf",
        "outputId": "daba6efd-d033-4e4d-d3d3-9f2b429bef76"
      },
      "source": [
        "%%time\n",
        "MIN_COUNT = 2\n",
        "EN_TEXT.build_vocab(train_data, min_freq=MIN_COUNT)\n",
        "RU_TEXT.build_vocab(train_data, min_freq=MIN_COUNT)\n",
        "print(f'Length of EN vocabulary: {len(EN_TEXT.vocab):,}')\n",
        "print(f'Length of RU vocabulary: {len(RU_TEXT.vocab):,}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of EN vocabulary: 10,199\n",
            "Length of RU vocabulary: 14,147\n",
            "CPU times: user 511 ms, sys: 29.4 ms, total: 540 ms\n",
            "Wall time: 541 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kOFPHsLmIhg"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-JKljRgmIhg"
      },
      "source": [
        "### Multi Head Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbLJQzOSmIhg"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, n_heads):\n",
        "        super(MultiHeadAttentionLayer, self).__init__()\n",
        "        assert d_model % n_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_size = d_model // n_heads\n",
        "        self.fc_q = nn.Linear(d_model, d_model)\n",
        "        self.fc_k = nn.Linear(d_model, d_model)\n",
        "        self.fc_v = nn.Linear(d_model, d_model)\n",
        "        self.fc_o = nn.Linear(d_model, d_model)\n",
        "        \n",
        "    def forward(self, query, key, value, mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, q_len, d_model] query\n",
        "        :param Tensor[batch_size, k_len, d_model] key\n",
        "        :param Tensor[batch_size, v_len, d_model] value\n",
        "        :param Tensor[batch_size, ..., k_len] mask\n",
        "        :return Tensor[batch_size, q_len, d_model] context\n",
        "        :return Tensor[batch_size, n_heads, q_len, k_len] attention_weights\n",
        "        \"\"\"\n",
        "        Q = self.fc_q(query) # [batch_size, q_len, d_model]\n",
        "        K = self.fc_k(key) # [batch_size, k_len, d_model]\n",
        "        V = self.fc_v(value) # [batch_size, v_len, d_model]\n",
        "\n",
        "        Q = Q.view(Q.size(0), -1, self.n_heads, self.head_size).permute(0, 2, 1, 3) # [batch_size, n_heads, q_len, head_size]\n",
        "        K = K.view(K.size(0), -1, self.n_heads, self.head_size).permute(0, 2, 1, 3) # [batch_size, n_heads, k_len, head_size]\n",
        "        V = V.view(V.size(0), -1, self.n_heads, self.head_size).permute(0, 2, 1, 3) # [batch_size, n_heads, v_len, head_size]\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) # [batch_size, n_heads, q_len, k_len]\n",
        "        scores = scores / torch.sqrt(torch.FloatTensor([self.head_size]).to(Q.device))\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e18)\n",
        "        attention_weights = F.softmax(scores , dim=-1) # [batch_size, n_heads, q_len, k_len]                \n",
        "        \n",
        "        context = torch.matmul(attention_weights, V) # [batch_size, n_heads, q_len, v_len]\n",
        "        context = context.permute(0, 2, 1, 3).contiguous() # [batch_size, q_len, n_heads, v_len]\n",
        "        context = context.view(context.size(0), -1, self.d_model)\n",
        "        context = self.fc_o(context) # [batch_size, q_len, d_model]\n",
        "\n",
        "        return context, attention_weights"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3PvGh5OmIhh"
      },
      "source": [
        "### Position-Wise Feed-Forward Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn4tkXL-mIhi"
      },
      "source": [
        "class PositionWiseFeedForwardLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, hidden_size):\n",
        "        super(PositionWiseFeedForwardLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.fc_in = nn.Linear(d_model, hidden_size)\n",
        "        self.fc_ou = nn.Linear(hidden_size, d_model)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, seq_len, d_model] inputs\n",
        "        :return Tensor[batch_size, seq_len, d_model] outputs\n",
        "        \"\"\"\n",
        "        outputs = F.relu(self.fc_in(inputs)) # [batch_size, seq_len, hidden_size]\n",
        "        return self.fc_ou(outputs) # [batch_size, seq_len, d_model]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vzOPa-DmIhi"
      },
      "source": [
        "### Positional Encoding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efrbyw8hmIhi"
      },
      "source": [
        "class PositionalEncodingLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, max_len=100):\n",
        "        super(PositionalEncodingLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def get_angles(self, positions, indexes):\n",
        "        d_model_tensor = torch.FloatTensor([[self.d_model]]).to(positions.device)\n",
        "        angle_rates = torch.pow(10000, (2 * (indexes // 2)) / d_model_tensor)\n",
        "        return positions / angle_rates\n",
        "\n",
        "    def forward(self, input_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, seq_len] input_sequences\n",
        "        :return Tensor[batch_size, seq_len, d_model] position_encoding\n",
        "        \"\"\"\n",
        "        positions = torch.arange(input_sequences.size(1)).unsqueeze(1).to(input_sequences.device) # [seq_len, 1]\n",
        "        indexes = torch.arange(self.d_model).unsqueeze(0).to(input_sequences.device) # [1, d_model]\n",
        "        angles = self.get_angles(positions, indexes) # [seq_len, d_model]\n",
        "        angles[:, 0::2] = torch.sin(angles[:, 0::2]) # apply sin to even indices in the tensor; 2i\n",
        "        angles[:, 1::2] = torch.cos(angles[:, 1::2]) # apply cos to odd indices in the tensor; 2i\n",
        "        position_encoding = angles.unsqueeze(0).repeat(input_sequences.size(0), 1, 1) # [batch_size, seq_len, d_model]\n",
        "        return position_encoding"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJlGFrLpmIhj"
      },
      "source": [
        "### Encoder Block Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWGGlGPNmIhj"
      },
      "source": [
        "class EncoderBlockLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, n_heads, hidden_size, dropout):\n",
        "        super(EncoderBlockLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.multi_head_attention_layer = MultiHeadAttentionLayer(d_model=d_model, n_heads=n_heads)\n",
        "        self.multi_head_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.position_wise_feed_forward_layer = PositionWiseFeedForwardLayer(d_model=d_model, hidden_size=hidden_size)\n",
        "        self.position_wise_feed_forward_layer_norm = nn.LayerNorm(d_model)\n",
        "    \n",
        "    def forward(self, src_inputs, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, src_len, d_model] src_inputs\n",
        "        :param Tensor[batch_size,  src_len] src_mask\n",
        "        :return Tensor[batch_size, src_len, d_model] outputs\n",
        "        \"\"\"\n",
        "        context, _ = self.multi_head_attention_layer(query=src_inputs, key=src_inputs, value=src_inputs, mask=src_mask)\n",
        "        context = self.multi_head_attention_layer_norm(self.dropout(context) + src_inputs)\n",
        "        \n",
        "        outputs = self.position_wise_feed_forward_layer(context)\n",
        "        outputs = self.position_wise_feed_forward_layer_norm(self.dropout(outputs) + context)\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdtTnRsTmIhk"
      },
      "source": [
        "### Decoder Block Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYPAhQkNmIhl"
      },
      "source": [
        "class DecoderBlockLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, n_heads, hidden_size, dropout):\n",
        "        super(DecoderBlockLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.mask_multi_head_attention_layer = MultiHeadAttentionLayer(d_model=d_model, n_heads=n_heads)\n",
        "        self.mask_multi_head_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.multi_head_attention_layer = MultiHeadAttentionLayer(d_model=d_model, n_heads=n_heads)\n",
        "        self.multi_head_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.position_wise_feed_forward_layer = PositionWiseFeedForwardLayer(d_model=d_model, hidden_size=hidden_size)\n",
        "        self.position_wise_feed_forward_layer_norm = nn.LayerNorm(d_model)\n",
        "    \n",
        "    def forward(self, dest_inputs, src_encoded, dest_mask, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, dest_len, d_model] dest_inputs\n",
        "        :param Tensor[batch_size, src_len, d_model] src_encoded\n",
        "        :param Tensor[batch_size,  dest_len] dest_mask\n",
        "        :param Tensor[batch_size,  src_len] src_mask\n",
        "        :return Tensor[batch_size, dest_len, d_model] outputs\n",
        "        :return Tensor[batch_size, n_heads, dest_len, src_len] attention_weights\n",
        "        \"\"\"\n",
        "        masked_context, _ = self.mask_multi_head_attention_layer(query=dest_inputs, key=dest_inputs, value=dest_inputs, mask=dest_mask)\n",
        "        masked_context = self.mask_multi_head_attention_layer_norm(self.dropout(masked_context) + dest_inputs)\n",
        "        \n",
        "        context, attention_weights = self.multi_head_attention_layer(query=masked_context, key=src_encoded, value=src_encoded, mask=src_mask)\n",
        "        context = self.multi_head_attention_layer_norm(self.dropout(context) + masked_context)\n",
        "        \n",
        "        outputs = self.position_wise_feed_forward_layer(context)\n",
        "        outputs = self.position_wise_feed_forward_layer_norm(self.dropout(outputs) + context)\n",
        "        \n",
        "        return outputs, attention_weights"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_DJtsaCmIhm"
      },
      "source": [
        "### Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RdteY-umIhm"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, max_len, d_model, n_heads, hidden_size, dropout, n_layers):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.n_layers = n_layers\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.position_encoding = PositionalEncodingLayer(d_model=d_model, max_len=max_len)\n",
        "        self.encoder_block_layers = nn.ModuleList([EncoderBlockLayer(d_model=d_model, n_heads=n_heads, hidden_size=hidden_size,\n",
        "                                                                     dropout=dropout) for _ in range(n_layers)])\n",
        "    \n",
        "    def forward(self, src_sequences, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, src_len] src_sequences\n",
        "        :param Tensor[batch_size, src_len] src_mask\n",
        "        :return Tensor[batch_size, src_len, d_model] outputs\n",
        "        \"\"\"\n",
        "        token_embedded = self.token_embedding(src_sequences) # [batch_size, src_len, d_model]\n",
        "        position_encoded = self.position_encoding(src_sequences) # [batch_size, src_len, d_model]\n",
        "        outputs = self.dropout(token_embedded) + position_encoded # [batch_size, src_len, d_model]\n",
        "        for layer in self.encoder_block_layers:\n",
        "            outputs = layer(src_inputs=outputs, src_mask=src_mask) # [batch_size, src_len, d_model]\n",
        "        return outputs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi-q_IdhmIhn"
      },
      "source": [
        "### Decoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6w3D0ufmIhn"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, max_len, d_model, n_heads, hidden_size, dropout, n_layers):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.n_layers = n_layers\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.position_encoding = PositionalEncodingLayer(d_model=d_model, max_len=max_len)\n",
        "        self.decoder_block_layers = nn.ModuleList([DecoderBlockLayer(d_model=d_model, n_heads=n_heads, hidden_size=hidden_size, dropout=dropout) for _ in range(n_layers)])\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "    \n",
        "    def forward(self, dest_sequences, src_encoded, dest_mask, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, dest_len] dest_sequences\n",
        "        :param Tensor[batch_size, src_len, d_model] src_encoded\n",
        "        :param Tensor[batch_size, dest_len, d_model] dest_mask\n",
        "        :param Tensor[batch_size, src_len, d_model] src_mask\n",
        "        :return Tensor[batch_size, dest_len, vocab_size] logits\n",
        "        :return Tensor[batch_size, n_heads, dest_len, src_len] attention_weights\n",
        "        \"\"\"\n",
        "        token_embedded = self.token_embedding(dest_sequences) # [batch_size, dest_len, d_model]\n",
        "        position_encoded = self.position_encoding(dest_sequences) # [batch_size, dest_len, d_model]\n",
        "        outputs = self.dropout(token_embedded) + position_encoded # [batch_size, dest_len, d_model]\n",
        "        for layer in self.decoder_block_layers:\n",
        "            outputs, attention_weights = layer(dest_inputs=outputs, src_encoded=src_encoded, dest_mask=dest_mask, src_mask=src_mask)\n",
        "        logits = self.fc(outputs)\n",
        "        return logits, attention_weights"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIFwaKFGmIho"
      },
      "source": [
        "### Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hUIswgvmIho"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    \n",
        "    def __init__(self, encoder, decoder, src_pad_index, dest_pad_index):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_index = src_pad_index\n",
        "        self.dest_pad_index = dest_pad_index\n",
        "\n",
        "    def make_src_mask(self, src_sequences):\n",
        "        \"\"\"Mask <pad> tokens.\n",
        "        :param Tensor[batch_size, src_len] src_sequences\n",
        "        :return Tensor[batch size, 1, 1, src len] src_mask\n",
        "        \"\"\"        \n",
        "        src_mask = (src_sequences != self.src_pad_index).unsqueeze(1).unsqueeze(2)\n",
        "        return src_mask\n",
        "    \n",
        "    def make_dest_mask(self, dest_sequences):\n",
        "        \"\"\"Mask <pad> tokens and futur tokens as well.\n",
        "        :param Tensor[batch_size, dest_len] dest_sequences\n",
        "        :return tensor[batch_size, 1, dest_len, dest_len] dest_mask\n",
        "        \"\"\"\n",
        "        mask = (dest_sequences != self.dest_pad_index).unsqueeze(1).unsqueeze(2) # [batch size, 1, 1, trg len]\n",
        "        sub_mask = torch.tril(torch.ones((dest_sequences.size(1), dest_sequences.size(1))).to(dest_sequences.device)).bool() # [trg len, trg len]        \n",
        "        return mask & sub_mask\n",
        "    \n",
        "    def forward(self, src_sequences, dest_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, src_len] src_sequences\n",
        "        :param Tensor[batch_size, dest_len] dest_sequences\n",
        "        :return Tensor[batch_size, dest_len, vocab_size] logits\n",
        "        :return Tensor[batch_size, n_heads, dest_len, src_len] attention_weights\n",
        "        \"\"\"\n",
        "        src_mask, dest_mask = self.make_src_mask(src_sequences), self.make_dest_mask(dest_sequences)\n",
        "        src_encoded = self.encoder(src_sequences=src_sequences, src_mask=src_mask)\n",
        "        logits, attention_weights = self.decoder(dest_sequences=dest_sequences, src_encoded=src_encoded, dest_mask=dest_mask, src_mask=src_mask)\n",
        "        return logits, attention_weights"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZhcsU8YmIho"
      },
      "source": [
        "### Training routines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u675PFn0mIho"
      },
      "source": [
        "class AverageMeter:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def reset(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def update(self, value, n=1):\n",
        "        self.value = value\n",
        "        self.sum += value * n\n",
        "        self.count += n\n",
        "        self.average = self.sum / self.count"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqR1OqZ3mIhp"
      },
      "source": [
        "def accuracy(outputs, target_sequences, k=5):\n",
        "    \"\"\" Calculate Top-k accuracy\n",
        "    :param Tensor[batch_size, dest_seq_len, vocab_size] outputs\n",
        "    :param Tensor[batch_size, dest_seq_len] target_sequences\n",
        "    :return float Top-k accuracy\n",
        "    \"\"\"\n",
        "    # print([*map(lambda token: EN.vocab.itos[token], outputs.argmax(dim=-1)[0].tolist())])\n",
        "    # print([*map(lambda token: EN.vocab.itos[token], target_sequences[0].tolist())])\n",
        "    # print(\"=\"*100)\n",
        "    batch_size = target_sequences.size(0)\n",
        "    _, indices = outputs.topk(k, dim=2, largest=True, sorted=True) # [batch_size, dest_seq_len, 5]\n",
        "    correct = indices.eq(target_sequences.unsqueeze(-1).expand_as(indices))\n",
        "    correct_total = correct.view(-1).float().sum()  # 0D tensor\n",
        "    return correct_total.item() * (100.0 / indices.numel())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esOC3Ki8mIhp"
      },
      "source": [
        "class Trainer:\n",
        "    \n",
        "    def __init__(self, model, optimizer, criterion):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "    \n",
        "    def train_step(self, loader, epoch, grad_clip):\n",
        "        loss_tracker, acc_tracker = AverageMeter(), AverageMeter()\n",
        "        self.model.train()\n",
        "        progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "        for i, batch in progress_bar:\n",
        "            src, trg = batch.src, batch.trg\n",
        "            self.optimizer.zero_grad()\n",
        "            logits, _ = self.model(src, trg[:, :-1]) # [batch_size, dest_len, vocab_size]\n",
        "            loss = self.criterion(logits.contiguous().view(-1, self.model.decoder.vocab_size), trg[:, 1:].contiguous().view(-1))\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), grad_clip)\n",
        "            self.optimizer.step()\n",
        "            loss_tracker.update(loss.item())\n",
        "            acc_tracker.update(accuracy(logits, trg[:, 1:]))\n",
        "            loss_, ppl_, acc_ = loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "            progress_bar.set_description(f'Epoch: {epoch+1:02d} -     loss: {loss_:.3f} -     ppl: {ppl_:.3f} -     acc: {acc_:.3f}%')\n",
        "        return loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "    \n",
        "    def validate(self, loader, epoch):\n",
        "        loss_tracker, acc_tracker = AverageMeter(), AverageMeter()\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "            for i, batch in progress_bar:\n",
        "                src, trg = batch.src, batch.trg\n",
        "                logits, _ = self.model(src, trg[:, :-1]) # [batch_size, dest_len, vocab_size]\n",
        "                loss = self.criterion(logits.contiguous().view(-1, self.model.decoder.vocab_size), trg[:, 1:].contiguous().view(-1))\n",
        "                loss_tracker.update(loss.item())\n",
        "                acc_tracker.update(accuracy(logits, trg[:, 1:]))\n",
        "                loss_, ppl_, acc_ = loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "                progress_bar.set_description(f'Epoch: {epoch+1:02d} - val_loss: {loss_:.3f} - val_ppl: {ppl_:.3f} - val_acc: {acc_:.3f}%')\n",
        "        return loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "    \n",
        "    def train(self, train_loader, valid_loader, n_epochs, grad_clip):\n",
        "        history, best_loss = {'acc': [], 'loss': [], 'ppl': [], 'val_ppl': [], 'val_acc': [], 'val_loss': []}, np.inf\n",
        "        for epoch in range(n_epochs):\n",
        "            loss, ppl, acc = self.train_step(train_loader, epoch, grad_clip)\n",
        "            val_loss, val_ppl, val_acc = self.validate(valid_loader, epoch)\n",
        "            if best_loss > val_loss:\n",
        "                best_loss = val_loss\n",
        "                torch.save(self.model.state_dict(), './models/transformer.pth')\n",
        "            history['acc'].append(acc); history['val_acc'].append(val_acc)\n",
        "            history['ppl'].append(ppl); history['val_ppl'].append(val_ppl)\n",
        "            history['loss'].append(loss); history['val_loss'].append(val_loss)\n",
        "        return history"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zLK2C_OmIhp"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuNSZZ-YmIhp"
      },
      "source": [
        "D_MODEL = 256\n",
        "N_LAYERS = 2\n",
        "N_HEADS = 8\n",
        "HIDDEN_SIZE = 512\n",
        "MAX_LEN = 50\n",
        "DROPOUT = 0.25\n",
        "BATCH_SIZE = 64\n",
        "LR = 1e-3\n",
        "N_EPOCHS = 50\n",
        "GRAD_CLIP = 1.0"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XimRFwZtmIhp",
        "outputId": "b5d5f63b-8d59-4d97-d843-b82787f8b6ff"
      },
      "source": [
        "transformer = Transformer(\n",
        "    encoder=EncoderLayer(\n",
        "        vocab_size=len(EN_TEXT.vocab),\n",
        "        max_len=MAX_LEN,\n",
        "        d_model=D_MODEL,\n",
        "        n_heads=N_HEADS,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        dropout=DROPOUT,\n",
        "        n_layers=N_LAYERS\n",
        "    ),\n",
        "    decoder=DecoderLayer(\n",
        "        vocab_size=len(RU_TEXT.vocab),\n",
        "        max_len=MAX_LEN,\n",
        "        d_model=D_MODEL,\n",
        "        n_heads=N_HEADS,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        dropout=DROPOUT,\n",
        "        n_layers=N_LAYERS\n",
        "    ),\n",
        "    src_pad_index=EN_TEXT.vocab.stoi[EN_TEXT.pad_token],\n",
        "    dest_pad_index=RU_TEXT.vocab.stoi[RU_TEXT.pad_token]\n",
        ").to(DEVICE)\n",
        "optimizer = optim.Adam(params=transformer.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=RU_TEXT.vocab.stoi[RU_TEXT.pad_token])\n",
        "print(f'Number of parameters of the model: {sum(p.numel() for p in transformer.parameters() if p.requires_grad):,}')\n",
        "print(transformer)\n",
        "trainer = Trainer(model=transformer, optimizer=optimizer, criterion=criterion)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters of the model: 12,504,131\n",
            "Transformer(\n",
            "  (encoder): EncoderLayer(\n",
            "    (dropout): Dropout(p=0.25, inplace=False)\n",
            "    (token_embedding): Embedding(10199, 256)\n",
            "    (position_encoding): PositionalEncodingLayer()\n",
            "    (encoder_block_layers): ModuleList(\n",
            "      (0): EncoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.25, inplace=False)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=512, bias=True)\n",
            "          (fc_ou): Linear(in_features=512, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): EncoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.25, inplace=False)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=512, bias=True)\n",
            "          (fc_ou): Linear(in_features=512, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): DecoderLayer(\n",
            "    (dropout): Dropout(p=0.25, inplace=False)\n",
            "    (token_embedding): Embedding(14147, 256)\n",
            "    (position_encoding): PositionalEncodingLayer()\n",
            "    (decoder_block_layers): ModuleList(\n",
            "      (0): DecoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.25, inplace=False)\n",
            "        (mask_multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (mask_multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=512, bias=True)\n",
            "          (fc_ou): Linear(in_features=512, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): DecoderBlockLayer(\n",
            "        (dropout): Dropout(p=0.25, inplace=False)\n",
            "        (mask_multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (mask_multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (multi_head_attention_layer): MultiHeadAttentionLayer(\n",
            "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (multi_head_attention_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (position_wise_feed_forward_layer): PositionWiseFeedForwardLayer(\n",
            "          (fc_in): Linear(in_features=256, out_features=512, bias=True)\n",
            "          (fc_ou): Linear(in_features=512, out_features=256, bias=True)\n",
            "        )\n",
            "        (position_wise_feed_forward_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (fc): Linear(in_features=256, out_features=14147, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGbbnHE4jZjc"
      },
      "source": [
        "!mkdir -p models"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd8AOS1vmIhq",
        "outputId": "c4b9e7c8-c0c1-4e5c-c779-204e8f410bc5"
      },
      "source": [
        "train_iterator, valid_iterator, _ =  BucketIterator.splits((train_data, valid_data, test_data), batch_size=BATCH_SIZE, device=DEVICE, sort=False)\n",
        "history = trainer.train(train_loader=train_iterator, valid_loader=valid_iterator, n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 -     loss: 3.394 -     ppl: 29.777 -     acc: 5.319%: 100%|██████████| 625/625 [00:41<00:00, 15.22it/s]\n",
            "Epoch: 01 - val_loss: 2.332 - val_ppl: 10.299 - val_acc: 6.328%: 100%|██████████| 40/40 [00:01<00:00, 38.10it/s]\n",
            "Epoch: 02 -     loss: 2.310 -     ppl: 10.072 -     acc: 6.281%: 100%|██████████| 625/625 [00:42<00:00, 14.63it/s]\n",
            "Epoch: 02 - val_loss: 2.012 - val_ppl: 7.478 - val_acc: 6.666%: 100%|██████████| 40/40 [00:01<00:00, 36.68it/s]\n",
            "Epoch: 03 -     loss: 1.955 -     ppl: 7.064 -     acc: 6.572%: 100%|██████████| 625/625 [00:44<00:00, 14.12it/s]\n",
            "Epoch: 03 - val_loss: 1.850 - val_ppl: 6.359 - val_acc: 6.839%: 100%|██████████| 40/40 [00:01<00:00, 36.65it/s]\n",
            "Epoch: 04 -     loss: 1.723 -     ppl: 5.601 -     acc: 6.789%: 100%|██████████| 625/625 [00:43<00:00, 14.23it/s]\n",
            "Epoch: 04 - val_loss: 1.785 - val_ppl: 5.961 - val_acc: 6.911%: 100%|██████████| 40/40 [00:01<00:00, 36.71it/s]\n",
            "Epoch: 05 -     loss: 1.554 -     ppl: 4.728 -     acc: 6.952%: 100%|██████████| 625/625 [00:44<00:00, 14.16it/s]\n",
            "Epoch: 05 - val_loss: 1.747 - val_ppl: 5.740 - val_acc: 6.984%: 100%|██████████| 40/40 [00:01<00:00, 36.97it/s]\n",
            "Epoch: 06 -     loss: 1.423 -     ppl: 4.149 -     acc: 7.137%: 100%|██████████| 625/625 [00:43<00:00, 14.32it/s]\n",
            "Epoch: 06 - val_loss: 1.702 - val_ppl: 5.487 - val_acc: 7.027%: 100%|██████████| 40/40 [00:01<00:00, 36.06it/s]\n",
            "Epoch: 07 -     loss: 1.323 -     ppl: 3.753 -     acc: 7.258%: 100%|██████████| 625/625 [00:43<00:00, 14.27it/s]\n",
            "Epoch: 07 - val_loss: 1.670 - val_ppl: 5.313 - val_acc: 7.067%: 100%|██████████| 40/40 [00:01<00:00, 36.76it/s]\n",
            "Epoch: 08 -     loss: 1.243 -     ppl: 3.464 -     acc: 7.327%: 100%|██████████| 625/625 [00:43<00:00, 14.21it/s]\n",
            "Epoch: 08 - val_loss: 1.656 - val_ppl: 5.236 - val_acc: 7.091%: 100%|██████████| 40/40 [00:01<00:00, 36.28it/s]\n",
            "Epoch: 09 -     loss: 1.178 -     ppl: 3.249 -     acc: 7.375%: 100%|██████████| 625/625 [00:44<00:00, 14.14it/s]\n",
            "Epoch: 09 - val_loss: 1.645 - val_ppl: 5.183 - val_acc: 7.121%: 100%|██████████| 40/40 [00:01<00:00, 36.72it/s]\n",
            "Epoch: 10 -     loss: 1.128 -     ppl: 3.091 -     acc: 7.444%: 100%|██████████| 625/625 [00:43<00:00, 14.26it/s]\n",
            "Epoch: 10 - val_loss: 1.640 - val_ppl: 5.156 - val_acc: 7.152%: 100%|██████████| 40/40 [00:01<00:00, 36.76it/s]\n",
            "Epoch: 11 -     loss: 1.086 -     ppl: 2.963 -     acc: 7.530%: 100%|██████████| 625/625 [00:43<00:00, 14.34it/s]\n",
            "Epoch: 11 - val_loss: 1.635 - val_ppl: 5.128 - val_acc: 7.155%: 100%|██████████| 40/40 [00:01<00:00, 36.56it/s]\n",
            "Epoch: 12 -     loss: 1.051 -     ppl: 2.861 -     acc: 7.504%: 100%|██████████| 625/625 [00:43<00:00, 14.31it/s]\n",
            "Epoch: 12 - val_loss: 1.625 - val_ppl: 5.079 - val_acc: 7.183%: 100%|██████████| 40/40 [00:01<00:00, 36.36it/s]\n",
            "Epoch: 13 -     loss: 1.016 -     ppl: 2.763 -     acc: 7.573%: 100%|██████████| 625/625 [00:43<00:00, 14.28it/s]\n",
            "Epoch: 13 - val_loss: 1.622 - val_ppl: 5.064 - val_acc: 7.201%: 100%|██████████| 40/40 [00:01<00:00, 36.92it/s]\n",
            "Epoch: 14 -     loss: 0.987 -     ppl: 2.683 -     acc: 7.604%: 100%|██████████| 625/625 [00:43<00:00, 14.22it/s]\n",
            "Epoch: 14 - val_loss: 1.616 - val_ppl: 5.033 - val_acc: 7.215%: 100%|██████████| 40/40 [00:01<00:00, 36.60it/s]\n",
            "Epoch: 15 -     loss: 0.963 -     ppl: 2.618 -     acc: 7.684%: 100%|██████████| 625/625 [00:43<00:00, 14.29it/s]\n",
            "Epoch: 15 - val_loss: 1.609 - val_ppl: 4.996 - val_acc: 7.217%: 100%|██████████| 40/40 [00:01<00:00, 36.49it/s]\n",
            "Epoch: 16 -     loss: 0.936 -     ppl: 2.551 -     acc: 7.651%: 100%|██████████| 625/625 [00:43<00:00, 14.26it/s]\n",
            "Epoch: 16 - val_loss: 1.624 - val_ppl: 5.074 - val_acc: 7.207%: 100%|██████████| 40/40 [00:01<00:00, 36.63it/s]\n",
            "Epoch: 17 -     loss: 0.915 -     ppl: 2.498 -     acc: 7.675%: 100%|██████████| 625/625 [00:43<00:00, 14.28it/s]\n",
            "Epoch: 17 - val_loss: 1.619 - val_ppl: 5.047 - val_acc: 7.223%: 100%|██████████| 40/40 [00:01<00:00, 36.76it/s]\n",
            "Epoch: 18 -     loss: 0.894 -     ppl: 2.445 -     acc: 7.738%: 100%|██████████| 625/625 [00:43<00:00, 14.30it/s]\n",
            "Epoch: 18 - val_loss: 1.636 - val_ppl: 5.136 - val_acc: 7.206%: 100%|██████████| 40/40 [00:01<00:00, 36.42it/s]\n",
            "Epoch: 19 -     loss: 0.877 -     ppl: 2.404 -     acc: 7.731%: 100%|██████████| 625/625 [00:43<00:00, 14.26it/s]\n",
            "Epoch: 19 - val_loss: 1.623 - val_ppl: 5.069 - val_acc: 7.247%: 100%|██████████| 40/40 [00:01<00:00, 36.25it/s]\n",
            "Epoch: 20 -     loss: 0.858 -     ppl: 2.359 -     acc: 7.735%: 100%|██████████| 625/625 [00:43<00:00, 14.27it/s]\n",
            "Epoch: 20 - val_loss: 1.629 - val_ppl: 5.097 - val_acc: 7.227%: 100%|██████████| 40/40 [00:01<00:00, 36.22it/s]\n",
            "Epoch: 21 -     loss: 0.840 -     ppl: 2.317 -     acc: 7.767%: 100%|██████████| 625/625 [00:43<00:00, 14.24it/s]\n",
            "Epoch: 21 - val_loss: 1.628 - val_ppl: 5.092 - val_acc: 7.240%: 100%|██████████| 40/40 [00:01<00:00, 36.95it/s]\n",
            "Epoch: 22 -     loss: 0.827 -     ppl: 2.286 -     acc: 7.807%: 100%|██████████| 625/625 [00:43<00:00, 14.37it/s]\n",
            "Epoch: 22 - val_loss: 1.627 - val_ppl: 5.090 - val_acc: 7.271%: 100%|██████████| 40/40 [00:01<00:00, 36.51it/s]\n",
            "Epoch: 23 -     loss: 0.812 -     ppl: 2.253 -     acc: 7.822%: 100%|██████████| 625/625 [00:43<00:00, 14.40it/s]\n",
            "Epoch: 23 - val_loss: 1.634 - val_ppl: 5.123 - val_acc: 7.269%: 100%|██████████| 40/40 [00:01<00:00, 36.88it/s]\n",
            "Epoch: 24 -     loss: 0.799 -     ppl: 2.223 -     acc: 7.791%: 100%|██████████| 625/625 [00:43<00:00, 14.34it/s]\n",
            "Epoch: 24 - val_loss: 1.642 - val_ppl: 5.163 - val_acc: 7.239%: 100%|██████████| 40/40 [00:01<00:00, 36.73it/s]\n",
            "Epoch: 25 -     loss: 0.785 -     ppl: 2.192 -     acc: 7.792%: 100%|██████████| 625/625 [00:43<00:00, 14.33it/s]\n",
            "Epoch: 25 - val_loss: 1.640 - val_ppl: 5.154 - val_acc: 7.256%: 100%|██████████| 40/40 [00:01<00:00, 36.49it/s]\n",
            "Epoch: 26 -     loss: 0.774 -     ppl: 2.168 -     acc: 7.776%: 100%|██████████| 625/625 [00:43<00:00, 14.29it/s]\n",
            "Epoch: 26 - val_loss: 1.637 - val_ppl: 5.138 - val_acc: 7.266%: 100%|██████████| 40/40 [00:01<00:00, 36.29it/s]\n",
            "Epoch: 27 -     loss: 0.759 -     ppl: 2.137 -     acc: 7.798%: 100%|██████████| 625/625 [00:43<00:00, 14.27it/s]\n",
            "Epoch: 27 - val_loss: 1.643 - val_ppl: 5.173 - val_acc: 7.243%: 100%|██████████| 40/40 [00:01<00:00, 36.25it/s]\n",
            "Epoch: 28 -     loss: 0.748 -     ppl: 2.113 -     acc: 7.855%: 100%|██████████| 625/625 [00:43<00:00, 14.38it/s]\n",
            "Epoch: 28 - val_loss: 1.651 - val_ppl: 5.210 - val_acc: 7.258%: 100%|██████████| 40/40 [00:01<00:00, 35.66it/s]\n",
            "Epoch: 29 -     loss: 0.736 -     ppl: 2.088 -     acc: 7.821%: 100%|██████████| 625/625 [00:43<00:00, 14.22it/s]\n",
            "Epoch: 29 - val_loss: 1.659 - val_ppl: 5.254 - val_acc: 7.249%: 100%|██████████| 40/40 [00:01<00:00, 37.12it/s]\n",
            "Epoch: 30 -     loss: 0.726 -     ppl: 2.067 -     acc: 7.887%: 100%|██████████| 625/625 [00:43<00:00, 14.43it/s]\n",
            "Epoch: 30 - val_loss: 1.654 - val_ppl: 5.230 - val_acc: 7.274%: 100%|██████████| 40/40 [00:01<00:00, 36.94it/s]\n",
            "Epoch: 31 -     loss: 0.718 -     ppl: 2.050 -     acc: 7.905%: 100%|██████████| 625/625 [00:43<00:00, 14.48it/s]\n",
            "Epoch: 31 - val_loss: 1.664 - val_ppl: 5.279 - val_acc: 7.253%: 100%|██████████| 40/40 [00:01<00:00, 36.46it/s]\n",
            "Epoch: 32 -     loss: 0.708 -     ppl: 2.030 -     acc: 7.851%: 100%|██████████| 625/625 [00:43<00:00, 14.33it/s]\n",
            "Epoch: 32 - val_loss: 1.660 - val_ppl: 5.257 - val_acc: 7.249%: 100%|██████████| 40/40 [00:01<00:00, 36.83it/s]\n",
            "Epoch: 33 -     loss: 0.700 -     ppl: 2.014 -     acc: 7.898%: 100%|██████████| 625/625 [00:43<00:00, 14.37it/s]\n",
            "Epoch: 33 - val_loss: 1.673 - val_ppl: 5.328 - val_acc: 7.261%: 100%|██████████| 40/40 [00:01<00:00, 35.12it/s]\n",
            "Epoch: 34 -     loss: 0.690 -     ppl: 1.994 -     acc: 7.915%: 100%|██████████| 625/625 [00:43<00:00, 14.40it/s]\n",
            "Epoch: 34 - val_loss: 1.677 - val_ppl: 5.349 - val_acc: 7.265%: 100%|██████████| 40/40 [00:01<00:00, 36.94it/s]\n",
            "Epoch: 35 -     loss: 0.682 -     ppl: 1.978 -     acc: 7.912%: 100%|██████████| 625/625 [00:43<00:00, 14.28it/s]\n",
            "Epoch: 35 - val_loss: 1.678 - val_ppl: 5.355 - val_acc: 7.262%: 100%|██████████| 40/40 [00:01<00:00, 35.70it/s]\n",
            "Epoch: 36 -     loss: 0.673 -     ppl: 1.961 -     acc: 7.903%: 100%|██████████| 625/625 [00:43<00:00, 14.35it/s]\n",
            "Epoch: 36 - val_loss: 1.685 - val_ppl: 5.395 - val_acc: 7.260%: 100%|██████████| 40/40 [00:01<00:00, 36.72it/s]\n",
            "Epoch: 37 -     loss: 0.664 -     ppl: 1.942 -     acc: 7.930%: 100%|██████████| 625/625 [00:43<00:00, 14.41it/s]\n",
            "Epoch: 37 - val_loss: 1.689 - val_ppl: 5.415 - val_acc: 7.276%: 100%|██████████| 40/40 [00:01<00:00, 36.67it/s]\n",
            "Epoch: 38 -     loss: 0.658 -     ppl: 1.930 -     acc: 7.920%: 100%|██████████| 625/625 [00:43<00:00, 14.33it/s]\n",
            "Epoch: 38 - val_loss: 1.688 - val_ppl: 5.406 - val_acc: 7.272%: 100%|██████████| 40/40 [00:01<00:00, 36.96it/s]\n",
            "Epoch: 39 -     loss: 0.649 -     ppl: 1.914 -     acc: 7.907%: 100%|██████████| 625/625 [00:43<00:00, 14.39it/s]\n",
            "Epoch: 39 - val_loss: 1.700 - val_ppl: 5.472 - val_acc: 7.283%: 100%|██████████| 40/40 [00:01<00:00, 36.75it/s]\n",
            "Epoch: 40 -     loss: 0.643 -     ppl: 1.902 -     acc: 7.981%: 100%|██████████| 625/625 [00:43<00:00, 14.33it/s]\n",
            "Epoch: 40 - val_loss: 1.684 - val_ppl: 5.386 - val_acc: 7.284%: 100%|██████████| 40/40 [00:01<00:00, 36.98it/s]\n",
            "Epoch: 41 -     loss: 0.637 -     ppl: 1.890 -     acc: 7.951%: 100%|██████████| 625/625 [00:43<00:00, 14.43it/s]\n",
            "Epoch: 41 - val_loss: 1.691 - val_ppl: 5.427 - val_acc: 7.268%: 100%|██████████| 40/40 [00:01<00:00, 36.49it/s]\n",
            "Epoch: 42 -     loss: 0.628 -     ppl: 1.875 -     acc: 7.911%: 100%|██████████| 625/625 [00:43<00:00, 14.26it/s]\n",
            "Epoch: 42 - val_loss: 1.708 - val_ppl: 5.519 - val_acc: 7.286%: 100%|██████████| 40/40 [00:01<00:00, 36.66it/s]\n",
            "Epoch: 43 -     loss: 0.623 -     ppl: 1.864 -     acc: 7.929%: 100%|██████████| 625/625 [00:43<00:00, 14.36it/s]\n",
            "Epoch: 43 - val_loss: 1.699 - val_ppl: 5.468 - val_acc: 7.286%: 100%|██████████| 40/40 [00:01<00:00, 36.86it/s]\n",
            "Epoch: 44 -     loss: 0.616 -     ppl: 1.851 -     acc: 7.927%: 100%|██████████| 625/625 [00:43<00:00, 14.34it/s]\n",
            "Epoch: 44 - val_loss: 1.729 - val_ppl: 5.638 - val_acc: 7.269%: 100%|██████████| 40/40 [00:01<00:00, 36.03it/s]\n",
            "Epoch: 45 -     loss: 0.610 -     ppl: 1.840 -     acc: 7.934%: 100%|██████████| 625/625 [00:43<00:00, 14.35it/s]\n",
            "Epoch: 45 - val_loss: 1.729 - val_ppl: 5.633 - val_acc: 7.273%: 100%|██████████| 40/40 [00:01<00:00, 36.56it/s]\n",
            "Epoch: 46 -     loss: 0.602 -     ppl: 1.826 -     acc: 7.942%: 100%|██████████| 625/625 [00:43<00:00, 14.51it/s]\n",
            "Epoch: 46 - val_loss: 1.732 - val_ppl: 5.651 - val_acc: 7.274%: 100%|██████████| 40/40 [00:01<00:00, 36.29it/s]\n",
            "Epoch: 47 -     loss: 0.595 -     ppl: 1.813 -     acc: 7.971%: 100%|██████████| 625/625 [00:43<00:00, 14.52it/s]\n",
            "Epoch: 47 - val_loss: 1.733 - val_ppl: 5.656 - val_acc: 7.274%: 100%|██████████| 40/40 [00:01<00:00, 36.26it/s]\n",
            "Epoch: 48 -     loss: 0.592 -     ppl: 1.808 -     acc: 7.921%: 100%|██████████| 625/625 [00:43<00:00, 14.33it/s]\n",
            "Epoch: 48 - val_loss: 1.746 - val_ppl: 5.730 - val_acc: 7.264%: 100%|██████████| 40/40 [00:01<00:00, 35.77it/s]\n",
            "Epoch: 49 -     loss: 0.588 -     ppl: 1.801 -     acc: 7.966%: 100%|██████████| 625/625 [00:43<00:00, 14.36it/s]\n",
            "Epoch: 49 - val_loss: 1.747 - val_ppl: 5.735 - val_acc: 7.267%: 100%|██████████| 40/40 [00:01<00:00, 36.45it/s]\n",
            "Epoch: 50 -     loss: 0.579 -     ppl: 1.784 -     acc: 8.002%: 100%|██████████| 625/625 [00:43<00:00, 14.25it/s]\n",
            "Epoch: 50 - val_loss: 1.762 - val_ppl: 5.821 - val_acc: 7.270%: 100%|██████████| 40/40 [00:01<00:00, 36.30it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4ybctUVAYK8",
        "outputId": "94bbd056-c376-4402-e971-6bc3f61b59b3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Mar  7 13:51:08 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P0    32W /  70W |   8580MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "gFcY3q9dmIhr",
        "outputId": "5aa7faac-f516-4094-9866-5b83e9372fa7"
      },
      "source": [
        "_, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axes[0].plot(history['loss'], label='train')\n",
        "axes[0].plot(history['val_loss'], label='valid')\n",
        "axes[0].set_title('Loss history')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].grid(True)\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(history['ppl'], label='train')\n",
        "axes[1].plot(history['val_ppl'], label='valid')\n",
        "axes[1].set_title('Perplexity history')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Perplexity')\n",
        "axes[1].grid(True)\n",
        "axes[1].legend()\n",
        "\n",
        "axes[2].plot(history['acc'], label='train')\n",
        "axes[2].plot(history['val_acc'], label='valid')\n",
        "axes[2].set_title('Top-5 Accuracy & BLEU history')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('Accuracy & BLEU (%)')\n",
        "axes[2].grid(True)\n",
        "axes[2].legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFNCAYAAABSRs15AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5hU5fXA8e+Z2dm+tF16bwpIB7GhYokFeyFi7zWJJaZoYmKJJkZTjD9bjA3FhtiwxRZXUSkCIq50pNddYGF7Pb8/3rswLFthd6edz/PMw+wtc8/MZd65575NVBVjjDHGGGOMMZHPF+oAjDHGGGOMMcY0DUvwjDHGGGOMMSZKWIJnjDHGGGOMMVHCEjxjjDHGGGOMiRKW4BljjDHGGGNMlLAEzxhjjDHGGGOihCV4JiyIyHMicm8d6/NFpE9LxmSMiTwi0ktEVETi9vN1ficiTzVRTJeJyJd1rP9ARC5timMZY0y0qK88b8pyOtpYgmf2ICKrROT4UMdRnaqmquqPdW0jIuNEZF1LxWSMaTivbCnybtZs9m7qpIY6rtqo6p9V9SpouqSxjmOdrKqT6tvOi6Ffc8RgTHPxvvNVj8qgciBfRC5somNUfUeDj/WHBuyXKSLbRSShKeIIRyLSTkTeEZEdIrJBRH7TgH1URAq8zzFHRF4WkTZB6zNF5Koa9qvpPOSLyHm17bc/127B5XQ976fGeKOZJXjGeJrr4s0Ys8tpqpoKjARGA3c0Zmdx7HdrH1j5ZkLFu0Gb6n331+CVA97jxSY+XJug1/5TXRuKSC/gSECB05s4jjq18Pfx10Ai0Bk4CPiqgfsN885ZH6AtcFcjjhl8HlJV9dXGBBxOIvV3J+ICNqEhIgki8pB392eD9zzBW5chIu+KSK6IbBOR6VVfBhH5rYisF5E8EVkiIsfVcZi2IvKet+0sEekbdPxdd65FZLyILPS2Wy8ivxKRFOADoEvQHaMu9cQ9TkTWeTFuAp4VkSwROS3ouAHv7tWIpv9UjYlNqroe930dDCAih4rI114Z8p2IjKva1rvzep+IfAUUAn28ZX8RkdkislNE3haRdjUdS0Rai8jTIrLRKy/uFRG/iMSLyHwR+YW3nV9EvhKRP3p/3yUik72X+cL7N9crW472yrohQcfpICKFItK+tvctIn/zagtWisjJ1d5jVW1hPxH5XNzd9hwRedVbXhXDd9XuiF8tIsu9eKaJSJeg11UR+ZmILAOWicijIvL3ajFNE5FbaovZmObSwN/n33nfg1XSRLV9QS4BZgLPAXs0kRaR7iLyhohki8hWEXkkaN3VIrLIuwZZKCIjveV71LBLUNeTWq432oq7dsr2yoV3RaRb0P7tRORZ77PZLiJvecsbe51SBmxR1UJV3a6qDU3wAFDVncA0YFBj9mtiF4rIGu99/r5qYXA5LSKJIjLZO1+5IvKNiHQUkftwifwjXtn5iLf94d42O7x/Dw963eq/O7eKyNzggETklyLydku8+X1hCZ5pqN8DhwLDgWHAGHbffb8VWAe0BzoCvwNURA4Efg4crKppwInAqjqOMRG4G3enaDlwXy3bPQ1c673mYOB/qloAnAxsCLpjtKGeuAE6Ae2AnsA1wPPARUHrxwMbVfXbOuI2xjSCiHTHfbe+FZGuwHvAvbjv4q+A16slShfjvp9pwGpv2SXAFbi70uXAw7Uc7jlvfT9gBHACcJWqluK+6/eIyEDgNsBPzeXOUd6/VXelPwdeYc+y4nzgU1XNriWOQ4AlQAbwAPC0iEgN2/0J+AhXDnYD/g9AVatiGFZ1R1xEjgX+AvzU+xxWe3EFO9M79iBgEnC+7L4BlwEcD7xUS8zGNKeG/D5nAF1xCdiT3nVFXVZ7idSz3v/vulwCvOg9ThSRjuBu9gDv4r5Pvbzjv+Ktm4CryboEaIWr+dvagPda9X6Crzd8wLPe3z2AIuCRoO1fAJJxtW4dgH96yxt7nfIN7nt/ZQPj3IOItMWVIzP3Zf8mMhY4EDgO+KNXZld3KdAa6A6kA9cBRar6e2A68HOv7Py5uBuC7+F+N9KBfwDviUh60OsF/+48DPSudtyLceciLFmCZxrqQuAeVd3iXcDcjfvPDe7uUGegp6qWqep0VVWgAkgABolIQFVXqeqKOo7xpqrOVtVyXIE7vJbtyrzXbOXdjZq3j3EDVAJ3qmqJqhYBk4HxItLKW38xrpA1xuy/t0QkF/gS+Bz4M+5C5X1VfV9VK1X1Y2AO7qKlynOq+oOqlqtqmbfsBVXN8m7u/AH4qXdhtot3wTYeuFlVC1R1C+4iaSKAqmbhEsu3cInlxapa0cD3UpUsVSVp9ZUVq1X1P97rT8KVmR1r2K4Md8HXRVWLVbXWwVlw5dszqjpPVUuA24HDxDU9q/IXVd2mqkWqOhvYgbtIAvc5ZKrq5jrfqTHNo77fZ4A/eL/Pn+MuyH9ay2vlAAfjvjujcBfltTb/FJGx3rZTVHUusAK4wFs9BugC/NorN4K/h1cBD6jqN+osV9XVex2gZntcb6jqVlV93atZy8PdXDrai68z7qb1dd51Tpn3GUAjrlO8GsUngXHAbSJyhbc8QURKRaR1HfHO88rrHFwC+u8Gvk+AHK8WrepRU0LWGHd7n9l3wHe4GwLVleGStX6qWqGqc73ax5qcAixT1Re835WXgcXAaUHbBP/ulACv4iXWInIQLvl/dz/fV7OxBM80VBd23znHe17VFOhBXI3bRyLyo4jcBqCqy4GbcXe7tojIKxLUfKgGm4KeFwK1DcBwDu6ibbW4pkyH7WPcANmqWlz1h1fr9xVwjrgOxSdTx4+EMaZRzlTVNqraU1Vv8G6q9AQmBF8M4O7Wdg7ab20NrxW8bDUQwN3tD9bTW74x6LX/jbsbXmWSt937qrqsoW9EVWfhyqlxIjIAV0M4rY5ddpVvqlroPa2pjPsNIMBsEfmh6oKsFnuUb6qaj6tN6Bq0TfXPbhK77/5fhN3AMqFT3+/zdu8Gzh7rRaSHBA3gAe7/vqrO8S7GN+NaD50gImm1HPtS4CNVzfH+fondzTS7427IlNewX3dcMrgv9rjeEJFkEfm3iKwWkZ24puBtvBtV3YFtqrq9+os08jrlSmCaqn6Ba71wj1emHAp8p6o76oh3pKq2wfXfexyYLiKJDXyvGV5ZX/VY5C0vx5XJwQK45KwuDbk+fAH4EHjFa9b6gIhUP1aV6v/38P6ur+y8wLupdzHu5kBJPXGHjCV4pqE24C6CqvTwlqGqeap6q6r2wTVX+KV4fe1U9SVVrbpTpsBf9zcQ787ZGbiLtLeAKVWrGhN3HftUXQBNAGao6y9kjGkea3G1ccEXAymqen/QNjV9T7sHPe+Bu0DIqbbNWqCEPS82WqnqQUHbPIa7C3uid1e/JjUdH3aXFRcDU4Mv3vaVqm5S1atVtQtwLfCY1D5y5h7lm7i+yOlAcJlVPfbJwBkiMgwYiCtDjQmF+n6f23r/p/dYr6prdM+BW2pS9f9+r+tcEUnC1QQeLSKbxPWJuwUY5n0v1gI9pOaBUNYCfWtYDi7xSA76u1MtMVW5Fdfs8BBVbcXupuDiHaedBI1cWU1Dr1Pi8BIqVV0JnIS7DnuKBl6Pea0mngJ64/Wb3g9rcDVfwXqzd7LVaF4t592qOgg4HDgV15QW9v7sq//fA/f/q9ayU1VnAqW4/nwXEOY3xyzBMzUJeJ1Vqx5xwMvAHSLS3mvX/kfchQIicqq4gQEE1/ynAqgUkQNF5FhxnaaLce3LK/cnMHEDI1woIq29Qmdn0GtuBtKrNTmoNe46vIUb5e8mwrh9tTFRYjJwmoicKG6gk0RxAxJ0q2e/i0RkkIgkA/fgEqw9mleq6kZcf7a/i0grEfGJSF8RqWoGdTGuOddlwI3AJKl56oZsXDlTfS7OycBZuAutJikrRGRC0HvfjrvICC7jgmN4GbhcRIZ75eyfgVmquqq211fVdbg+OS8Ar3u1qMaEQkN+n+/2fvePxF2wv1bTC4nIId41h8/rR/UwrvlxTTVUZ+KuUwbhuoIMx93smI5LCGYDG4H7RSTFK5OO8PZ9CviViIwSp5+IVCUK83E1PH4ROQmvuWUd0nDXRbni+oTdWbXCK7s+wN3gaStuIJWjgvZt6HXKG8B5InKmVzO4E9fEsS8uIa2Xt9/lXqzB01XFVbtWrK22LNiruDJrjPf5HYBLrqv3HW40ETlGRIYEvc8yai873wcOEJELRCRO3KBVg6i/yeXzuH6SZfU0nw85S/BMTd7HfZGrHnfh+qnMARYA3wPzvGUA/YFPgHxgBvCYqn6G6393P+6u+iZcjdvtTRDfxcAqr0nDdbh2/KjqYtwPxo9ec6wu9cRdI++C53XcXaU3miBeY0wtVHUtcAZucKZs3J3rX1P/79MLuAFUNuGaEN1Yy3aXAPHAQlzCNBXoLCI9gIeAS7zmXS/hyop/Vn8Br0nlfcBXXtlyaFDs83BJ2PQGvuX6HAzM8pqeTQNu0t1zgN6FS0JzReSnqvoJrv/h67gL0r54/QvrMQkYQpjfgTZRr77f50247+wGXBPE67zf+Zr0Af4L5AFZuJr782vZ9lLgWa8mcFPVA3fhfiGuBu00XLPrNbhB5M4DUNXXcGXBS96x3sINnAIu2ToNyPVep77a8YeAJNw10kwv/mAX45KUxcAWXJcXvDgadJ2iqjNwtU134m7AfwFkAucCL0vdI4R/55VD23Gf2Vmqui1o/ePsea34bNC6qhGHqx6/9OL5EDeg1bNePO/jyqMn64ijoTrhyvedwCJcP++qMu5fwLniRiN9WFW34m4Y3Ipr1v4b4NSgJru1eQFXi1lfRUHIiWptLU+MiV3ihko/QFUvqndjY0yLEpFMYLKqPhUGsTyDazbWqDn9QsmrCZiMGxjLLgJM2BE3VcpkVa2vJj9m2XVKy/Oa927B9U9scJ/tULCJT42pxmsqcSV7j+ZljDG7iBut8mzc9AsRwWtGdRPwlCV3xkQmu04JmeuBb8I9uQNromnMHkTkalwTsQ+8UaeMMWYvIvInXFOwB73BC8KeuKHKc3EjlD4U4nCMMfvArlNCQ0RW4W6O3RriUBrEmmgaY4wxxhhjTJSwGjxjjDHGGGOMiRLNluB5Q6bOFpHvxE3WencN21wmItkiMt97XNVc8RhjjDHGGGNMtGvOQVZKgGNVNd/r1P2liHzgTRQY7FVV/XlDXzQjI0N79erVoG0LCgpISUmpf8MwY3G3nEiMGaIv7rlz5+aoavsQhNSkor18isSYweJuSZEYM9QddzSUT9FeNoHF3ZIiMWaIvrjrLJtUtdkfQDJufpNDqi2/DHikMa81atQobajPPvuswduGE4u75URizKrRFzcwR1ugLGruR7SXT5EYs6rF3ZIiMWbVuuOOhvIp2ssmVYu7JUVizKrRF3ddZVOz9sETEb+IzMfNGfGxqs6qYbNzRGSBiEwVke7NGY8xxhhjjDHGRLNmnQdPVSuA4SLSBnhTRAaralbQJu8AL6tqiYhci5vN/tjqryMi1wDXAHTs2JHMzMwGHT8/P7/B24YTi7vlRGLMYHEbY4wxxpiatchE56qaKyKfASfh5g2qWr41aLOngAdq2f9J4EmA0aNH67hx4xp03MzMTBq6bTixuFtOJMYMFrcxxhhjjKlZsyV4ItIeKPOSuyTgJ8Bfq23TWVU3en+eDixqrniMCVdlZWWsW7eO4uLiBu/TunVrFi2KvK9LamoqZWVlBAKBUIdijGmAxpZPkVo2tW7dmpUrV9KtW7eYKZ9qO7eRfA5rizsxMTGmzq0xzVmD1xmYJCJ+3HQMU1T1XRG5B9cpcBpwo4icDpQD23CDrhgTU9atW0daWhq9evVCRBq0T15eHmlpac0cWdNSVdatW8e6devo3bt3qMMxxjRAY8unSCybAHbu3ElpaWlMlU+1ndtIPYe1xa2qbN26NabOrTHNluCp6gJgRA3L/xj0/Hbg9uaKwZhIUFxc3KjkLlKJCK1bt2b9+vWhDmUPIpIIfAEk4MrEqap6p4j0Bl4B0oG5wMWqWhq6SI1pebFUPqWnp5OdnR3qUFqMnVtjolezjqJpjGmYaP+BrRKm77Nqzs5hwHDgJBE5FNek/J+q2g/YDlwZwhiNCZkw/d42uVh5n8Fi5T3Hyvs0pooleMbEuNzcXB577LFG7zd+/Hhyc3ObIaKW5U0nk+/9GfAeihvRd6q3fBJwZgjCMyamxWL5JCK3iMgPIpIlIi97rQyC1yeIyKsislxEZolIr9BEun9i8dwa01JaZBRNY0z4qvqRveGGG/ZYXl5eTlxc7UXE+++/39yhtRivr/BcoB/wKLACyFXVcm+TdUDXWvaNmWlcIjFmsLj3R+vWrcnLy2vw9hUVFY3avj7r1q3jkUce4eKLL95jeX3l06uvvgrQ4Fiq4i4uLg7pZy4iXYEbgUGqWiQiU4CJwHNBm10JbFfVfiIyEdfa4LwWD3Y/2W+PMc0nahO8lTkFfLamjNEl5aQmRO3bNGa/3XbbbaxYsYLhw4cTCARITEykbdu2LF68mKVLl3LmmWeydu1aiouLuemmm7jmmmsA6NWrF3PmzCE/P5+TTz6ZsWPH8vXXX9O1a1fefvttkpKSQvzOGq76nJ3AgEbs2+hpXKbMWcvO3KVcFWFTRkTqNBcW975btGhRowbcaOoBOu69915WrlzJkUce2azlU1XciYmJjBix1/ABLS0OSBKRMiAZ2FBt/RnAXd7zqcAjIiKqqi0X4v5r6t+ejh078t5770XUb48xweau3s7OojKOGdBhv18rajOf79bmMmlhKZfllViCZ0wd7r//frKyspg/fz6ZmZmccsopZGVl7Rpt7JlnnqFdu3YUFRVx8MEHc84555Cenr7HayxbtoyXX36Z//znP/z0pz/l9ddf56KLLgrF29kvQXN2Hga0EZE4rxavG9Bko8PcPe0HxnYWrmqqFzQmSsVa+aSq60Xkb8AaoAj4SFU/qrZZV2Ctt325iOzADQaVE7xRfa0Laqudbepa2NrccccdLFiwgOnTpzN9+nQmTJjAzJkz6dWrF3l5efzrX//adW7HjRvHCSecQHp6OqpKfn4++fn5LFu2jKeeeop//OMfXHLJJUyePJmJEyfWeLxQ187WJhxq6hsrEmOG8I27UpV3fyzjreVl9EjzwWGJe/Qb3Ze4ozbzSY73A1BQUl7PlsaEj7vf+YGFG3bWu11FRQV+v79BrzmoSyvuPO2gBscwZsyYPYaSfvjhh3nzzTcBWLt2LcuWLdvrAqp3794MHz4cgFGjRrFq1aoGHy/U6piz8zPgXNxImpcCbzfVMePjfJRF1s12YxpUPjWmbAIrn6oTkba4GrreQC7wmohcpKqTG/ta9bUuCK6dDT63jT2Htanv3KampuLz+UhLSyM5OZkxY8YwZMiQXev//ve/7zq369evZ9OmTbtG/UxNTQXcuT3iiCMAGDFiBJs3b661BjlMamf3Eg419Y0V7jFv3lnM+99v5NxR3UhL3D33YTjGvSG3iJtfnc/slYWcMbwLfzpzMK0S95yvcV/ijtoEL8WrtbMEz5jGSUlJ2fU8MzOTTz75hBkzZpCcnMy4ceNqnPA4ISFh13O/309RUVGLxNpEapuzcyHwiojcC3wLPN1UBwz4fZRXVjTVyxkTM2KgfDoeWKmq2QAi8gZwOBCc4K0HugPrRCQOaA1sbelAm1pTnNuysrIWidWEr8pK5Rcvf8vsldt4PHMFfzh1EKcO7dyiI6nOXrmNb1Zt4+oj+xAfV/t4lh98v5Hb3vie8opK/j5hGGeP7NpkcUZ9gldYahdRJnI09E52U/ZzSUtLq7U5zo4dO2jbti3JycksXryYmTNnNskxw0kdc3b+CIxpjmPGx1mCZyJPQ8qnpu6DF4Pl0xrgUBFJxjXRPA6YU22babhWBTNwrQz+t7/974LPbUtNdB6D59a0gEkzVjF75TZuGNeX6cty+MXL3/LqN2u554yGtxTYVxt3FPGX9xcz7TvXbXb+2lwevWDkXkmeqvK3j5bw6GcrGNqtNQ9PHEGvjJSaXnKfRW+CV9VEs9Rq8IypS3p6OkcccQSDBw8mKSmJjh077lp30kkn8cQTTzBw4EAOPPBADj300BBGGj1cgmdNNI2pT6yVT6o6S0SmAvOAclzrgSdF5B5gjqpOw7UmeEFElgPbcKNsRpxYO7em+a3KKeCv/13MMQe259cnHsitJxzIi7NW8+CHSzjpoemc3sfPUUcpPl/T1uYVl1Xw1PQfefSzFVSqcuNx/WmVGMe97y3iZy/N2yPJK6uo5PY3vmfq3HVMPLg795wxuM5avn0VtQlesjXRNKbBXnrppRqXJyQk8MEHH9S4rqofS0ZGBllZWbuW/+pXv2ry+KJNvN9HWWWoozAmMsRa+aSqdwJ3Vlv8x6D1xcCEFg2qmTTlub3xxhtbpObRhKeKSuVXr31HwO/jL2cPRUTwC1xyWC9OHtyZu975gakLNpL/4jz+9tNh+zwAY35JOatyCliyKY+lm/NYsjmPrPU7yMkv5eTBnfjd+IF0b5cMuO4Yd077YVeSV1ZRyc9emkfmkmxuPr4/Nx3Xv9majkZtgpcaX5XgWTMoY0x4iY/zUbF3dxJjjDHG4JoxfrEsh+e/XkW7lHiGdmvN0G5tGNA5jYS4vQcBevarlcxZvZ2/TxhGp9aJe6xrn5bAI+ePoFXpVqYs2sxZj37Fk5eMprfXLFJVmbt6O2/NX8+abUUkBXwkx8eRFO8n3u9jS14x67YXsXZbIdsLd/fzjI/z0a99KmP7ZTBhdHeO6Jexx3EvPbwXAHdO+4EbXpzLlrwSstbv4C9nD+H8MT2a+BPbU9QmeEleE81Ca6JpjAkz8X4fBdZE0xhjTAwoKq3g86Vb2F5YRpukAK2TA7RJiqdtSoCOaYl7NZmct2Y7D/x3MTN/3EbHVgmUVSivzV0HQMAvDOzcijG92nFIn3QO7tWWrQWlPPjhEo4f2IGzR3atMQYR4cReAU4dO4KfvzSP0x/5krtPP4hVOQW8OX89a7cVkRjwcWDHNDaXVVJYVk5RaSUl5RW0T0uge9tkhnRtTfd2yfRsl8wBndLo2S6ZOH/dzSuDk7zEgI//XDKa4wZ2rHOfphC1CV58nI84gQIbZMUYE2bi43zssCaaxhhjIkhZRSXTl2UzY30ZR6vW2bywuKyCzCXZvPf9Rj5dtLnWQQ+T4/3065C66/Htmlw+XriZjNR47j79IM4f04OAX1ifW8T363awYP0O5q7ezvMzV/PUlysRca32EgN+/nzWkHqbPB7RL4NpPx/LtS/M5ZdTvsMnbtnNxx3AiYM7Ncvc2Zce3ovu7ZLo1CqJQV1aNfnr1yRqEzyAhDjrg2eMCT9ukJVQR2GMMcbUTVWZvzaXt75dzzsLNrKtoBSAtP8t58bj+te4z1vfrueOt7LILymnXUo8Z47oyqlDOtMrI4UdRWXkFpaxo6iU7PxSfszOZ/mWfL5evpU35q0nLSGOX51wAJcf0XvXiPgA3dom061tMicP6Qy4BPK7tbnMWrmNb9ds58JDetKhVWKN8VTXvV0yr19/OJ8vzWZEjzZ0bOB+++PYAc1faxcsqhO8RL9YHzxjTNgJ+H2UWwtNY4wxYSwnv4SLnprF4k15JMT5OH5QR84a3pVnP5nPPz5eStuUeC4+tOce+7w4azV3vJXFwT3b8fNj+3F43/Q9mjF2aZNU6/F2FpcR8Pl2dbOqS2LAzyF90jmkT/o+vbekeD8nDe60T/tGguhO8OKsD54xJvzEx/kosz54xhhjwlRFpXLzK/NZmVPA/WcPYfzQzrRKDLiVm+JJbNWOP76dRZukAKcN6wLAf774kfveX8SxAzrw2IUjSQzUn6gF2/X6Zr81/cQLYSTBL+RbE01jmlxqaioAGzZs4Nxzz61xm3HjxjFnTvX5eQ1Agt+aaBrTHKxsil52blvWI/9bzpfLc7jnjIOYOKbHHslXnE949MKRHNyzHb+cMp/Pl2bzz4+Xct/7izhlaGeeuGhUo5M707SiOsFLiqPWTp3GmP3XpUsXpk6dGuowIk7AEjxjmpWVTdHLzm3TyFq/gzMf/Yopc9aiumeLkq+X5/DQp0s5e0RXfjq6e437Jwb8/OfS0fTrkMYVz33Dvz5dxoRR3Xh44ohmmbjbNE5Un4EEv9ggK8Y0wG233cajjz666++77rqLe++9l+OOO46RI0cyZMgQ3n777b32W7VqFYMHDwagqKiIiRMnMnDgQM466yyKiopaLP5I4wZZsSaaxtTHyqbo1dTn9oILLrBz20Drc4u44rlvyFq/g99MXcBVk+aweaebnHVLXjE3vjKfvu1TufeswXWOStk6KcCkKw5mcJdWXHNUH/56zlD8vuaZuNs0TlT3wUuIg5xiq8Ezpj7nnXceN998Mz/72c8AmDJlCh9++CE33ngjrVq1Iicnh0MPPZTTTz+91sL+8ccfJzk5mUWLFrFgwQJGjhzZkm8hotgomsY0jJVN0aupz+2MGTM48sgjW/ItRKSdxWVc8ew3FJVW8O6NY/l6+VYe+HAxJ/zzC+48bRCvzVlHfkkZL151CMnx9acJHdISefvnY1sgctMYUZ3gJVoNnok0H9wGm76vd7OkinLwN/Dr22kInHx/nZuMGDGCLVu2sGHDBrKzs2nbti2dOnXilltu4YsvvsDn87F+/Xo2b95Mp041jzr1xRdfcOONNwIwdOhQhg4d2rD4YpAbZCXUURjTSA0onxpVNkG95ZOVTS0k6Nw2+hzWpoXP7eDBg6Pm3FZUuqkJMpds4ZtV2zjmwA5cMbY3gXom1a5PaXkl10+ey4rsfCZdMYYBnVoxoFMrxh3Ynl+99h2/nPIdAA+eO5QDO6U1xVsxIRLdCV6cUGCjaBrTIBMmTGDq1Kls2rSJ8847jxdffJHs7Gzmzp1LIBCgV69eFBcXhzrMqBDw+6hQN79QfZOyGhPrrGyKXnZu9zRvzXYmfb2Kz5dmk1tYhk+gV3oKf/lgMW/MW8+fzx7MqJ7t9um1VZXfvfk9Xy3fyt8mDOOIfhm71vVpn8pr1x3O8zNWUVRWwYRa+t2ZyBHdCZ4fivRiqbwAACAASURBVMsqqahUaxNsIkM9NW1VivLySEtr2rtr5513HldffTU5OTl8/vnnTJkyhQ4dOhAIBPjss89YvXp1nfsfddRRvPTSSxx77LFkZWWxYMGCJo0vmiR4HdBLKypJiLORxkyEaED5ZGVThAo6t81xDmvTlOd24cKFEX1uX5y1mjvf/oG0xDiOHdCBYw7swJH9M2iTHM9HP2zirmk/cM7jMzh/THd+feIAkgJ+SsorKC2vpKS8ko6tEmsd3GRrfgn/+nQZU+eu46bj+nPuqG57beP3CZcf0bu536ZpIVGd4CX4XVJXUFpuc2sYU4+DDjqIvLw8unbtSufOnbnwwgs57bTTGDJkCKNHj2bAgAF17n/99ddz+eWXM3DgQAYOHMioUaNaKPLIE+81sykttwTPmPpY2RS9mvLc9u/fPyLPbXmlcsdb3zN55hqOPqA9D58/gtZJe16znnBQJ47ol8FDnyzlma9W8fLstXu9TuukACce1JFThnbh8L7pBPw+lm/J4+kvV/L6vPWUlldy8aE9ufn4/i311kwIRXWCl+i9u8KSCkvwjGmA77/f3b8mIyODGTNm1Lhdfn4+AL169SIrKwuApKQkXnnlleYPMgpU3WUtq7CRNI1pCCuboldTndu8Fqx5bCpb80t48Jtilmxfw7VH9eE3Jw2otcVZSkIcvz9lEGeP7MbHCzcT8PtIiPOREPDhF2H2ym28//0mpsxZR9vkAP07pDF71TYS4nycM7IbV47tTb8OqS38Dk2oRHeCF1SDZ4wx4SIQVINnjDEm9ny9Iodfv7aALTsreei84Zw5omuD9hvYuRUDO7faa/nEMT0oLqvg86XZvLtgI4s27uSXPzmACw/pQXpqQlOHb8JcVCd4CUE1eMYYEy6qavAswTPGmNiyvaCUP7+/iNfmrqNnejK3H5LY4OSuPokBPyce1IkTD6p51FETO6I6wauqwcu3qRKMMWFkV4JXYTefjDEm0pWWV1JWUUlKQu2X1arKtO82cM87C8ktKuP6cX256bj+zPxqegtGamJFdCd4VTV41kTThLlYGS5f1fqcAcR7N59Ky+3zMOHPyqfoZed2/23eWcxZj37Fhh3FdEhLoFdGCr3TU+jUOpEdRWVk55eQnVfCph3FrNlWyLDubZh89pAam1ka01SiOsHbPYqm3SU34SsxMZGtW7eSnp4e1T+0qsqOHTtITEwMdSghFx80TYIx4SyWyqetW7fGVPlk53b/VU0cnltUxk3H9Wd9bhGrcgr4dPFmcvJLSUuMo31qAhlpCQzp1pprjurD+WN62NRdptlFdYJXVYNXYE00TRjr1q0b69atIzs7u8H7FBcXR+SFSEFBAcOGDQt1GCEX73dTI1gfPBPuGls+RWrZVFxcTJs2bejWbe/5waJVbec2ks9hbXEnJiY2y7m9590fmLcml0cvGMkpQzvvsa68opI4f83z0hnT3KI7wauqwbMEz4SxQCBA796Nm1w0MzOTESNGNFNEzSczM5NAwKYssUFWTKRobPkUyWVTJMa9P2o7t5H6WbR03FPmrGXyzDVce3SfvZI7wJI7E1JR/b8vwZs/uNCaaBpjwkjAu/lUZk00jTEmbFRWaoNuvC1Yl8sdb2VxRL90fn3CgS0QmTGNE9UJnt8nJMT5bB48Y0xYqarBK7EaPGOMCRu/fX0Bo+/9mClz1tY6MMvGHUVc98Jc2qcm8H/nj7SaOhOWov5/ZUpCnDXRNMaElQQbZMUYY8LK9GXZvDZ3HUnxfn4zdQGXPDObtdsKd63fkFvEnW9ncfSDmWwrLOWJi0bRLiU+hBEbU7tm64MnIonAF0CCd5ypqnpntW0SgOeBUcBW4DxVXdWUcaQk+G2ic2NMWKkaZKXMavCMMSbkissq+P2bWfTJSOH9m47ktTlruf+DxZz40BfcdFx/Vm0tYOrcdajCOSO7ccMxfemZnhLqsI2pVXMOslICHKuq+SISAL4UkQ9UdWbQNlcC21W1n4hMBP4KnNeUQaTEx1kTTWNMWAnEefPgWQ2eMcaE3MOfLmPNtkJeuvoQEgN+Lj6sF8cO7Mjv3viev3ywmHi/j4kH9+C6cX3p2iYp1OEaU69mS/DUNV7O9/4MeI/qDZrPAO7ynk8FHhER0SackTI53k+B1eAZY8JIvN9G0TTGmHCwZFMeT37xI+eO6sbhfTN2Le/aJonnLj+YeWu2061tMh1bRd7UESZ2NWsfPBHxi8h8YAvwsarOqrZJV2AtgKqWAzuA9KaMISXBavCMMeHFpkkwxpjQq6xUfvfm96QlxvG78QP3Wi8ijOrZzpI7E3GadR48Va0AhotIG+BNERmsqlmNfR0RuQa4BqBjx45kZmY2aL/8/HwKdxaTXVDZ4H3CQX5+fkTFWyUS447EmMHijnQBvw2yYowxofbyN2uYu3o7f58wzAZMMVGlRSY6V9VcEfkMOAkITvDWA92BdSISB7TGDbZSff8ngScBRo8erePGjWvQcTMzM+nZtQ2bV26jofuEg8zMzIiKt0okxh2JMYPFHemsiaYxxoTW50uzuf+DxRzeN52zR3YNdTjGNKlma6IpIu29mjtEJAn4CbC42mbTgEu95+cC/2vK/nfgDbJi0yQYY8KIzyf4xWrwjDGmpW3JK+bGl7/l0mdm0z4tgfvPHoqIhDosY5pUc9bgdQYmiYgfl0hOUdV3ReQeYI6qTgOeBl4QkeXANmBiUwfh+uDZICvGmPAS8Nk0CcYY01IqK5VXvlnL/R8soriskluOP4DrxvUhIc4f6tCMaXLNOYrmAmBEDcv/GPS8GJjQXDEApMT7KS2vpKyicle/F2OMqSIi3XHzcXbEjfT7pKr+S0TuAq4Gsr1Nf6eq7zfVcf0+q8EzxpiWoKr84uVvee/7jRzapx33nTWEvu1TQx2WMc2mRfrghVJygnuLhSUVtE62BM8Ys5dy4FZVnSciacBcEfnYW/dPVf1bcxw04BPrg2eMMS1g8qw1vPf9Rm79yQH8/Nh+1iTTRL2oz3hSE1zVu02VYIypiapuVNV53vM8YBFuCpdmFeezQVaMMaa5Lducx73vLuToA9pbcmdiRtQneMnxXg2eJXjGmHqISC9c0/KqOTt/LiILROQZEWnblMeKsyaaxhjTrErKK7jxlfmkJsTx4AQbTMXEjqhvoplSVYNXYgOtGGNqJyKpwOvAzaq6U0QeB/6E65f3J+DvwBU17LdP83T6tJINm7ZE1LyAkTqPocXdciIxZgifuEXkQODVoEV9gD+q6kNB24wD3gZWeoveUNV7WizIMFNRqVw56Ru2bi2mbd9chnVvs2vdg/9dwqKNO3n60tF0SLPJyk3siPoEr6oGz6ZKMMbURkQCuOTuRVV9A0BVNwet/w/wbk377us8nQlff0Crtu0YN27M/gXfgiJ1HkOLu+VEYswQPnGr6hJgOIA3Cvl64M0aNp2uqqe2ZGzhaurctWQuySbBD2c8+hUnHtSRW084kE07innqy5VcclhPjhvYMdRhGtOioj7BS/UGWbGpEowxNRHXZudpYJGq/iNoeWdV3ej9eRaQ1ZTHtT54xph6HAesUNXVoQ4kXOUVl/Hgh0sY1bMtV/UvYSnd+M/0H/lo4RckB/z075DK78YPDHWYxrS4GOiD55poWh88Y0wtjgAuBo4VkfneYzzwgIh8LyILgGOAW5ryoHE+KLM+eMaY2k0EXq5l3WEi8p2IfCAiB7VkUOHkkc+Wk5Nfyh9PHURSnHDT8f2Z/ptjuObIPnRslcjD548gMWDz3JnYE/U1eCleDV6+NdE0xtRAVb8Eaup532Rz3tUkzqZJMMbUQkTigdOB22tYPQ/oqar53s2ot4D+NbzGPvUPDpf+iPXZXFDJU18WMbZrHNtXzN8j7sOS4bDRsHnJPDYvCW2c9YmUzztYJMYMsRV3zCR4hTbIijEmjMT5oMgSPGNMzU4G5gX3Ba6iqjuDnr8vIo+JSIaq5lTbbp/6B4dLf8T6XP38HBIDpfzj0qPp0CoxYuKuLhLjjsSYIbbijvommkkBmwfPGBN+AtZE0xhTu/OppXmmiHTy+g4jImNw13JbWzC2kPtqeQ4fL9zMDcf0o0MrGx3TmOqivgbP7xOSAn4KbZAVY0wY8fugtNQSPGPMnkQkBfgJcG3QsusAVPUJ4FzgehEpB4qAiaqqoYg1FMorKrnnnYV0b5fElWN7hzocY8JS1Cd44ObCsz54xphwErA+eMaYGqhqAZBebdkTQc8fAR5p6bjCxXNfr2LJ5jyeuGikDaBiTC2ivokmuH54hZbgGWPCiE2TYIwxjZO1fgcP/HcJxw/syIkHdQp1OMaErZhI8JLj42wePGNMWAkIlFXETKsqY4zZL4Wl5dz4yre0TQnwwLlD8bohGmNqEBtNNOP9FFgNnjEmjPh9Qmm53XgyxpiGuHvaQlbmFPDiVYfQLiU+1OEYE9ZiogYvJcFq8Iwx4SXgg9KKSmJobARjjNkn7y3YyKtz1nL90X05vG9GqMMxJuzFSILntz54xpiwEueVvtZM0xhjardueyG3vbGA4d3bcMtPDgh1OMZEhJhI8JLj46yJpjEmrMT5XP+RUpsLzxhjalRUWsFNr8xHFR6eOIKAPyYuW43ZbzHxTUmJ91sTTWNMWKmqwbORNI0xZm8FJeVc/txs5q3Zzl/PGUqP9ORQh2RMxIiNQVYS4igstRo8Y0z4CFiCZ4wxNdpZXMblz37D/LW5PHTecE4Z2jnUIRkTUWImwSurUErLK4mPi4lKS2NMmNvdB88SPGOMqZJbWMolz8xm4YadPHL+CE4eYsmdMY0VEwlecrwfcNX98XE2tK4xJvTivDmcSqwGzxhjANhWUMpFT81i+ZZ8nrhoFMcP6hjqkIyJSDFRnZWS4PLYAmumaYwJE9YHzxhjdquoVK6fPJcV2fk8deloS+6M2Q8xUYOXEu/eZqENtGKMCRO7EjxrommMMTyeuZxZK7fxtwnDOOqA9qEOx5iIFhM1eMkJrolmvk2VYIwJEwFvmgTrg2eMiXVzV2/nn58s4/RhXThnZNdQh2NMxIutGrwSq8EzxoQHa6JpjDFuxMybXvmWzq0TufeswYjXP9mYBqmsgJylULwTKstBK9y/gWToOgr8gb33UYUN38KKT6G8FNDd61p3hwGnQkp6i72F5hAbCZ5Xg2d98Iwx4cISPGNMrFNV7ngzi407iply7WG0SqzhYjyWqELJTvDHgz8BfCFuaFdeCj9mQoeB0KZ7yx67ohxWfQHLPnGfQ3I6JGe4fytKYP08WD8XNsyHsoKaXyOxNfQ/EQaMh37Hk1i0Gb54EBZMcUkhAN4NBRH3+aPw7i3Q9xgYfA4MOAXiEqFwGxRuhcIcl0xWlLpHeQlUlLnX8PlA/ODzQ3wKdBoG7fo0/DyqutdqggEhYyPB29UHzxI8Y0x4sD54xphY9/q89Uz7bgO3/uQARvVsG+pwQmvdHJdYbFqwe5kvztVEDZsIx97hEpa6FOXCpu/da+RvhqEToeOgxsdSXgLfToYv/wk71oL4XKIz5hrodWT9+5fkwaYsKNoGRdt3P1QhIRXivUdCKiSkQXya+zchzSVeC9+CRe+4hCou0YupeM9j+OOh0xAYcaGrqUtp7xIrX5x7FGTDkv/C0g/g+yngC3BopZeI9TwCDvs5DDodkoL+36m6zy/rdch6A966HpcAKvssoTV0GQZdRrr3HPx5FOe6z6p4p0vsS/Kg5+Fw2bv7fjxPTCR4u/vgWRNNY0x4iPP64FkNnjEmFm3JK+bOt7M4pHc7bjimX6jDCZm4sjx45yaYOwnSOsGxf3AJVXmJq6nauQG+eQoWvg0n/tnVKlU1Yy0vdc0Mf3gT1s6G7St3v7D44at/uRqsI25yiYMIlBbA8k9h8Xuw5mto1dXV0HUY5B5bFrrEbud66HYwnHCva844b5JLutoPpHvawbBgC6RkuFq1pLaQswRWTodVX7rttdo1t/jd8SsbUNkSSIEDT4aDzoJ+x0EgycVduBUKctw2HQ+CuIS6X2fgaa4J59pZsPS//LhhG33O+A206VHz9iLQeah7HH+XqyFc9pFr5pmcvvuR0Molnv6Ai8Hv1bhVVnhNRCtcArdxvqtp3DAPZjzi3nt8qvu8ktpAYhto22t3cpuQBulN812IiQRvdx88q8EzxoSHgDXRNMbEsFdnr6WgtII/nz0Evy/K+t1lvQGz/g19xsHIS6B1DQPHlOTDD28wZvbvobwADvsZjLvNXeRXd+j1rnbv9Svh2xdg9JUu8Vg0DYp3uISh11gYcRF0Hu4SFF+cSwxnPQHPjXfJWkp7WPE/VxuW1NbVxhVkuxqr4md2H6/7oXDGI9DnGJf0HHSmiy3rdZj1b/r++Dz8+PzecfrioOtoGHsLdD8EUjt4yUzb3e+rvARK811tVWm++xxK8lwNVmm+Sxirkrpg8SnuUVtyVhuf3yW3PQ9nTWYmfRq6vwh0G+0e+6JNd3ceRl7i/i4vdf+20HzcMZHgJQX8iECBTZNgjAkT1kTTGBOrKiqVl2ev4Yh+6fRtnxrqcJpOZSVk/tn182rVFT7/K3zxgKtFG3357gTrx0xYMxMqyyhqdSDxFzztmhvWpssIuOpTmPMMfPon+PFiVxM04FRXo9dnXM2Jw9G/cU0R578IMx+HvM0w6jLX3LLH4eD30gBVyNsImxe6ZpPdD9ldS1glkOQSyBEX8eXH7zB2xABXm1aQ7WrW2vZ0+8Wn1P0ZBRLdIyWj4Z9rNGihxG7X4Vr0aCHi8wnJAT8FVoNnjAkTcTZNgjEmRv1v8RY27CjmD6fuQ/+wpqTqms2Vl+weMCOQ5JrP1WTrClj8LmxbCQecCH2P3d1MsCQf3rzWrR9xEZzyD5c0zZ3k+rMt/WD363QaAofdAH2P5dvVlYyrK7mr4vPDmKth0BmwOQt6HLZ3LVdN4pPdfmOurn0bEWjVxT0aoDyQBhn93cOEpZhI8ACSE+JskBVjTNiI826OWhNNY6KPiPiAYUAXoAjIUtUtoY0qfLw4azUd0hI4flDHlj947hpY+iEs+xhWTYeywr23adMTugyHzsNcv7QN813itjnLrQ+kwNxn3QAaA0+F/j+Bzx+E7EVw0l/hkGtd0tS2Fxx/J4y7HZZ9CGXF0Odo13SxyprMxsWf2gFSj93Xd29iRMwkeKkJcRTYICvGmDBR1USzxBI8Y6KGiPQFfgscDywDsoFE4AARKQT+DUxS1Zj94q/dVsjnS7P5xbH9CfhbaBqA7CWw4FU3sEj2YresbS8YfgGkdnSDZMQlumZ0Rbmw8Ts3QMbCt70XEFdjduJfXPPGVl1cM8us193AI/NfdCNcXvS6q9WrLi7eDfhhTAuJmQQvOd5vNXjGmLBRleBZE01josq9wOPAtaq6x9jqItIBuAC4GJgUgtjCwouz1uAT4fwxzTyvWt5ml4AteNUla+JzA5GMvAT6n+BGK6xvUvWi7bBlkds2uNYNXK1d/5+4Wrk1X0PGgTUPpmJMCDRbgici3YHngY64CSSeVNV/VdtmHPA2UDWu6xuqek9zxJMSH0e+9cEzxoQJnwgBv1gTTWOiiKqeX8e6LcBDLRhO2Ckpr2DKnLUcN6ADnVs3oP/YvijcBp/dB3OedUPWdx7uat4GnwNpjWwSmtTWjcBYl0BizbV2xoRQc9bglQO3quo8EUkD5orIx6q6sNp201X11GaMA3Bz4W0rKG3uwxhjTIMF/D5L8IyJYiLSD7gLSAL+pqozQhtRaP03axPbCkq56NCeTf7aUlkOM5+AzL+4IfdHXe4m5u4woMmPZUy4a7YET1U3Ahu953kisgjoClRP8FpESkIca7fV0JHWGGNCJD7OZ9MkGBNFRCRRVYuDFv0J+I33/B1geMtHFT4mz1xNz/RkxvbbjyHyKyth2woo3gmleW70ysKtjJ7zABSug95Hw0n3Q8cQj9BpTAi1SB88EekFjABm1bD6MBH5DtgA/EpVf2iOGFLi/TbIijEmrMT7fdYHz5jo8o6IvKCqVbNAlwG9cF1VYvoiZPGmnXyzaju/Gz8A375ObL55Ibx7M6zd+3LSl9gJJr4EB46vv2+dMVGu2RM8EUkFXgduVtWd1VbPA3qqar6IjAfeAvaaVENErgGuAejYsSOZmZkNOnZ+fv6ubbdnl7CjsLzB+4ZScNyRJBLjjsSYweKOFgG/z0bRNCa6nARcLyL/Bf4M/Aq4EddE88JQBhZqL89aQ3ycjwmj9mFwlbIiN3n4V/+ChFZuKoJ2vd1k3wmpEJ/K7O9WcvSA45s+cGMiULMmeCISwCV3L6rqG9XXByd8qvq+iDwmIhmqmlNtuyeBJwFGjx6t48aNa9DxMzMzqdp2TskS/rd2BUcffTQS5nd2guOOJJEYdyTGDBZ3tEiIsz54xkQTVa0AHhGRF4A/ANcDd6jqitBGFlqqyieLtjDugPa0TYlv3M4rPoP3fgnbfoRhF8AJ90JK+t7H8K1tomiNiXzNOYqmAE8Di1T1H7Vs0wnYrKoqImMAH7C1OeJJTvBTUamUlFeSGPA3xyGMMaZR4i3BMyaqiMghwK+BUlwNXhFwn4isB/6kqrmhjC9UVm0tZH1uEdeN69vwnfI2wYe/h6yp0K4vXDLNTRJujKlXc9bgHYGb6+V7EZnvLfsd0ANAVZ8AzsU1ZSjHFYITq88b01RS4t1bLSgptwTPGBMW4uOsD54xUebfwHggFXhWVY8AJorI0cCrwImhDC5UvlzuGmY1aHCVinKY8zT8714oL4ajb4Oxt7jpCIwxDdKco2h+CdTZFlJVHwEeaa4YgiXHu6SusLSCvSv2jTGxqrY5O0WkHe6CrBewCvipqm5vymMH/DaKpjFRphxXZqTgavEAUNXPgc9DFFPIfbksm65tkuiVnlz7Rqqw+iv47+2waYGbW2783yC9EbV+xhighUbRDAepCV4NXqlNdm6M2UONc3YClwGfqur9InIbcBvw26Y8cLzNg2dMtLkAuBaX3F0S4ljCQkWl8vWKrYwf3LnmMRBUYfmnMP1vsGYGpHWGc5+Fg86y0TCN2Ucxk+AlJ+xuommMMVXqmLPzDGCct9kkIJOmTvDifBQWxfTI6cZEm2WqemtdG4iINFd3lHD0/fod5BWXM7Z/teaZqrDkA/j8r7BxPrTqBic/CCMvhkBSaII1JkrETIKX4jXRtLnwjDG1qTZnZ0cv+QPYhGvC2aQCVoNnTLT5TEReB95W1TVVC0UkHhgLXAp8BjwXmvBa3pfLsgE4vG9QB5myYnj/Vvh2MrTrA6f/HwydCHGNHGHTGFOj2EnwvBq8QmuiaYypQfU5O4ObEnkj/dZ4x31/5uncsb2Y3LzKiJkbMFLnMbS4W04kxgxNGvdJwBXAyyLSG8gFEgE/8BHwkKp+2xQHihRfLs9hUOdWpKcmuAW5a2HKxbDhWzjqN3D0b8EfM5ejxrSImPlG7R5F02rwjDF7qmXOzs0i0llVN4pIZ2BLTfvuzzyd3Tq3YVPptoiZGzBS5zG0uFtOJMYMTRe3qhYDjwGPeeVKBlAUq9MjFJaWM3f1dq44ordbsPILeO0yqCiDiS/DgPEhjc+YaOULdQAtJTnBa6JpNXjGmCB1zNk5DdecCu/ft5v62PF+H2XlMdMVx5iYoqplqrqxMcmdiBwoIvODHjtF5OZq24iIPCwiy0VkgYiMbProm8bsldsoq1CO6JsOMx+H58+A5Ay4+n+W3BnTjKwGzxgT62qbs/N+YIqIXAmsBn7a1AcOxIlNk2CM2UVVlwDDAUTED6wH3qy22clAf+9xCPC492/Y+Wp5Dol+OHzpAzD3PzDgVDjrCUhIC3VoxkS1mEnwEgM+fGJ98Iwxe6pnzs7jmvPY8X6/DbJijKnNccAKVV1dbfkZwPPeSJwzRaRNVXPylg+xbrOXrmNy2sPEzZ0Jh/8Cjr8HfDHTeMyYkIneb1nxTlrnLoQKl9CJCCnxceTbNAnGmDARH2ejaBpjajUReLmG5V2BtUF/r/OWhZWcTWu4Z/tvGVk8201YfsK9ltwZ00KitwZv4duMmH87HHkipPcFXD+8QmuiaYwJE/FxPkorKlHVmicANsZEFBHJA4I71iqQg5sa4bequrWBrxMPnA7cvh+x7PMIv/s7omhCcQ6D5txGf9nJ//r8lrjC/tDMo6vaCK4tJxJjhtiKO3oTvPYD3L/ZS3YleCkJcTbIijEmbMT7XVJXVqHEx1mCZ0ykU9W9OpeJSFvgMuAJYEIDX+pkYJ6qbq5h3Xqge9Df3bxl1WPZ5xF+92tEUVV44SxKKvO5TO5m8kXX4fc1f/kW6yO4tqRIjBliK+7orStvf4D7N3vxrkVpCXHsKCoLUUDGGLOn+DhXBNtAK8ZEL1Xdrqr/BPo2Yrfzqbl5JrgRfi/xRtM8FNgRVv3v5j4HP37Gw76LadNvTIskd8aYPUVvgpfYmpL4dpCzdNei7u2SWbOtMIRBGWPMbvF+VwSXWT88Y6KaNydeg1pNiUgK8BPgjaBl14nIdd6f7wM/AsuB/wA3NG20+2H7avjoDgq7jeWx/KMY2z8j1BEZE5Oit4kmUJDSnYSgGrzeGSl8kLWJ0vLKXXfOjTEmVAJWg2dMVBGRs2tY3BY4D5jakNdQ1QIgvdqyJ4KeK/Cz/QizeVRWwts/A4RpPW5Hl+/gqP7tQx2VMTEpqhO8wuRutNuS6Qodn4/eGSlUVCprtxfSt31qqMMzxsS4qho8G0nTmKhxWrW/FdgK/EtV3wtBPC1nztOwajqc9jBvzfUzoFMa3dslhzoqY2JSlCd43aGsAHauhzbd6ZWRAsCqnAJL8IwxIVfVkqDEEjxjooKqXh7qGEJi6wr4+I/Q73hyB0zkm9c/5fqjG9Pl0BjTlKK6nWJBSg/3JHsJAH28BG9lTkGoQjLGmF0SvASvzJpoGhMVRGRK0PO/Vlv3UctH1AIqwo+OLwAAIABJREFUK1zTTF8ATnuYzKU5VFQqxw/qGOrIjIlZUZ3gFSZ3c09yXILXJjmeNskBfrQEz5ioJCLp9W8VPgLWRNOYaNM/6PlPqq2Lzg5pX/8frJkB4x+A1l35eOFm2qclMLRr61BHZkzMiuoEryy+NSSn7zFVQu+MFFZZgmdMtJopIq+JyHiJgJnDbZoEY6KO7uO6yLQpCz67DwaeDkPPo6S8gs+XZnP8wA74bHoEY0ImqvvgAW7Cc6+JJkDv9BRm/Lg1hAEZY5rRAcDxwBXAw15zqedUdWndu4WGTZNgTNRJFpERuBvoSd5z8R5JIY2sqZWXwBvXQGIbOPUhEGHWj9vILynn+IHWPNOYUIr+BC/jAPjhTVAFEXpnpPDGt+spKq0gKd4f6uiMMU3IGz78Y+BjETkGmAzcICLfAbep6oyQBljNrkFWrAbPmGixEfiH93xT0POqddHjs/tgyw9wwRRIca3jP1m0maSAnyP62fx3xoRS9Cd47QdAcS7kb4G0jrtH0txawMDOrUIcnDGmKXl98C4CLgY2A78ApgHDgdeA3qGLbm/WB8+Y6KKqx9S2TkQOaclYmtXqr+Grh2HUZXDAiQCoKp8s3MyR/TNIDNgNdGNCKar74AHQ/kD3rzfQSu+gqRKMMVFnBtAKOFNVT1HVN1S1XFXnAE/Us2+LqxpF0xI8Y2LCa6EOoEmU5MGb10HbXnDCfbsWL9y4kw07im30TGPCQOwkeF4/vKoaPBtJ05iodIeq/klV11UtEJEJAKr619p3C414mybBmFgSHaOOzJ0EuavhrCcgYfecwp8s3IIIHDugQwiDM8ZALCR4aZ0hodWukTRTE+LokJZgNXjGRKfbalh2e4tH0UDWRNOYmBIdo2gu+xA6DIIeh+6x+JNFmxnZoy0ZqQkhCswYUyX6++CJuFq84JE0M1JssnNjooiInAyMB7qKyMNBq1oB5aGJqn42TYIx/8/efYfHVV6JH/+eaRr1ao0sWXKVuzEGYWwwoNACCQQSsgTSK4EksCmbzWazaWST3V8KCYQASxIgDUKAECBUUwSYjg0G995tyVYfldGU9/fHO5JluUm2pKs7Op/nuc/MvXPvzJFg5Dlz3ve8qUVEHuHQiZwArlqn85AirbD1FVj4pQMO727u4N2dzXzrgukOBaaU6i31EzyAommw/qme3YlFmSxeVetgQEqpQbYLeBP4ALC01/FW4GuORNQPAZ2Dp1Sq+fkxPuYOm56HRBSmHLiG+zOr6wA4b6YOz1RqJBgdCd6YafD2n6G9ATIKmFiUSX1bF80dUXLT/U5Hp5Q6TsaY5cByEfmLMWbEVuz66l4HTyt4SqUGY8zzTscwpDYshkD2IYdnTijMYPKYrMNcqJQaTqk/Bw/sUgkA++xaxxO0k6ZSKSW5oDnAWyLyTt/N0eCOIKBz8JRKKSJSKSJ3isgNIjJORB4XkbCILBeRU5yO77gYA+sXw+Rq8O7/cjwWT/D65gbOnDoGkdToI6OU242SCt5Ue7t3LVQsYFKvtfDmluc5GJhSapD8a/L2IkejGCCPR/B5RBM8pVLHncAfsfN/XwO+CnwQOAO4GXDvWnh1q6FlJ5z1rQMOr9nTSntXnKoJBQ4FppTqa3RU8HIrwJfe02ilvCADEdi0Vyt4SqUCY8zu5N1MY8zW3hsjbHHzvgI+jy6ToFTqyDLG3G6M+TnQYYy5zxjTaYxZDLi7vWR3L4PKA+ffLd3aCMDJ4/OHOyKl1GH0K8ETkUwR8STvTxWRD4iIeyaveTy2ipdcKiHo91KWl86Wek3wlEoxfxORb4mVLiK/Bv7H6aCOJODzaAVPqdTR+83ccoTH3GfD0xCaDTmlBxxeurWRsblByvLSHQpMKdVXfyt4LwBBESkDngI+Adw1VEENiaJpPXPwQJdKUCpFnQqUAy8Db2C7a57uaERH4fd6tMmKUqljenLu77u97nfvT3M6uGPW2QLbXjmoegc2wTtJq3dKjSj9nYMnxph2EfkccIsx5qci8vZQBjboxkyDd/8GkTCkZTGxKJMH39qJMUYnBSuVOqJAB5AOBIHNxpgRnT0FvB4iWsFTKlXMcDqAIbGpBhKxg5ZH2N3cwc6mDj63aESPhFdq1OlvBU9EZCHwMeDR5DHv0IQ0RMYkvzjr7qRZmElrZ4z6ti4Hg1JKDbI3sAneKdimBleKyH3OhnRkaT4P0fih1kVWSrlN3znAh5gT7E7rn4K0HCiff8Dh7vl3VRO0gqfUSNLfBO+rwLeBB40xK0VkEvDckS4QkXIReU5EVonIShH510OcIyJyk4hsSA5hOGngP0I/dS+VkGy0MnGM7aSpwzSVSimfM8Z8zxgTNcbsNsZcAjzsdFBH4vd66IrFnQ5DKaUOzRg7/27yew5YHgFsghf0e5gxNseh4JRSh9KvIZrJhTufB0g2W9lnjLnuKJfFgG8YY5aJSDawVEQWG2NW9TrnQqAyuZ0K3MpQtRDOnwgef0+jlYmF+xO8U7S1r1KpYqmIfByYZIy5XkQqgLVOB3Uk2mRFKTWi1a6A1t0HDc8EWLa1kbnj8vB7R0dTdqXcor9dNO8WkRwRyQRWAKtE5JtHuib57fmy5P1WYDVQ1ue0S4A/GutVIE9Exg74p+gPrw+KKu0fKmBcfjo+j2gFT6nUcguwELgyud8K/Ma5cI4uoEM0lRoVRKTQ6RiOyfrF9nbKuQcc7uiKs3JXiw7PVGoE6u9XLjONMS3ApcDj2HWlPtHfFxGRCcA87KKfvZUB23vt7+DgJHDwTKqGzS9CpBWf10NFYQZbNMFTKpWcaoz5MtAJYIxpBALOhnRkAa9W8JRKVSKyMTkVZT7wotPxHJP1i6FkDuQc+P378h1NxBJG179TagTqbxdNf3Ldu0uBm40xURHp11fOIpIFPAB8NZkkDpiIXAVcBRAKhaipqenXdeFw+IBzczvHMS8eYeVDv2Jv8Rlk08m7W9r7/XzDpW/cbuHGuN0YM2jcRxAVES9gAERkDCN87Sm/z0N7R9TpMJRSQ8AYM1lEvga8AnzG6XgGLB6FHa/Dgi8d9FB3g5WTKjTBU2qk6W+C93/AFmA58IKIjOfgBTwPkkwKHwD+Yoz5+yFO2Ylds6rbuOSxAxhjbgduB6iqqjLV1dX9CrqmpoYDzk2cAet/ySzZCNXfZUl4FX9+bStnnnkWHs/IWSrhoLhdwo1xuzFm0LiP4CbgQaBYRH4MfBj4r6F8weOlFTylUoeIPAV8obtjpogsAK4GvghcBPzRwfAGrmmbXR6h+ODVH5ZubWRKcRZ5GSN6kIRSo1K/hmgaY24yxpQZY96XnC+3FXjPka4Ru7jc74HVxpgbDnPaw8Ank900FwDNxpjdA/kBBsTjhekXwbqnINrJhKJMOqMJ9rR0DtlLKqWGjzHmL8C/A/8D7AYuNca4YJkETfCUShHFvZK79wN3ABcbY36Hnd7iLvUb7G3B5AMOJxKGZdsaOVmrd0qNSP2q4IlILvB94MzkoeeB64HmI1x2Onae3ru9FkX/T6ACwBhzG/AY8D5gA9DOcAxfmHExLL0TNj3HpKJTANi4N0xpXvqQv7RSamiISO9WuHXAPb0fM8Y0DH9U/aNdNJVKKRER+RR2dNK1wDxjzC4RyQEynQ3tGNRvtLeFUw44vGlfG03tUU7WBitKjUj9HaJ5B7Z75uXJ/U8AdwIfOtwFxpglwBHHPRpjDPDlfsYwOCacAcFcWPUwsy6wHaHe3tbEGZVjhjUMpdSgWoqdd3eovzkGmHS4C0XkDuzQqTpjzOzksR8AXwD2Jk/7T2PMY4MZcDe/VzTBUyp1fAz4D6AL+Clwh4i8jO0a/lsnAzsm9RvsZ6aMA5eTWrrVfmemDVaUGpn6m+BNNsZc1mv/h72qcu7iC8DUC2HtY+R+4CYqi7NYtq3R6aiUUsfBGHM8Q5/uAm7m4LkxvzTG/Pw4nrdfAj4PXTpEU6mUYIzZAHy+e19EngXOBb5ljHnascCOVcNGW72TA787W7q1kfwMP5OK3FeUVGo06O8yCR0isqh7R0ROBzqGJqRhMONi6GyCLUs4qSKfZduaSCR0HSqlUoGIfEhEbhCRX4jIpUc73xjzAuDYEM6A10tUK3hKpSRjzFvGmJ+5MrkDO0Szz/w7sAneyePzERk5DeqUUvv1N8G7GviNiGwRkS3Yb7u/OGRRDbXJZ4M/A1Y/wsnj82nuiLJJ18NTyvVE5Bbs36t3scPKrxaRY13o/Csi8o6I3CEiQzYOye8TIlrBU0qNNNEOaN5x0Py7xrYuNu5t4yQdnqnUiNWvIZrGmOXA3OQkYYwxLSLyVeCdoQxuyAQyYMq5sOafnHTK9wFYts22+1VKudrZwIzk/F5E5A/AymN4nluBH2Hn7/0I+AXw2UOdeLzrdO7e0UVXLMFzzz034r8N1/UXh5cb43ZjzODeuIdUw2bAQOGBFbzuaS1V4wsOcZFSaiTo7xw8wCZ2vXa/DvxqcMMZRjMvgdUPM6lzNbnpfpZtbeTyqvKjX6eUGsk2YDv1bk3ulyePDYgxprb7voj8FvjnEc49rnU6VyTWw8Z1LDrzLPze/g6qcIauvzi83Bi3G2OGwY9bRC4GHjXGuLc839DdQfPABG/FzhZEYHZZjgNBKaX643g+TYzsr5qPpvJ88AbwrHmEeRV52mhFqdSQDawWkRoReQ5YBeSIyMMi8nB/n0RExvba/SB2uOeQCPjsn2HtpKlUSvkIsF5Efioi050O5pgcZg28dXWtVBRkkBEYUI1AKTWMjufd6e6uJMEcmFQNqx/m5NmfombtXpo7ouSm+52OTCl17L430AtE5B6gGigSkR3YNT+rReRE7N+5LQzhnOPuql1XLEFm2lC9ilJqOBljPp6c1nIlcJeIGOzyUvcYY1qdja6f6jdCZrH9vNTLuj2tTA1lOxSUUqo/jpjgiUgrh07kBHD/yuAzLob1T/Ge4Fp+gYe3tzdx1lRdD08pNxIRL/ADY8x7BnKdMebKQxz+/eBEdXQ9FTxttKJUSkn2K7gf+3npq9jRAN8UkZuMMb8+3HUikgf8DpiN/Qz2WWPMK70erwYeAjYnD/3dGHP9oP8A9RsPGp7ZFUuweV8b588KDfrLKaUGzxGHaBpjso0xOYfYso0x7q/Nz7wU8icw89VvEJJGlm3VYZpKuZUxJg4kRCTX6VgGIuDVIZpKpRoR+YCIPAjUAH5gvjHmQmAu8I2jXH4j8IQxZnry/NWHOOdFY8yJyW3wkztIroF3YIK3eV8bsYTRCp5SI5z7k7TjEcyBK+7G87tzuTPj1/xs68+BqU5HpZQ6dmHgXRFZDPSsfWKMuc65kI5MK3hKpaTLgF8m19nsYYxpF5HPHe6i5BdUZwKfTp7fBXQNYZyH1tkC4dqD5t+trbWjS6eVaIKn1Eg2slu2DYfQLLj0VmbG1/D+7TcQ1w9ZSrnZ34HvAi8AS3ttI5ZW8JRKST8AXu/eEZF0EZkAYIx55gjXTQT2AneKyFsi8jsRyTzEeQtFZLmIPC4iswYv7KSGTfa2zxp46/a04vUIE4sOFZJSaqQY3RW8brMuZc3bV/Hh9bezp+ZWSs75stMRKaWOgTHmDyKSDlQYY9Y6HU9/dFfwovrlklKp5D7gtF778eSxU45ynQ84CbjWGPOaiNwI/Af2i6tuy4DxxpiwiLwP+AdQ2feJjmeNzlUvvsBM4I1NDbTV7b/u5ZWdhNLhlSUv9uu5hpNb1zJ0Y9xujBlGV9ya4CUFz/suz655neol34Mp82D8aUe/SCk1oiTXnvo5EAAmJjthXm+M+YCzkR2eLpOgVEryJYdXAnaopYgE+nHdDmCHMea15P792ASvR+81iY0xj4nILSJSZIzZ1+e8Y16jc2Z2EFbDKe/9CPj399T7wRvPMW9SLtXVJ/XruYaTrsE4fNwYM4yuuHWIZtL4Mdn80P816v0l8Jd/geV/dTokpdTA/QCYDzQBGGPeBiY5GdDR+HWIplKpaK+I9HyxJCKXAPuOcD4Axpg9wHYRmZY8dA52Pc8eIlIiIpK8Px/7Wa5+sAIH7Bp4OeMOSO46o3G2NrRTGcoa1JdSSg0+TfCSRITK8eP4su+HUHICPPhF+PtVdqKxUmpg4lHY68gIyagxprnPsRGdOXVX8CI6RFOpVHI18J8isk1EtgPfov/raV4L/EVE3gFOBH4iIleLyNXJxz8MrBCR5cBNwBXGmMFdm/gQSyRsqAtjDEzTDppKjXg6RLOXk8fn8/9W19Jwzd8pWHoTPP+/sP11+PDvoexkp8NTamRr2QXrF8P6p2DT8+D1wzc3gMc7nFGsFJGPAl4RqQSuA14ezgAGqrvJSlQreEqlDGPMRmCBiGQl98MDuPZtoKrP4dt6PX4zcPNgxHlY9Rtg9ocOOLR2j+2gWakJnlIjniZ4vZxUkQfAWztaOKf6WzDxTHjg8/D78+HCn8Iph+1srFTqa9wKW5bYrXm7rdIlYpCIQiRs10wCO6xnzmUw5TwY5C+V++Fa4DtABLgbeBL47+EOYiDSdJkEpVKSiLwfmAUEkyMqGbI16waRL9oCnU0Hd9CsayXg9TChMMOhyJRS/aUJXi8njMvD5xGWbWvknBkhGL8Qrllih2o++nVo3ALn/hA8OrJVudDOpdBaCx6frap5fICBSKsdihxpsbexjv3JWzwKnc2w/TWb1AGkF8CY6eALgCfTPk9eAE7+lE3qimdA8sPMcBGRIHZI1BTgXWChMSY2rEEcI52Dp1TqEZHbgAzgPcDvsMMqXz/iRSNERvsue6fPGnjr9rQyuTgLn1c/Ayk10mmC10t6wMvM0hyWbm3sdTAfrrgHHv93ePkmaNoGH7ztgInHSo1oDZvhye/A2kf7d77Hb4dXenx282dA2Ulw2nUwYZFN7kbelxx/AKLAi8CFwAzgq45G1E/aRVOplHSaMeYEEXnHGPNDEfkF8LjTQfVHekcywetbwasNUzUh34GIlFIDpQleHwsmFXLnS5tp7YySHfTbg14fvP8XUDARnvovaN1tk77MQmeDVQqgaTtseg4yiiA0E3IrbALW1QZLfgkv3WQTtXO+B5PPhkQiObQyBhhIy4a0HAjm2vtev9M/0bGYaYyZAyAiv8cl35SDroOnVIrqTN62i0gptsvlWAfj6beM9l0gXsgf33OstTPKzqYOPhqqcDAypVR/aYLXx7kzQtz+wiZeWLeP95/Q62+xCJx2LeSW2w6bv62Gi34JU851LFaVIoyxHcu2vWKHQgayYNqFdi3GwyRb6e074cUbYPXDsOutAx8MZNlhki27oGUnzLkczvsh5JQOww/jmGj3HWNMTIZ5iOjx6OmiqRU8pVLJIyKSB/wMuzC5AX7rbEj9k96xyyZ3vf79WV9ne8RM1QYrSrmCJnh9nDw+n/wMP4tX7Tkwwes261LIHWeTvD9fBrM+BBf8D2SXDH+wamQxBjoaoWGTTdiat9v9jiZ729lkz/OlgS9ob6OdsOMNaE8uj5SeD9EOeO1WW1GrPB8mVUN7g+1q1rAJ6jdwautue37ZyXDuD2DqhXYuXd1KqF0FdaugYBJc9ns7lzT1zRWR7jVNBEhP7gtgjDE5zoV2ZN1dNLXJilKpQUQ8wDPGmCbgARH5JxA8xBIuI1J6xy4oOXB45vpa20FTl0hQyh00wevD6xHOnh5i8ao9ROOJngYIBxhXBde8DC/dCC/8HDY8DWd/F6o+a4dzqtTRvMNW1cJ1Nslqr4eOBptMxbtsE5J4FGIRaN5mG5L05s+wSVt6PgTzbCU40gpte21yJx6oPA8qFkDFQiistE1ONj4Hax+DdU/Au/fZ58oosusSTT6b9eEMKi/+qv2yobfyU4bn9zLCGGOGdS2GwbR/mYRh7ziqlBoCxpiEiPwGmJfcj2A7+458xpDRvhsKLzjg8No9YdL9Xsbla/8BpdxAs5FDOG9miAeW7eCNLQ2cNrno0Cf50uCsf4fZl8Gj34DHvwnP/djOcZpyLkw5R6t6TopFbEKWUWD/W/XW1QZ1a6B2BRM3vQj+5TZ5yii0W/M22PyC3Ro27b9OPDZRyyi0wyB9afubkHgDUD7fJmAFk+yWV3FszXgCmTDjIrsl4rBvPWSH7Gsn7aypobJvcqdcyeMRfB6hKx53OhSl1OB5RkQuA/4+6IuQD6XWPXgTnQctcr6utpXKUBYej3uGvys1mmmCdwhnVBYR8HlYvKr28Alet8LJ8IkHbaVl9SO2mrfy7/ax4pm2++DYE2HsXAjNsh/e1eAwxlbWGjfbRGzfOti71m6Nm8Ekh7wFcyGzGDKL7PkNm7DTIaACgW33HfzcaTkw/nQ45Qsw4XQ79zKYN/zdIz1eKJ4+vK+php3f69Eumkqlli8CXwdiItKJC4aLA/vXMz1Egnfm1DEOBKSUOhaa4B1CZpqPRVOKeHp1Ld+7aCZHbdggYptiTLvQJh21K2yit/lFWPs4vPXn5HkeyCmzlb2sEGSPtfezx9oGGDml9r6Top1g4kOXiMa6bPJVv8FWppp32IncvqCtdvnS7GunJTs6BnPs8dY9dqHtpq32tnGL3aJt+5/b47f/KJXMtpXV7BC0N0JbnU3s2vbZJPuEy+1taBbPL99C9Wmn2KGX7fXQVm8rdGPn6nBbNWwCPk3wlEolxhh3Tlar32Bve62B19jWRV1rhKmhLIeCUkoNlH6CPYzzZoZ4dk0da2tbmV4ygC/cRKBkjt0Wfc0mfC27YPdyuzVttcss1G+ALUv2N97o5XRfNmw50T5HMhEhs9gmPIGsY68ixZONBvt2Zox2JCuPD8LaJyDWCaXzYOIZdt2z8lNtYtay0/4srbvsXDNvwG4eH3gDhPasheW1NpEVsc/TvMO28W/aapuONG23CWS3tFy7H+tMtu0/Cn8G5E+AvPEw6SzIn2iXr8ifeFDXr36RbcllArLt8yrlgIDPQ1fcPaO4lFJHJiJnHuq4MeaF4Y5lQOo3khA/nl5TANYlG6xoB02l3EMTvMM4Z3oxAE+vqh1YgteXCOSW2W36+w5+PNphE76WXdCyG1p2snflEkq76uHNO23DjQOf0CYj6fl22GBe+f7b/Al27ld26f4ksHUPrH/KJm6bnrOvlzkGcsba87w+29CjK2wrVydcbuetbVkCL//arqPWTzMA1hzigeyxdj5aWZVt2V84JblNhvS8/efFY/bn7WqzjUg6WyDSDF3tttKZN94Os3RRC3yl+iOgQzSVSjXf7HU/CMwHlgJnOxNOP538aVa05nKCZ3/fqnXJJRKmlWiCp5RbaIJ3GMU5QU4sz2Pxqlq+cnbl0L2QP31/U46kdbETKa2utg02GjbblvcdDcmEpxUiLXa4YfMOOwy0ddf++WYA3jRb1fL6Yc+79ljOOJh7pU3uWnfZxK95h32u2ZfBrA/ChDMOHJbY1QbbXoWdS21SmVNqh5jmlNp5bYlYsotkF8S7ePXVV1gwf76tWpqEfa6csoObnByO1wfeZDVNG9SoUcRW8DTBUypVGGMu7r0vIuXArxwKp/8KJ9NQWHXAoXV7WslO81GSE3QoKKXUQGmCdwTnzQzxsyfXUtvSSciJP2weLxRNsduRxKO2Ati4xTYQ6d4iLXb5hqkX2GGeA618BTJtN9Ap5/Tr9M70LQdNzFZKHV3A6yGqFTylUtkOkgNd3GZtbStTS7KP3o9AKTViaIJ3BN0J3tOra/nYqeOdDufwvH47/yw/OS9NKeUqWsFTKrWIyK/pbtcMHuBEYJlzER27DXVh3jsr5HQYSqkB0ATvCCqLsxhfmMHiVSM8wVNKuZp20VQq5bzZ634MuMcY85JTwRyreMLQ0NblzCgmpdQx0wTvCESEc2eE+NMrWwlHYmSl6a9LKTX4/F7RBE+p1HI/0GmMbRstIl4RyTDGtDsc14C0ddnu1vr5Ryl3GeZVm93nvJkhuuIJnl+71+lQlFIpKuDz6hBNpVLLM0B6r/104GmHYjlmbRGb4GVqgqeUq2iCdxRV4/MJ5aRx39LtToeilEpRukyCUiknaIwJd+8k72c4GM8xCXdqgqeUGw1Zgicid4hInYisOMzj1SLSLCJvJ7fvDVUsx8Pn9fCRqnKeX7eXHY2uGlmhlHKJgE+0gqdUamkTkZO6d0TkZKDvwrYjXjjSPUTTe5QzlVIjyVBW8O4CLjjKOS8aY05MbtcPYSzH5fJTygH42xtaxVNKDT6t4CmVcr4K3CciL4rIEuBe4CsOxzRgbZE4AFlpfocjUUoNxJAleMaYF4CGoXr+4TQuP4Ozpo7h3je3E9Nv2ZVSgyzg8xDVvy1KpQxjzBvAdOAa4GpghjFmqbNRDVy4Zw6eVvCUchOn5+AtFJHlIvK4iMxyOJYjunJ+BbUtEZ7TZitKqUGmyyQolVpE5MtApjFmhTFmBZAlIl9yOq6BaotoF02l3MjJd+wyYLwxJiwi7wP+AVQe6kQRuQq4CiAUClFTU9OvFwiHw/0+92i8CUNemnDz42/hrxva9WAGM+7h5Ma43RgzaNypxq9DNJVKNV8wxvyme8cY0ygiXwBucTCmAQtrF02lXMmxd6wxpqXX/cdE5BYRKTLG7DvEubcDtwNUVVWZ6urqfr1GTU0N/T23Pz4eXcstNRuYeuKplOalH/2CYzTYcQ8XN8btxphB4041AZ9Hm6wolVq8IiLGGAN2HTwg4HBMAxbWCp5SruTYEE0RKRERSd6fn4yl3ql4+uMjp5RjgL+9qc1WlFKDJ81rE7zkZ0GllPs9AdwrIueIyDnAPcljrtIWieHzCGk+p2f0KKUGYsi+khGRe4BqoEhEdgDfB/wAxpjbgA8D14hIDNs6+Aozwj/dlBdkcEblGO59YzvXnl2J1yNOh6SUSgEBnwdjIJYw+L36d0WpFPAt7NSSa5L7i4HfOhfOsWmLxMhM85H8Pl4p5RJD2UXzSmPMWGOM3xgzzhjze2PMbcnkDmPQGxPLAAAgAElEQVTMzcaYWcaYucaYBcaYl4cqlsH00fnl7G7u5Pl1dU6HopQaBIdas1NECkRksYisT97mD9oLxmPw6m3kNb7Tc8jvtX+KdR6eUqnBGJNIfub5sDHmw8Aq4NdOxzVQ4Uhch2cq5UJacx+gc2aEKMpK4+7XdJimUiniLg5es/M/gGeMMZXAM8n9weHxwvP/j+K6F3sOBZLDn3SpBKVSh4jME5GfisgW4HpgjcMhDVg4EtUlEpRyIU3wBsjv9fCRU8bx7JpaNtS1Oh2OUuo4HWbNzkuAPyTv/wG4dNBeUARKZpMV3txzqDvB0wqeUu4mIlNF5PsisgZbsdsOiDHmPcYY11Xw2iJx7aCplAtpgncMPrdoEul+LzcsXud0KEqpoREyxuxO3t8DhAb32WeT2bYVEnFgf4e6xvbooL6MUmrYrQHOBi4yxixKJnVxh2M6ZuFITIdoKuVC+q49BgWZAT63aCI3PbuBFTubmV2W63RISqkhYowxInLYBlDHsk5nSaOP6YkuXnviHjoyxtHUYj//PfTca8wfO3L/LLt1HUONe/i4MWYY1Lg/BFwBPCciTwB/BVzboaQtEmNs7tCu/auUGnwj95PECPf5Myfxh1e2csPiddzx6VOcDkcpNbhqRWSsMWa3iIwFDttV6ZjW6dydD2tv4tSKDJhdTWc0zg9feQJfYTnV1dMG6UcYfG5dx1DjHj5ujBkGL25jzD+Af4hIJnao91eBYhG5FXjQGPPUcb/IMOruoqmUchcdonmMcoJ+vnjWJJ5dU8fSrY1Oh6OUGlwPA59K3v8U8NCgPvuY6STEC7W2cWfQ72VCUSZra3Ver1KpwBjTZoy52xhzMTAOeAu7dIKrtOoQTaVcSRO84/Dp0yZQlJXGz59c63QoSqljlFyz8xVgmojsEJHPAf8LnCci64Fzk/uDx5dGe8Y42NOzMgPTQtmsqw0P6ssopZxnjGk0xtxujDnH6VgGwhiTrOBpF02l3EYTvOOQEfDx5fdM5pVN9by0YZ/T4SiljsFh1uysN8acY4ypNMaca4zp22XzuLVlTuip4AFMDWWzpb6Nzqhr+zEopVJIZzRBwkBWmt/pUJRSA6QJ3nH66KkVlOYG+dmTazHmsH0YlFLqAOGsCdCyE9pt7jitJBtjYEOdVvGUUs4LR2IAZGkFTynX0QTvOKX5vFx3TiVvb2/i6dWH7cOglFIHCGdNtHeSVbypoWwA1u7ReXhKjWYikici94vIGhFZLSIL+zwuInKTiGwQkXdE5KShiKMtmeBpkxWl3EcTvEFw2cnjmDwmkx8+spL2rpjT4SilXKAnwUvOw5tQmEHA62GdNlpRarS7EXjCGDMdmAus7vP4hUBlcrsKuHUogghrgqeUa2mCNwj8Xg//e9kJ7Gjs4GfacEUp1Q/RQB5kFvdU8HxeD5OLs7STplKjmIjkAmcCvwcwxnQZY5r6nHYJ8EdjvQrkJZdzGVT7h2hqgqeU22iCN0hOmVDAJxeO566Xt+iyCUqp/imZDXve7dmdFspinQ7RVGo0mwjsBe4UkbdE5HfJNfV6KwO299rfkTw2qNo0wVPKtfRdO4j+/YLpPLO6jm898A6PXreINJ9OTFZKHUFoNrx2G8Sj4PUzrSSHf7y9i5bOKDlB7Vyn1CjkA04CrjXGvCYiNwL/AXx3oE8kIldhh3ASCoWoqanp13XhcJiamhre2GUTvJXLl9G4ceTXA7rjdhs3xu3GmGF0xa0J3iDKSvPx4w/O5tN3vsHNz27gG+dPczokpdRIVjIH4l2wbz2EZjKtJAuA9bWtnDy+wOHglFIO2AHsMMa8lty/H5vg9bYTKO+1Py557ADGmNuB2wGqqqpMdXV1vwKoqamhurqaXa9tg3fe5ewzTqMkNziwn8IB3XG7jRvjdmPMMLriHvlfybhM9bRiPnRSGbfWbGTVrhanw1FKjWSh2fb2oE6aulSCUqORMWYPsF1Eur8hPgdY1ee0h4FPJrtpLgCajTG7BzuWcCQKoAudK+VCmuANge++fyZ5GX6+9cA7dMUSToejlBqpiirBG+iZh1eWl05mwKudNJUa3a4F/iIi7wAnAj8RkatF5Ork448Bm4ANwG+BLw1FEOFIHIDMgA72Uspt9F07BPIzA/z3pbO5+s/L+NE/V/GjS2c7HZJSaiTy+mHM9J4KnogwtSRb18JTahQzxrwNVPU5fFuvxw3w5aGOoy0SIzPgxeORoX4ppdQg0wreELlg9liuOnMSf3p1K/e8vs3pcJRSI1XJnJ618ACmhbJZW9uK/QynlFLOaIvEdA08pVxKE7wh9K0LpnNGZRHfe2gFb25pcDocpdRIFJoNbXUQrgPsPLyGti72hbscDkwpNZqFIzFdIkEpl9IEbwh5PcLNV55EWV46V/95GbubO5wOSSk10pQkh3An5+FNK7GNVnQenlLKSVrBU8q9NMEbYrkZfn77ySo6umJ88U9L6YzGnQ5JKTWSHLaTpiZ4SinnhCMx7aCplEtpgjcMKkPZ/OqKebyzo5mv3fs20bh21lRKJWUUQE5Zzzy8oqwABZkBreAppRwVjsTJSvM7HYZS6hhogjdMzpsZ4rsXzeTxFXu45s9ayVNK9RKafWAnzVAWazXBU0o5qC0SI0sreEq5kiZ4w+hziybyo0tm8fTqOr7wxzfp6NIkTymFnYe3bx3EIoDtpLluj3bSVEo5R+fgKeVemuANs08snMDPPnwCL23Yx6fufJ1wJOZ0SEopp5UvgEQM1vwTgKkl2bR1xdnZpI2ZlFLO0C6aSrmXJngO+Jeqcm68Yh5Ltzby8d+9RkObtkNXalSbci4UToElvwJjmBbSTppKKedE4wkisYQmeEq5lCZ4Drl4bim3fuwkVu1u4QM3L2HVrhanQ1JKOcXjgdOugz3vwKYaKns6aYYdDkwpNRq1JUcX6RBNpdxJEzwHnT+rhPu+uJBY3HDZrS/zz3d2OR2SUsopc6+ArBC8dCO56X7G5gZZvVu/+FFKDb/u6SNawVPKnTTBc9jc8jwevvZ0ZpXm8JW73+KnT6whoY0VlBp9fGmw4BrY9BzsepvTJhfx3No67birlBp2bRH7d0creEq5kyZ4I0BxdpC7v7CAK+dXcEvNRm54M8Ke5k6nw1JKDbeTPwOBbHj5Ji45sZTWzhg1a/c6HZVSapQJ9wzR1GUSlHIjTfBGiIDPw/98aA4/+eAc1jXFOf+Xz/PgWzu0TbpSo0l6HlR9BlY+yGkFYYqyAjz09k6no1JKjTLdCV52UCt4SrmRJngjzEdPreBHp6UzNZTN1+5dzhf/tJS9rRGnw1JKDZcF14B48b32Gy46oZRn1tTR0hl1Oiql1CiiTVaUcjdN8EagUKaHe7+4kP9833Rq1u3lvb96QRuwKDVa5JTCCR+Bt/7MZdPS6IoleGLFHqejUkqNIj1DNAOa4CnlRprgjVBej3DVmZN59NpFlOen85W73+JLf1nKvrBW85RKeadfB7EOZm+4jfEF6TpMUyk1rNq0i6ZSrjZkCZ6I3CEidSKy4jCPi4jcJCIbROQdETlpqGJxs8pQNg9ccxrfumA6T6+q47wbnueR5bt0bp5SqWzMNDj5M8gbv+X3wV/x7sbt1LVo4yWl1PDQIZpKudtQVvDuAi44wuMXApXJ7Srg1iGMxdV8Xg/XVE/m0esWUVGYybX3vMVVf1rKtvp2p0NTSg2Vi34J7/0Jk5te4mH/d1iy5DmnI1JKjRKtkRgBn4eATwd6KeVGQ/bONca8ADQc4ZRLgD8a61UgT0TGDlU8qaAylM0DVy/k2xdOZ8n6fZx7w/P87+NraNUGDEqlHhFY+GXk04+S7Y3x/tc/CW/9GbR6r5QaYm2RmA7PVMrFnHz3lgHbe+3vSB7b3fdEEbkKW+UjFApRU1PTrxcIh8P9PnckOVrc04CfnB7g/nVRbnt+I3e/spHLKgOcMc6HR2TY4uzLjb9vN8YMGveoUrGAxxf9jYk113H6Q1+GV2+F+VfBnH+BQIbT0SnlPsaASYBH13g7nLZIXNfAU8rFXPH1jDHmduB2gKqqKlNdXd2v62pqaujvuSNJf+P+4AWwfHsT1/9zFXeubKSm1s9VZ07iQyeVkeYb/j/Mbvx9uzFm0LhHm/NOmc1pT3+bW6et4fzWf8Aj18Hi78FJn4T5X4C8CqdDVMp5sS5o3QXxqE3gEnEwcQjXwt61ULca9q6x9z94G0x/v9MRj1jhSEw7aCrlYk6+e3cC5b32xyWPqQGYW57H/Vcv5IkVe7ilZiPf/vu73LB4HZ9bNJGPnlpBTtDvdIhKqeMUygly6qQx/GR3Fud94xvItlfgtdvgld/Aq7fA3Ctg0dehcLLToSo1cA2bYM8KOyxZPCBeez8ehVin3aIdEO/an7SZBCQSEN5jr6/fCM3b7fHDySiC4hlwwuV2ORJ1WDpEUyl3c/Ld+zDwFRH5K3Aq0GyMOWh4pjo6EeHCOWO5YHYJL22o57bnN/K/j6/hN89t4LOnT+SziyaSm66JnlJudumJZfz7A+/w6uZGFk4+HSacDk3b4eVfw7I/wNt3w5zL4cx/g6JKp8NVCqKdsG8ddLVBVjFkl0Ag0z62dx2seghWPwR73j3210jLhcJJMK7Krh+ZVwG+oE0QPV6bLKbn28Qus2hwfq5RIByJUZAZcDoMpdQxGrIET0TuAaqBIhHZAXwf8AMYY24DHgPeB2wA2oHPDFUso4WIsKiyiEWVRby7o5lfP7ueG59Zzx0vbeZzi2yipxU9pdzporlj+eXT6/jRP1fxyLWL8HoE8srhfT+FM75uE70374B37oUJi2DWB2HGByBrjNOhq5Ei1gUdDdDeANH25NZhb+NRmxB5/ODx2a2tDpq2QeNWaNoKHU22Sjxmuk2YxkwDXzq074O2fdBez/gtr8J9d0HtKqjfYKttvQWyIS3bDqUEKD8Vzv+x/cJCvLYCZxJ2npzXZ5/fH7RJmzewP2kTTzJen03m1KAKR2KUF+gcX6XcasgSPGPMlUd53ABfHqrXH+3mjMvl9k9WsWJnMzc9s55fPb2eO5Zs5uMLxnPl/Ar9w61UP4jIFqAViAMxY0yVU7FkBHz81/tn8uW7l3H369v4xILx+x/MLoH3/hgWfQ3e+B28ez88+nV47N9gwhkw9QL7YbxwCuSO0+YSI120A8K1BDtqIbwX/OngzwAMNO+Axs12WGLjFmir75WsJRO2RCw5lDE5Dy3abpO6rtaBxyIeyCmDvPFQMNFW5NY+fnDiljQR7LmhWTDjYgjNhGAuhOugdY+dD9feAONOgRkX6VDJEaotEiNL5+Ap5Vr67k1xs8sOTPRue34jtz6/kTMrx/DRUys4Z3oxPq+uc6PUEbzHGLPP6SAA3jenhIWTCvn5k2t5/5yxBw+hyiyC6v+As74Fdatg5YN2e/Lb+8/xpkHBJFv9yy6B7FJ7m1UMaTmQlpWssmTZSos/Y/RVSKKd0F5vEyVvr4qW128rSX2rRvGorW51NEJn8rb31l4PbXttlattr933+O1wxUAmBLLs84VrbSIUaQFgAcBrveISz4FzzLwByBxj/xt1J4GBrGS8yUqXx2OrYBmFya3ADllMy05ek24f9/ptMpiI7k8QMwogZxz4+vx/FovY6lzd6uR5hZBZCBlFvLB0FWee896h+i+jhontoqkfEZVyK333jhLdid7Opg7ufWM7976xjS/+aSmhnDSuOKWCK+dXUJIbdDpMpdQRiAg/vGQWF974Ij97ci3/86E5hzvRVlBCs+A937GJQ/1G+6G8fr2937ITdr1tEw6OsLaeeG0ykJZDVcwD2yZAVsgmhJnFNlnwpSW3oL1Ny7Zzo4K5EMyxxw7FGJv01K+31Z1AMqlMy7L3w3U2Ua1bbW+bd9hkNK/CVonyx9sEKdJqt84W6Arb5+5JcLxM2LoNzCsHJmVdYehs3r91NNnKUns9RNuO9l9i/88ajx7lfLG/o8wxdiueYROiRNzOTetqs7GYBJTMOeB3u2btOqZPrrAVuK52WzXLLbeVtPyJtvrlRDXWl7b//68+Et6Nwx+PGlQJY2jripGlyyQo5Vqa4I0yZXnpfP28qVx39hSeWVPH3a9t46Zn13Pzcxs4d0YxH18wntMnF+HxjLJv7JU6NAM8JSIG+L/kki2OmhrK5tOnTeCOlzbz0fkVzBmXe+QLRJKVuhI7z6mveNQmUuFam2hEwjZZ6mrdfz/SApFWOndsJKurDba9Yq+JdfYvaF/QJjnpyepRMMe+3r4NEGk++vWBLDvvq3Sefd0tL0HL3zhkYupPDj/v7raYiDMBA1v7xpSeTECTW+/kK6PAxur122pWPLr/Nh6xFaxYxP783gAE8yA9b/9teoG9zSiwia7n2EZJ7GmpYfr86mO6VqljFYnb716ygvoRUSm30nfvKOXzenjvrBLeO6uEbfXt/OX1rdz35g6eXFlLWV46F84u4cI5Y5lXnqfJnhrNFhljdopIMbBYRNYYY17ofYKIXAVcBRAKhfq9kPvxLPp+cprhPr/w1T+9zHcWBPEM6hDKjOQWsrve/YfC/jBZWVn2uDH4Ym144+14EtFeWxfeeAe+WBhfrB1frA1fLIw/GsYXa8Xf1Igvtp2oP5f2wtNozyijI72MSFoBnkQEX6wDb7wdX6yDqD+btszxdAbH2OGJAGOAiSCJKMHOfXgSEWK+TOLedGK+dFu16yMcDpOVmezeiLHbIc7rEQfCR/gVeYBAcut+yvbkBthpm63A9iM8ydEdz/8jTnFjzODeuIdCZ8x+caJDNJVyL333KioKM/j2hTP42rlTeWLFHh5evos/vLKF3y3ZTElOkAtml3Dx3FJOqshDRttcHDWqGWN2Jm/rRORBYD7wQp9zbgduB6iqqjL9Xcj9eBd9by/Ywb/dt5z67Cn8S1X50S8YBIO9UH3+oD3TkQ123MPFjXG7MWZwb9xDoTNmb3UdPKXcS9+9qkfQ7+XSeWVcOq+Mls4oz66u47F3d3PP69u46+UtTCjM4NJ5ZXxwXhnjCzOP/oRKuZiIZAIeY0xr8v75wPUOh9XjQ/PKuOf1bVz/yCrmjMtlekmO0yEppVJAZzxZwdMumkq5lrZPVIeUE/Rz6bwybv9kFW/+17n89MMnMDY3nRufWc9ZP6vhQ7e8xB9e3sLe1ojToSo1VELAEhFZDrwOPGqMecLhmHp4PMJNV84jM83Hp+54nZ1NHU6HpJRKAd0VPB2iqZR76btXHVV20M/lVeVcXlXOrqYOHnp7Fw+9vZPvP7ySHz6yktOnFPGBuaWkdR2hE59SLmOM2QTMdTqOIynLS+euz57Cv9z2Cp+643Xuv3oheRmBo1+olFKH0ZGcg5etTVaUci1996oBKc1L55rqyVxTPZm1e1p5ePlOHl6+i2/e/w4At6x6gYWTCzltchHzJxaQm+53OGKlUtv0khxu/0QVn7rjdT7/hzf58+dPJejX9uZKqWPTmVzDXit4SrmXvnvVMZtWks03S6bzb+dP450dzfzpqdfZY9K4+7Vt3PnSFjwCJ5bncebUMZxROYa543J1UXWlhsDCyYXc8JG5XHvPW/zrX9/ilo+djFe73yqljsH+Lpr6RZFSbqUJnjpuIsLc8jwaJweorj6VSCzOW9uaeGnDPl5Yv48bn1nPr55eT07Qx8LJhSyaUsRpU4qYVJSpXTmVGiQXnVBKXUuE6/+5is/94Q1+efmJ5GfqcE2l1MB0J3jaRVMp99J3rxp0aT4vCyYVsmBSId84fxqNbV28tHEfL6zby0sb6nlyZS0AJTlBTp9SxKLKQk6fUkRxdtDhyJVyt88umkjA5+H6R1Zx0a+XcPNH5zGvYrgWI1BKDQYR2YJdSDEOxIwxVX0erwYeAjYnD/3dGDNoHX474uARSNeh3kq5liZ4asjlZwa46IRSLjqhFGMMW+vbeWnjPl7eUM+za2p5YNkOAKaFsllUWcSpEws4sTyP4hxN+JQaqI8vGM8J43L50l+Wcfn/vcJ/vX8mn1w4XqvlSrnLe4wx+47w+IvGmIuG4oU7Y4bMNJ/+zVDKxTTBU8NKRJhQlMmEokw+dup4EgnDqt0tLNmwjyXr9/GnV7fy+yX2S8mxuUHmjstjbnkep08pZHZpLh6dV6TUUZ0wLo9Hrz2Dr//tbb7/8Epe3VTPdy+aSWleutOhKaVGuM6YDs9Uyu30Hawc5fEIs8tymV2Wy9VnTaYzGmflrmaWb29m+Y4mlm9v4omVewAoyAxwRmURZ00dw+lTighphU+pw8rN8PPbT1Zx+4ubuGHxOp5dU8fnz5jINdVT9MObUiObAZ4SEQP8nzHm9kOcszC5Rucu4N+MMSsH68U7khU8pZR76TtYjShBv5eTxxdw8viCnmP7whGWrN/H8+v28uL6vTz09i4ASnODnFiRx9xxeZxYnscJ4/JID+icAaW6eTzC1WdN5qITxvKzJ9fym+c2cu8b2/naeVP5SFW5drVVamRaZIzZKSLFwGIRWWOMeaHX48uA8caYsIi8D/gHUNn3SUTkKuAqgFAoRE1NTb9evC0SI2Ha+33+SBEOh10XM7gzbjfGDKMrbk3w1IhXlJXGpfPKuHReWc+Qztc2N/D29ibe3t7IY+/aCp/PI8wszeGkinyqJuQzryKf0tygziNQo964/AxuvGIenzl9Ij9+dBXfeXAFNz+7gY/Or+CK+RWMyU5zOkSlVJIxZmfytk5EHgTmAy/0eryl1/3HROQWESnqO2cvWfm7HaCqqspUV1f36/X/+9XHGTsmn+rqBcf9swynmpoa+vszjiRujNuNMcPoilsTPOUqvYd0dtsXjrB8exPLtjWydGsjf31jG3e9vAWwwzpnleYwqzSX2WU5TC/JZnxhJn6tXKhR6MTyPP72xYU8u6aOu17ewi8Wr+OmZ9dz4eyxfOzUCk6ZUKDzXJVykIhkAh5jTGvy/vnA9X3OKQFqjTFGROYDHqB+sGLojBkdxq2Uy+k7WLleUVYa58wIcc6MEADReILVu1t4e3sTK3e2sGJXM79fsolo3K7t4/MI4wszmFKchb+ji/bC3cwuzaW8IF2rfSrliUjP+2Xj3jB/fnUr9y/dwcPLd1GUFeCc6SHOnRli0ZQiHfKs1PALAQ8m/y3yAXcbY54QkasBjDG3AR8GrhGRGNABXGGMMYMVQEcMnYOnlMvpO1ilHL/Xwwnj7Jy8bl2xBOtqW1lf18qGunDPtnlflH9uWgZAdtDHrNIcppfkMGlMJpPHZDFpTCYlOTrMU6WmyWOy+P7Fs/jme6exeFUtT6+u47F3d3Pvm9tJ83k4dVIhp04sYMGkAuaU5R39CZVSx8UYswmYe4jjt/W6fzNw81DF0BnXCp5SbqfvYDUqBHyeg4Z2Ajz1zHOMnXYSK3Y1s2JnMyt2tXDfm9tp64r3nJMR8DKtJJuZY3OYMTaHmaU5TAtl6zecKmVkBHxccmIZl5xYRlcswRtbGli8qpaXN+7jZ0+uBSDo9zAxG17tWMOcslzmlGnVW6lU1KkVPKVcT9/BalQLeIU543KZM25/4meMobYlwqa9YTbua2NjXZjVu1t4ePku/vLatp7zyvLSmTQmkynFWUwpzqKyOJvK4izyMwNO/ChKDYqAz8PpU4o4fUoRAPXhCG9saeDVTQ08t2LbAcOdc4I+ZpflMjP5xcfM0hwmj8nSOa5KuVQkFidudB08pdxO38FK9SEilOQGKckNclryQy7YxG9nUwerdrWwrjY51HNvmL++vp2O6P6KX1FWgMribKaGsnoqflND2QT9Op9JuU9hVhoXzB7LBbPHUp2zl4WLzmDdnjDv7mzm3Z3NrNrVzJ9e3UoklgAg4PUwsSiTycV2mPPkMVlMLMpkXH46BZkBrfgpNYK1Rey/ZZrgKeVu+g5Wqp9EhHH5GYzLz+D8WSU9xxMJw67mjp55fXauX5j7l+7oGerpEXo+6JbmpVOWl05ZfnpPFTA76Hfqx1JqQNJ83oOq3rF4gs372li1u4VVu1rYuDfM6t2tPLFiD4lerR/S/V7G5acntwwqCjIoL7D3y/MzyEn3aQKolIPCnTFAh2gq5Xb6DlbqOHk8+xO/6mnFPccTCcP2xnZW7Wph9e4WVu1uYUt9Gy9t2HfAHD+AsblBphRn9TR2KcuzH3rL8tP1m1Q14vm8HipD2VSGsrnkxLKe45FYnG317Wze18bOpg52NHawo7Gd7Q0dLN3aSEvyw2S3oN9DKCdIKDtIKDdIKDuNUE6Q4pzkbXYahZlpmggqNUTCEfuezErTESdKuZl+clRqiHg8wvjCTMYXZnLhnLE9x40xtHTG2NXUwbaGdjbUhdmYHO75tze3094n+cvL8FOam05pXpDSvHTG5qbTujtGyZ4WJhRm6tBPNWKl+bw9id+hNLdH2d7YzvaGdnY2dVDb0kltS4Q9LZ28s6OJ2pZOOqOJg67zeYS8jACFmQEKMgMUZgUoykqjKCtAYVaaPdb9WGYag9hBXqmU1talFTylUoG+g5UaZiJCbrqf3HQ/M8bm8N5Z+x8zxrA3HGFno6122KpHO7uaOtnR2MHrmxt6qh63LH8Rj0B5QQaTx2RRlpdOSW6Qscn5g6W5dhioNrxQI1Vuhp/cjIO723YzxtAaiVHX0sme5gh1rZ00tHXR0NZFY3sX9WF7f+WuFvaFI7T2qQh28whkv/AU2UEf2UE/2UEfOUE/Oendt35ykseygz5y0v0HnJsd9JHm0y9SVOrrruBpgqeUu+k7WKkRREQozg5SnB1kXkX+Ic8JR2I88OTz5I+fYat/e20FcOnWRpo7ogec6xEozUtnfGEGFQWZPfOfuucBFmen4dMEUI1QImITsKCfKcWHrgL2FonFe5K++rYuGtoi1Ie7WL56AwWhUlo7Y7R0xmjpjLKzqYPVu6O0dERpjRw6MewtzechO+gnM81LRsBHRsBLRsBrE089L70AAAxkSURBVMA0myx2J4SZafbxzOR5Pfu9jns8OsRUjTxtyfdCtiZ4SrmavoOVcpmsNB/jc7xUzy096LH2rhh7mjvZ09LJzkY7BHRrfTtbG9p5YsVuGtsPTAB9HmFcfjrjCzOZUJhhb4symFCYSXlBhlb/lKuk+byU5tkvMHqriW+junr2Ya+LJwzhZOLX2hmjtfs2EqWlY/9+S2eMjq4YbV1x2rtitHba91v3dX2HVx85Vg8ZAS/pfi/B7lu/lzSfp+e2uSHCU43vkuH3kh7Y/3ha963PQ5rPPmav95Du95Lm85Lm3/94ms+jCaXqF22yolRq0HewUikkI+Bj0pgsJo3JOuTjbZEYu5s72NnUmRwGapO/rfVtLNvaeEAlw5tM/ioKMshNDlnLSrPViZygn7wMP/kZAXIz/BRkBBiXn67VQOVKXo8kh4seXzfbaDyRTPRsstcWsbfhSIyOrjhtXTHaIjHaInE6o3Hau+J0RO3W2RWnMxYnEk3Q0hmlM5qgqTXOupY9dCTPSxzHVMKA13NAchj020SyO7EM+j34vfu3gE/sNb2SyYCv9+MeAsn7Pq/03F/TECd3WyNpPi+BPtf5vILf48HvFbwe0UY5I5AO0VQqNeg7WKlRJDPNx5Ti7EMOdzPG0NDWxZZk18Mt+9rYXN/GjoZ2djZ20BqJ9XxgPZSAz0NlcRbTS3KYMTabGWNzWDipUCsHatTwez0UJJu7DIaamhqqq6sB+/7siieIxBJEogkisTidPbf2fnciGInZ4/a8BJ29j3XvR+1tR9RWIxvaEsQSCaJxQ1csQVc8QTRuX6szFmdAfWpef/mop4jY31fA250ASq8EUw5KJLvPCfi8PfsBr+DzevCIbWrlFcEjNnns3jwi+L1Cmt9LsFeCe8K4XMbmph81ztGmex28zIDOOVXKzTTBU0oBdr5TYVYahVlpnDz+0PP/wA5na+2M0tgepbG9i6b2LvaFu9hQF2b17hZeWL+XB5btIDvo453vnz+MP4FSqUtEksMtvRAc3tc2xhBLGCKxBNGYTfy64gm6YgliCdNzG40neGPpW8yYNeeAhLIrliAW7z7HnheLJ4jEE0Rjdr8rliCaTDB7v0Y0nuD/t3f/sXfdcxzHny/frdTPzWZN6ehEE5nYhsbPRWYJGZH5g8QWfyCTiRgjgjUSCfEPf/gx9s/8/kMQQdQimDKRENvQTWvGSGW/6IaRsnRr+/bHPZ3r69vv2rXn3vM59/lITr7nfO7p7et7e/pqP/ece77/vm8f/7j3vxPP+/Yd6J53clZz/4FifxVVxf4DdVhnOi+/8Fmcf6YTvOX+dd8+1jwMr8aQGucET9IRWepuUX/CI9dwGo9acZ+79+zljnvu9RIsaQTSnQU7fulh8PDV9/3XriXOefopq+/Us4MTvf1VHDhAd+Zz//+c+dxwopO7lbzp7NN44v13zDuGpKPkBE/SMTf5mWQP8j9BSepBEo5bygP/wVnLEnB0n69cFKc89hFsfJyXZ0qt8xy8JEmSJI1ErxO8JOcluTnJLUkuW+HxNyS5K8n2bnlTn3kkSZIkacx6u0QzyRJwBfBS4DbguiRbq+o3y3b9alVd0lcOSZIkSVoUfZ7Bey5wS1X9saruA74CvKrH30+SJEmSFlqfN1l5EnDr1PZtwPNW2O/VSV4M/A54Z1XdunyHJBcDFwOsW7eOa6655rAC7Nmz57D3HRJzz06LmcHckiRJWtm876L5beDLVbU3yZuBLwLnLt+pqq4ErgTYvHlzHfzBrw9m+ofEtsTcs9NiZjC3JEmSVtbnJZq3A6dObW/oxh5QVX+tqr3d5meA5/SYR5IkSZJGrc8J3nXApiSnJVkDXABsnd4hyfqpzfOBm3rMI0mSJEmj1tslmlW1L8klwPeAJeBzVbUzyQeB66tqK/D2JOcD+4C/AW/oK48kSZIkjV2vn8Grqu8A31k29v6p9S3Alj4zSJIkSdKiSFXNO8MRSXIX8KfD3P1k4O4e4/TF3LPTYmYYX+6nVNUTZh3mWFuAfmoxM5h7llrMDKvnbr6fFqCbwNyz1GJmGF/uQ3ZTcxO8I5Hk+qraPO8cR8rcs9NiZjD3GLT4WrSYGcw9Sy1mhnZz96HV18Lcs9NiZlis3H3eZEWSJEmSNENO8CRJkiRpJMY+wbty3gEeInPPTouZwdxj0OJr0WJmMPcstZgZ2s3dh1ZfC3PPTouZYYFyj/ozeJIkSZK0SMZ+Bk+SJEmSFsZoJ3hJzktyc5Jbklw27zyHkuRzSXYn2TE19vgkVyf5fff1xHlmXC7JqUl+lOQ3SXYmubQbH3ruRyS5NskNXe4PdOOnJfl5d6x8NcmaeWddLslSkl8luarbbiHzriS/TrI9yfXd2KCPkVmwm/rVYj+13E1gP42J/dSfFrsJ2u6nRe6mUU7wkiwBVwAvB04HLkxy+nxTHdIXgPOWjV0GbKuqTcC2bntI9gHvqqrTgecDb+1e36Hn3gucW1VnAmcB5yV5PvBh4GNV9TTg78BFc8x4KJcCN01tt5AZ4CVVddbU7X2Hfoz0ym6aiRb7qeVuAvtpFOyn3rXYTdB2Py1uN1XV6BbgBcD3pra3AFvmnWuVvBuBHVPbNwPru/X1wM3zzvgg+b8FvLSl3MAjgV8Cz2PywyOPW+nYGcICbOj+Qp8LXAVk6Jm7XLuAk5eNNXOM9PSa2E2z/x6a6qeWuqnLZT+NZLGfZp6/qW7q8jXTT4veTaM8gwc8Cbh1avu2bqwV66rqzm79z8C6eYZZTZKNwLOAn9NA7u50/XZgN3A18Afgnqra1+0yxGPl48B7gAPd9kkMPzNAAd9P8oskF3djgz9GemY3zVBL/dRoN4H9NCb204y01E3QbD8tdDcd11c6HRtVVUkGeavTJI8Gvg68o6r+meSBx4aau6r2A2clOQH4JvD0OUdaVZJXArur6hdJzpl3niN0dlXdnuQU4Ookv51+cKjHiA7P0P/8Wuun1roJ7CcN15D//FrrJmivn+ymkX4GD7gdOHVqe0M31oq/JFkP0H3dPec8/yfJ8UwK6ktV9Y1uePC5D6qqe4AfMTlFf0KSg292DO1YeRFwfpJdwFeYXGrwCYadGYCqur37upvJPwjPpaFjpCd20wy03E8NdRPYT2NjP/Ws5W6Cpvpp4btprBO864BN3d1y1gAXAFvnnOlIbAVe362/nsl12oORydtNnwVuqqqPTj009NxP6N59IslaJte+38SkrF7T7Tao3FW1pao2VNVGJsfxD6vqdQw4M0CSRyV5zMF14GXADgZ+jMyA3dSzFvupxW4C+2mE7KcetdhN0GY/2U2M8yYrNfkQ4iuA3zG5Tvh9886zSs4vA3cC9zO5HvgiJtcJbwN+D/wAePy8cy7LfDaTa4RvBLZ3yysayH0G8Ksu9w7g/d34U4FrgVuArwEPn3fWQ+Q/B7iqhcxdvhu6ZefBv4NDP0Zm9NrYTf3mbq6fWu+mLqv9NILFfuo1c3Pd1OVuup8WtZvS/UJJkiRJUuPGeommJEmSJC0cJ3iSJEmSNBJO8CRJkiRpJJzgSZIkSdJIOMGTJEmSpJFwgqfeJdmfZPvUctkxfO6NSXYcq+eTtFjsJ0lDZDfpaBz34LtIR+3eqjpr3iEkaQX2k6Qhspv0kHkGT3OTZFeSjyT5dZJrkzytG9+Y5IdJbkyyLcmTu/F1Sb6Z5IZueWH3VEtJPp1kZ5LvJ1k7t29K0ijYT5KGyG7S4XCCp1lYu+wyg9dOPfaPqnom8Cng493YJ4EvVtUZwJeAy7vxy4EfV9WZwLOBnd34JuCKqnoGcA/w6p6/H0njYT9JGiK7SQ9ZqmreGTRySfZU1aNXGN8FnFtVf0xyPPDnqjopyd3A+qq6vxu/s6pOTnIXsKGq9k49x0bg6qra1G2/Fzi+qj7U/3cmqXX2k6Qhspt0NDyDp3mrQ6wfib1T6/vxs6WSjg37SdIQ2U1alRM8zdtrp77+rFv/KXBBt/464Cfd+jbgLQBJlpI8blYhJS0k+0nSENlNWpWzdc3C2iTbp7a/W1UHb/d7YpIbmbyTdGE39jbg80neDdwFvLEbvxS4MslFTN5tegtwZ+/pJY2Z/SRpiOwmPWR+Bk9z011Hvrmq7p53FkmaZj9JGiK7SYfDSzQlSZIkaSQ8gydJkiRJI+EZPEmSJEkaCSd4kiRJkjQSTvAkSZIkaSSc4EmSJEnSSDjBkyRJkqSRcIInSZIkSSPxH2RHL+lPfxrMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_pcK8xOmIhr"
      },
      "source": [
        "transformer.load_state_dict(torch.load('./models/transformer.pth'))\n",
        "transformer.to(DEVICE);"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8LxG1gYiwJX"
      },
      "source": [
        "def find_path(tree):\n",
        "    path = []\n",
        "    for nodes in reversed(tree):\n",
        "        if len(path) == 0:\n",
        "            path.append(nodes[0])\n",
        "        else:\n",
        "            parent_id = path[-1].parent_id\n",
        "            for node in nodes:\n",
        "                if node.id == parent_id:\n",
        "                    path.append(node)\n",
        "    return path\n",
        "\n",
        "def find_best_path(tree):\n",
        "    best = []\n",
        "    for nodes in reversed(tree):\n",
        "        if len(best) == 0:\n",
        "            best.append(nodes[0])\n",
        "        else:\n",
        "            nodes_eos = []\n",
        "            parent_id = best[-1].parent_id\n",
        "            for node in nodes:\n",
        "                if node.eos:\n",
        "                    nodes_eos.append(node)\n",
        "                if node.id == parent_id:\n",
        "                    best.append(node)\n",
        "            if len(nodes_eos) > 0:\n",
        "                candidates = sorted([best[-1], *nodes_eos],\n",
        "                                    key=lambda node: node.logps,\n",
        "                                    reverse=True)\n",
        "                candidate = candidates[0]\n",
        "                if candidate.eos:\n",
        "                    best = [candidate]\n",
        "    return best\n",
        "\n",
        "class Node:\n",
        "    id_ = 0\n",
        "    \n",
        "    def __init__(self, token, states, logp=0., parent=None, eos=False):\n",
        "        self.__id = self.__class__.id_\n",
        "        self.__token = token\n",
        "        self.__states = states\n",
        "        self.__logp = logp\n",
        "        self.__parent_id = None if parent is None else parent.id\n",
        "        self.__eos = eos\n",
        "        self.__level = 0 if parent is None else parent.level + 1\n",
        "        self.__logps = logp if parent is None else parent.logps + logp\n",
        "        self.__class__.id_ += 1\n",
        "        \n",
        "    def __str__(self):\n",
        "        return f'Node[id={self.__id}, ' + \\\n",
        "                    f'index={EN.vocab.itos[self.__token.cpu().item()]}, ' + \\\n",
        "                    f'logp={self.__logp}, ' + \\\n",
        "                    f'logps={self.__logps}, ' + \\\n",
        "                    f'parent_id={self.__parent_id}, ' + \\\n",
        "                    f'level={self.__level}]'\n",
        "    \n",
        "    @property\n",
        "    def token(self):\n",
        "        return self.__token\n",
        "    \n",
        "    @token.setter\n",
        "    def token(self, token):\n",
        "        self.__token = token\n",
        "    \n",
        "    @property\n",
        "    def parent_id(self):\n",
        "        return self.__parent_id\n",
        "    \n",
        "    @parent_id.setter\n",
        "    def parent_id(self, parent_id):\n",
        "        self.__parent_id = parent_id\n",
        "        \n",
        "    @property\n",
        "    def id(self):\n",
        "        return self.__id\n",
        "    \n",
        "    @id.setter\n",
        "    def id(self, id_):\n",
        "        self.__id = id_\n",
        "    \n",
        "    @property\n",
        "    def token(self):\n",
        "        return self.__token\n",
        "    \n",
        "    @token.setter\n",
        "    def token(self, token):\n",
        "        self.__token = token\n",
        "    \n",
        "    @property\n",
        "    def states(self):\n",
        "        return self.__states\n",
        "    \n",
        "    @states.setter\n",
        "    def states(self, states):\n",
        "        self.__states = states\n",
        "      \n",
        "    @property\n",
        "    def eos(self):\n",
        "        return self.__eos\n",
        "    \n",
        "    @eos.setter\n",
        "    def eos(self, eos):\n",
        "        self.__eos = eos\n",
        "    \n",
        "    @property\n",
        "    def logps(self):\n",
        "        return self.__logps\n",
        "    \n",
        "    @logps.setter\n",
        "    def logps(self, logps):\n",
        "        self.__logps = logps\n",
        "        \n",
        "    @property\n",
        "    def level(self):\n",
        "        return self.__level\n",
        "    \n",
        "    @level.setter\n",
        "    def level(self, level):\n",
        "        self.__level = level\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScoI5AN1mIhr"
      },
      "source": [
        "def evaluate(model, data, beam_size, src_field, dest_field, max_len, device):\n",
        "    src_sentences = [*map(lambda example: example.src, data.examples)]\n",
        "    dest_sentences = [*map(lambda example: example.trg, data.examples)]\n",
        "    data = [*zip([*map(lambda word_list: src_field.process([word_list]), src_sentences)],\n",
        "                 [*map(lambda word_list: dest_field.process([word_list]), dest_sentences)])]\n",
        "    references, hypotheses, sources = [], [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (src_sequence, dest_sequence) in tqdm.tqdm(enumerate(data), total=len(data), position=0, leave=True):\n",
        "            src_sequence, dest_sequence = src_sequence.to(device), dest_sequence.to(device)\n",
        "            src_mask = model.make_src_mask(src_sequence)\n",
        "            src_encoded = model.encoder(src_sequences=src_sequence, src_mask=src_mask)\n",
        "            # Decoding\n",
        "            tree = [[Node(token=torch.LongTensor([dest_field.vocab.stoi[dest_field.init_token]]).to(device), states=None)]]\n",
        "            for _ in range(max_len):\n",
        "                next_nodes = []\n",
        "                for node in tree[-1]:\n",
        "                    if node.eos: # Skip eos token\n",
        "                        continue\n",
        "                    # Get tokens that're already translated\n",
        "                    already_translated = torch.LongTensor([*map(lambda node: node.token, find_path(tree))][::-1]).unsqueeze(0).to(device)\n",
        "                    dest_mask = model.make_dest_mask(already_translated)\n",
        "                    logit, _ = model.decoder(dest_sequences=already_translated, src_encoded=src_encoded,\n",
        "                                              dest_mask=dest_mask, src_mask=src_mask) # [1, dest_seq_len, vocab_size]                    \n",
        "                    logp = F.log_softmax(logit[:, -1, :], dim=1).squeeze(dim=0) # [vocab_size] Get scores                    \n",
        "                    topk_logps, topk_tokens = torch.topk(logp, beam_size) # Get top k tokens & logps                    \n",
        "                    for k in range(beam_size):\n",
        "                        next_nodes.append(Node(token=topk_tokens[k, None], states=None,\n",
        "                                               logp=topk_logps[k, None].cpu().item(), parent=node,\n",
        "                                               eos=topk_tokens[k].cpu().item() == dest_field.vocab[dest_field.eos_token]))\n",
        "                if len(next_nodes) == 0:\n",
        "                    break\n",
        "                next_nodes = sorted(next_nodes, key=lambda node: node.logps, reverse=True) # Sort next_nodes to get the best\n",
        "                tree.append(next_nodes[:beam_size]) # Update the tree\n",
        "            best_path = find_best_path(tree) # Find the best path of the tree\n",
        "\n",
        "            # Get the translation\n",
        "            pred_translated = [*map(lambda node: dest_field.vocab.itos[node.token], best_path)]\n",
        "            pred_translated = [*filter(lambda word: word not in [dest_field.init_token, dest_field.eos_token], pred_translated[::-1])]\n",
        "\n",
        "            hypotheses.append(pred_translated) # Update hypotheses\n",
        "\n",
        "            # Update references\n",
        "            references.append([[dest_field.vocab.itos[indice] for indice in dest_sequence[0] if indice not in (\n",
        "                dest_field.vocab.stoi[dest_field.init_token],\n",
        "                dest_field.vocab.stoi[dest_field.eos_token],\n",
        "                dest_field.vocab.stoi[dest_field.pad_token]\n",
        "            )]])\n",
        "\n",
        "            # Update sources\n",
        "            sources.append([src_field.vocab.itos[indice]  for indice in src_sequence[0] if indice not in (\n",
        "                src_field.vocab.stoi[src_field.init_token],\n",
        "                src_field.vocab.stoi[src_field.eos_token],\n",
        "                src_field.vocab.stoi[src_field.pad_token]\n",
        "            )])\n",
        "    \n",
        "        assert len(hypotheses) == len(references) == len(sources)\n",
        "        bleu = bleu_score(hypotheses, references) # Calculate BLEU score\n",
        "    return hypotheses, references, sources, bleu"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z4YL6aemIhr",
        "outputId": "1ce8cea4-a4ab-4a81-a5d8-909074a96ed6"
      },
      "source": [
        "bleu_scores = []\n",
        "for name, data in [('validation', valid_data), ('test', test_data)]:\n",
        "    _, _, _, bleu = evaluate(model=transformer, data=data, beam_size=1, src_field=EN_TEXT, dest_field=RU_TEXT, max_len=MAX_LEN, device=DEVICE)\n",
        "    bleu_scores.append((1, name, bleu))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2500/2500 [02:52<00:00, 14.51it/s]\n",
            "100%|██████████| 7500/7500 [08:37<00:00, 14.50it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhmKUQwL31PF",
        "outputId": "c1c80a8c-3f5b-47d5-c9e2-74fdbd9a7635"
      },
      "source": [
        "for score in bleu_scores:\n",
        "    print(f'BLEU: {score[2]*100:.3f}% with beam_size={score[0]} on {score[1]} data')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU: 31.740% with beam_size=1 on validation data\n",
            "BLEU: 32.305% with beam_size=1 on test data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRfG8X1pHEBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ad9d83-0109-4b2d-ed18-762d664a477d"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(transformer):,} trainable parameters')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 12,504,131 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH6X3gMImIhs"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TzuCX4wmIhs"
      },
      "source": [
        "def translate(sentences, model, beam_size, src_field, dest_field, max_len, device):\n",
        "    if isinstance(sentences, list):\n",
        "        sentences = [*map(src_field.preprocess, sentences)]\n",
        "        targets = None\n",
        "    if isinstance(sentences, Dataset):\n",
        "        targets = [*map(lambda example: ' '.join(example.trg), sentences.examples)]\n",
        "        sentences = [*map(lambda example: example.src, sentences.examples)]\n",
        "    data = [*map(lambda word_list: src_field.process([word_list]), sentences)]\n",
        "    translated_sentences, attention_weights, pred_logps = [], [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, src_sequence in tqdm.tqdm(enumerate(data), total=len(data), position=0, leave=True):\n",
        "            src_sequence = src_sequence.to(device)\n",
        "            src_mask = model.make_src_mask(src_sequence)\n",
        "            src_encoded = model.encoder(src_sequences=src_sequence, src_mask=src_mask)\n",
        "            tree = [[Node(token=torch.LongTensor([dest_field.vocab.stoi[dest_field.init_token]]).to(device), states=())]]\n",
        "            for _ in range(max_len):\n",
        "                next_nodes = []\n",
        "                for node in tree[-1]:\n",
        "                    if node.eos: # Skip eos token\n",
        "                        continue\n",
        "                    # Get tokens that're already translated\n",
        "                    already_translated = torch.LongTensor([*map(lambda node: node.token, find_path(tree))][::-1]).unsqueeze(0).to(device)\n",
        "                    dest_mask = model.make_dest_mask(already_translated)\n",
        "                    logit, attn_weights = model.decoder(dest_sequences=already_translated, src_encoded=src_encoded,\n",
        "                                              dest_mask=dest_mask, src_mask=src_mask) # [1, dest_seq_len, vocab_size]                      \n",
        "                    logp = F.log_softmax(logit[:, -1, :], dim=1).squeeze(dim=0) # [vocab_size] Get scores                    \n",
        "                    topk_logps, topk_tokens = torch.topk(logp, beam_size) # Get top k tokens & logps                    \n",
        "                    for k in range(beam_size):\n",
        "                        next_nodes.append(Node(token=topk_tokens[k, None], states=(attn_weights,),\n",
        "                                               logp=topk_logps[k, None].cpu().item(), parent=node,\n",
        "                                               eos=topk_tokens[k].cpu().item() == dest_field.vocab[dest_field.eos_token]))\n",
        "                if len(next_nodes) == 0:\n",
        "                    break\n",
        "                next_nodes = sorted(next_nodes, key=lambda node: node.logps, reverse=True)\n",
        "                tree.append(next_nodes[:beam_size])\n",
        "            best_path = find_best_path(tree)[::-1]\n",
        "            # Get the translation\n",
        "            pred_translated = [*map(lambda node: dest_field.vocab.itos[node.token], best_path)]\n",
        "            pred_translated = [*filter(lambda word: word not in [\n",
        "                dest_field.init_token, dest_field.eos_token\n",
        "            ], pred_translated)]\n",
        "            translated_sentences.append(' '.join(pred_translated))\n",
        "            # Get probabilities\n",
        "            pred_logps.append(sum([*map(lambda node: node.logps, best_path)]))\n",
        "            # Get attention weights\n",
        "            attention_weights.append(best_path[-1].states[0].cpu().numpy())\n",
        "        sentences = [*map(lambda sentence: ' '.join(sentence), sentences)]\n",
        "    return sentences, translated_sentences, targets, attention_weights, pred_logps"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FPeU0s4mIhs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5a3a05-62f5-445d-b6dd-859ed0c59b18"
      },
      "source": [
        "sentences, translated_sentences, dest_sentences, attention_weights, pred_logps = translate(sentences=test_data, model=transformer, beam_size=1, src_field=EN_TEXT,\n",
        "                                                                                           dest_field=RU_TEXT, max_len=MAX_LEN, device=DEVICE)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7500/7500 [08:09<00:00, 15.33it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_keF2reemIhs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352acda8-0e03-4d43-cf1b-3bab1f3187a6"
      },
      "source": [
        "indexes = np.random.choice(1000, size=10, replace=False)\n",
        "\n",
        "for i in indexes:\n",
        "    text = f'Source: {sentences[i]}\\n'\n",
        "    text += f'Ground truth translation: {dest_sentences[i]}\\n'\n",
        "    text += f'Predicted translation: {translated_sentences[i]}\\n'\n",
        "    print(text)\n",
        "    print()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source: located by berlin – kostrzyn route motelik lord offers rooms with free wi - fi .\n",
            "Ground truth translation: мотель motelik lord находится у шоссе берлин - костшин и располагает номерами с бесплатным wi - fi .\n",
            "Predicted translation: отель <unk> <unk> <unk> расположен на улице <unk> . к услугам гостей номера с бесплатным wi - fi .\n",
            "\n",
            "\n",
            "Source: kitchen area comes with a microwave , an electric kettle and a refrigerator .\n",
            "Ground truth translation: мини - кухня оборудована микроволновой печью , электрическим чайником и холодильником .\n",
            "Predicted translation: кухня оснащена микроволновой печью , холодильником и электрическим чайником .\n",
            "\n",
            "\n",
            "Source: a private bathroom features a shower with available towels in each non - smoking room .\n",
            "Ground truth translation: в каждом номере этого отеля для некурящих оборудована собственная ванная комната с душем .\n",
            "Predicted translation: в каждом номере есть собственная ванная комната с душем , полотенцами .\n",
            "\n",
            "\n",
            "Source: it is fitted with a living room , sound - proof walls , flat - screen tvs , minibar and a safety deposit box .\n",
            "Ground truth translation: в числе удобств гостиная , звукоизолированные стены , телевизоры с плоским экраном , мини - бар и сейф .\n",
            "Predicted translation: к услугам гостей гостиная , телевизор с плоским экраном , мини - бар , сейф , телевизор с плоским экраном и сейф .\n",
            "\n",
            "\n",
            "Source: towels are offered .\n",
            "Ground truth translation: полотенца входят в стоимость проживания .\n",
            "Predicted translation: гостям предоставляются полотенца .\n",
            "\n",
            "\n",
            "Source: the apartments have kitchen facilities including a microwave and a fridge .\n",
            "Ground truth translation: в апартаментах есть кухни с микроволновой печью и холодильником .\n",
            "Predicted translation: в апартаментах есть кухня с микроволновой печью и холодильником .\n",
            "\n",
            "\n",
            "Source: free private parking is possible on site .\n",
            "Ground truth translation: гостям предоставляется бесплатная парковка .\n",
            "Predicted translation: на территории обустроена бесплатная частная парковка .\n",
            "\n",
            "\n",
            "Source: the style is modern , with new furniture , white walls , and leather headboards .\n",
            "Ground truth translation: номера отличает интерьер в современном стиле с белыми стенами , новой мебелью и кроватями с кожаными изголовьями .\n",
            "Predicted translation: современный дизайн сочетается с мебелью , <unk> элементами декора и <unk> одеялами .\n",
            "\n",
            "\n",
            "Source: visitors can book soothing massages or relax in the gym after a long day .\n",
            "Ground truth translation: также в распоряжении гостей тренажерный зал и массажный кабинет , где можно снять усталость и напряжение после насыщенного дня .\n",
            "Predicted translation: гости могут заказать расслабляющий массаж в тренажерном зале и отдохнуть после долгого дня .\n",
            "\n",
            "\n",
            "Source: at hotel silver inn you will find facilities like car rental and laundry .\n",
            "Ground truth translation: в отеле silver inn предлагаются прокат автомобилей и прачечная .\n",
            "Predicted translation: в отеле silver inn есть прокат автомобилей и прачечная .\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQU5IpsG87Ly"
      },
      "source": [
        "### Results Table\n",
        "\n",
        "|                                                     Model                  | Complexity <br>(# of training parameters) | Training time<br>per an epoch* | Quality<br>(in BLEU)                                                                                                                                                                                          |\n",
        "|:------------------------------------------------------------------------------------------------------------------------------------------------------:|:-----------------------------------------:|:------------------------------:|:--------------------:|\n",
        "|                                               Transformer,<br> <br>epoch=50, hidden_size=512, n_layers=2, n_heads=8                                             |                 12,504,131                |          43 sec           |         32.3   \n",
        "\n",
        "* The time is a dependent parameter because I used Google Colab Pro but the time could be different on another machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wLHAM4cmIht"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}