{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "NMT_LSTM_Attention_EN_RU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0TvhQGyo0PZ"
      },
      "source": [
        "# Environment setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o2z-5Ji8LSL",
        "outputId": "99d2c154-9149-4205-cc34-b2e01d2df365"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elg-xyiDrY-A"
      },
      "source": [
        "folder_path = '/content/drive/MyDrive/models/yandex/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2abFJfKsnJl"
      },
      "source": [
        "!pip install torch --upgrade\n",
        "!pip install torchtext --upgrade\n",
        "!pip install git+https://github.com/aatimofeev/spacy_russian_tokenizer.git\n",
        "!pip install pymorphy2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qumUoRJWry7a"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import dill\n",
        "import spacy\n",
        "import random\n",
        "import warnings\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import Vectors\n",
        "from torchtext.data import Dataset, Example, Field\n",
        "from torchtext.data.iterator import BucketIterator\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torchtext.datasets import TranslationDataset\n",
        "\n",
        "\n",
        "from spacy.lang.ru import Russian\n",
        "from spacy_russian_tokenizer import RussianTokenizer, MERGE_PATTERNS"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1Z3_smGupMk",
        "outputId": "a56991b0-23b2-4f92-ead1-7c21a1c411e5"
      },
      "source": [
        "warnings.simplefilter(action='ignore', category=UserWarning)\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "SEED = 546\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {DEVICE}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qvOexBco7bW"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9rlKUst75QK"
      },
      "source": [
        "class EncRNN(nn.Module):\n",
        "    def __init__(self, vsz, embed_dim, hidden_dim, n_layers, use_birnn, dout):\n",
        "        super(EncRNN, self).__init__()\n",
        "        self.embed = nn.Embedding(vsz, embed_dim)\n",
        "        self.rnn = nn.LSTM(embed_dim, hidden_dim, n_layers,\n",
        "                           bidirectional=use_birnn)\n",
        "        self.dropout = nn.Dropout(dout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embs = self.dropout(self.embed(inputs))\n",
        "        enc_outs, hidden = self.rnn(embs)\n",
        "        return self.dropout(enc_outs), hidden\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim, method):\n",
        "        super(Attention, self).__init__()\n",
        "        self.method = method\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        if method == 'general':\n",
        "            self.w = nn.Linear(hidden_dim, hidden_dim)\n",
        "        elif method == 'concat':\n",
        "            self.w = nn.Linear(hidden_dim*2, hidden_dim)\n",
        "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_dim))\n",
        "\n",
        "    def forward(self, dec_out, enc_outs):\n",
        "        if self.method == 'dot':\n",
        "            attn_energies = self.dot(dec_out, enc_outs)\n",
        "        elif self.method == 'general':\n",
        "            attn_energies = self.general(dec_out, enc_outs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat(dec_out, enc_outs)\n",
        "        return F.softmax(attn_energies, dim=0)\n",
        "\n",
        "    def dot(self, dec_out, enc_outs):\n",
        "        return torch.sum(dec_out*enc_outs, dim=2)\n",
        "\n",
        "    def general(self, dec_out, enc_outs):\n",
        "        energy = self.w(enc_outs)\n",
        "        return torch.sum(dec_out*energy, dim=2)\n",
        "\n",
        "    def concat(self, dec_out, enc_outs):\n",
        "        dec_out = dec_out.expand(enc_outs.shape[0], -1, -1)\n",
        "        energy = torch.cat((dec_out, enc_outs), 2)\n",
        "        return torch.sum(self.v * self.w(energy).tanh(), dim=2)\n",
        "\n",
        "\n",
        "class DecRNN(nn.Module):\n",
        "    def __init__(self, vsz, embed_dim, hidden_dim, n_layers, use_birnn, \n",
        "                 dout, attn, tied):\n",
        "        super(DecRNN, self).__init__()\n",
        "        hidden_dim = hidden_dim*2 if use_birnn else hidden_dim\n",
        "\n",
        "        self.embed = nn.Embedding(vsz, embed_dim)\n",
        "        self.rnn = nn.LSTM(embed_dim, hidden_dim , n_layers)\n",
        "\n",
        "        self.w = nn.Linear(hidden_dim*2, hidden_dim)\n",
        "        self.attn = Attention(hidden_dim, attn)\n",
        "\n",
        "        self.out_projection = nn.Linear(hidden_dim, vsz)\n",
        "        if tied: \n",
        "            if embed_dim != hidden_dim:\n",
        "                raise ValueError(\n",
        "                    f\"when using the tied flag, embed-dim:{embed_dim} \\\n",
        "                    must be equal to hidden-dim:{hidden_dim}\")\n",
        "            self.out_projection.weight = self.embed.weight\n",
        "        self.dropout = nn.Dropout(dout)\n",
        "\n",
        "    def forward(self, inputs, hidden, enc_outs):\n",
        "        inputs = inputs.unsqueeze(0)\n",
        "        embs = self.dropout(self.embed(inputs))\n",
        "        dec_out, hidden = self.rnn(embs, hidden)\n",
        "\n",
        "        attn_weights = self.attn(dec_out, enc_outs).transpose(1, 0)\n",
        "        enc_outs = enc_outs.transpose(1, 0)\n",
        "        context = torch.bmm(attn_weights.unsqueeze(1), enc_outs)\n",
        "        cats = self.w(torch.cat((dec_out, context.transpose(1, 0)), dim=2))\n",
        "        pred = self.out_projection(cats.tanh().squeeze(0))\n",
        "        return pred, hidden\n",
        "\n",
        "\n",
        "class Seq2seqAttn(nn.Module):\n",
        "    def __init__(self, args, fields, device):\n",
        "        super().__init__()\n",
        "        self.src_field, self.tgt_field = fields\n",
        "        self.src_vsz = len(self.src_field.vocab.itos)\n",
        "        self.tgt_vsz = len(self.tgt_field.vocab.itos)\n",
        "        self.encoder = EncRNN(self.src_vsz, args.embed_dim, args.hidden_dim, \n",
        "                              args.n_layers, args.bidirectional, args.dropout)\n",
        "        self.decoder = DecRNN(self.tgt_vsz, args.embed_dim, args.hidden_dim, \n",
        "                              args.n_layers, args.bidirectional, args.dropout,\n",
        "                              args.attn, args.tied)\n",
        "        self.device = device\n",
        "        self.n_layers = args.n_layers\n",
        "        self.hidden_dim = args.hidden_dim\n",
        "        self.use_birnn = args.bidirectional\n",
        "\n",
        "    def forward(self, srcs, tgts=None, maxlen=100, tf_ratio=0.0):\n",
        "        slen, bsz = srcs.size()\n",
        "        tlen = tgts.size(0) if isinstance(tgts, torch.Tensor) else maxlen\n",
        "        tf_ratio = tf_ratio if isinstance(tgts, torch.Tensor) else 0.0\n",
        "       \n",
        "        enc_outs, hidden = self.encoder(srcs)\n",
        "\n",
        "        dec_inputs = torch.ones_like(srcs[0]) * 2 # <eos> is mapped to id=2\n",
        "        outs = []\n",
        "\n",
        "        if self.use_birnn:\n",
        "            def trans_hidden(hs):\n",
        "                hs = hs.view(self.n_layers, 2, bsz, self.hidden_dim)\n",
        "                hs = torch.stack([torch.cat((h[0], h[1]), 1) for h in hs])\n",
        "                return hs\n",
        "            hidden = tuple(trans_hidden(hs) for hs in hidden)\n",
        "\n",
        "        for i in range(tlen):\n",
        "            preds, hidden = self.decoder(dec_inputs, hidden, enc_outs)\n",
        "            outs.append(preds)\n",
        "            use_tf = random.random() < tf_ratio\n",
        "            dec_inputs = tgts[i] if use_tf else preds.max(1)[1]\n",
        "        return torch.stack(outs)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ_tYfY4pCvy"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1AkAd0V75QS"
      },
      "source": [
        "def train_opts(parser):\n",
        "    group = parser.add_argument_group('Training')\n",
        "    group.add_argument('--train', default='./sample_data/sample_train.tsv',\n",
        "        help='path to a train data')\n",
        "    group.add_argument('--valid', default='./sample_data/sample_valid.tsv',\n",
        "        help='path to a validation data')\n",
        "    group.add_argument('--batch-size', type=int, default=32, \n",
        "        help='batch size')\n",
        "    group.add_argument('--savedir', default='./checkpoints', \n",
        "        help='path to save models')\n",
        "    group.add_argument('--max-epoch', type=int, default=0, \n",
        "        help='number of epochs')\n",
        "    group.add_argument('--max-update', type=int, default=0,\n",
        "        help='number of updates')\n",
        "    group.add_argument('--lr', type=float, default=0.25,\n",
        "        help='learning rate')\n",
        "    group.add_argument('--min-lr', type=float, default=1e-5, \n",
        "        help='minimum learning rate')\n",
        "    group.add_argument('--clip', type=float, default=0.1,\n",
        "        help='gradient cliping')\n",
        "    group.add_argument('--tf-ratio', type=float, default=0.5,\n",
        "        help='teaching force ratio')\n",
        "    group.add_argument('--gpu', action='store_true',\n",
        "        help='whether gpu is used')\n",
        "    return group\n",
        "\n",
        "\n",
        "def translate_opts(parser):\n",
        "    group = parser.add_argument_group('Translation')\n",
        "    group.add_argument('--model', default='./checkpoints/checkpoint_best.pt',\n",
        "        help='model file for translation')\n",
        "    group.add_argument('--input', default='./sample_data/sample_test.txt',\n",
        "        help='input file')\n",
        "    group.add_argument('--batch-size', type=int, default=32,\n",
        "        help='batch size')\n",
        "    group.add_argument('--maxlen', type=int, default=100,\n",
        "        help='maximum length of output sentence')\n",
        "    group.add_argument('--gpu', action='store_true',\n",
        "        help='whether gpu is used')\n",
        "    return group\n",
        "    \n",
        "\n",
        "def model_opts(parser):\n",
        "    group = parser.add_argument_group('Model\\'s hyper-parameters')\n",
        "    group.add_argument('--embed-dim', type=int, default=200,\n",
        "        help='dimension of word embeddings')\n",
        "    group.add_argument('--src_min-freq', type=int, default=0,\n",
        "        help='''map words of source side appearing less than \n",
        "                threshold times to unknown''')\n",
        "    group.add_argument('--tgt_min-freq', type=int, default=0,\n",
        "        help='''map words of target side appearing less than\n",
        "              threshold times to unknown''')\n",
        "    group.add_argument('--rnn', choices=['lstm'], default='lstm',\n",
        "        help='rnn\\'s architechture')\n",
        "    group.add_argument('--hidden-dim', type=int, default=1024,\n",
        "        help='number of hidden units per layer')\n",
        "    group.add_argument('--n-layers', type=int, default=2,\n",
        "        help='number of LSTM layers')\n",
        "    group.add_argument('--bidirectional', action='store_true',\n",
        "        help='whether use bidirectional LSTM for encoder')\n",
        "    group.add_argument('--attn', choices=['dot', 'general', 'concat'],\n",
        "        default='dot', help='attention type')\n",
        "    group.add_argument('--dropout', type=float, default=0.2,\n",
        "        help='dropout applied to layers (0 means no dropout)')\n",
        "    group.add_argument('--tied', action='store_true',\n",
        "        help='tie the word embedding and softmax weight')\n",
        "    return group"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYRvjd9ZpL2a"
      },
      "source": [
        "# Dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPSUA-8pq_yM"
      },
      "source": [
        "en_tok = spacy.load('en')\n",
        "\n",
        "def tokenize_en(sentence):\n",
        "    return [tok.text for tok in en_tok.tokenizer(sentence)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovMJOLA0q_4F"
      },
      "source": [
        "ru_nlp = Russian()\n",
        "russian_tokenizer = RussianTokenizer(ru_nlp, MERGE_PATTERNS)\n",
        "ru_nlp.add_pipe(russian_tokenizer, name='russian_tokenizer')\n",
        "\n",
        "def tokenize_ru(sentence):\n",
        "    return [tok.text for tok in ru_nlp(sentence)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foLgMGMfq_-o"
      },
      "source": [
        "EN_TEXT = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>', lower=True, batch_first=False)\n",
        "RU_TEXT = Field(tokenize=tokenize_ru, init_token='<sos>', eos_token='<eos>', lower=True, batch_first=False)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyzSOTcLqrBH"
      },
      "source": [
        "dataset = TranslationDataset(\n",
        "    path=f'{folder_path}corpus/news-commentary-v12.ru-en', exts=('.en', '.ru'),\n",
        "    fields=(EN_TEXT, RU_TEXT))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSdFLX1zrMWo"
      },
      "source": [
        "train_data, valid_data, test_data = dataset.split(split_ratio=[0.7, 0.2, 0.1])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPl8k9bYrN8Y",
        "outputId": "f21fc5ec-002c-447e-9ac5-ad421df825f7"
      },
      "source": [
        "print(f'train set size: {len(train_data.examples):,}')\n",
        "print(f'valid set size: {len(valid_data.examples):,}')\n",
        "print(f'test set size: {len(test_data.examples):,}')\n",
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set size: 154,598\n",
            "valid set size: 22,085\n",
            "test set size: 44,171\n",
            "{'src': ['it', 'makes', 'sense', 'for', 'the', 'west', ',', 'particularly', 'the', 'european', 'union', ',', 'to', 'seek', 'cooperation', 'with', 'the', 'sco', ',', 'as', 'this', 'would', 'also', 'help', 'counter', 'russia', '’s', 'attempts', 'to', 'use', 'it', 'as', 'a', 'tool', 'for', 'its', 'anti', '-', 'western', 'policies', '.'], 'trg': ['мировой', 'финансовый', 'кризис', '2008', 'года', 'поначалу', 'лишь', 'ещё', 'больше', 'укрепил', 'репутацию', 'центральных', 'банков', '.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNA8qCnxrRTK",
        "outputId": "4fb4f6b6-f6dd-4f8a-94ce-a7a66fbb7a12"
      },
      "source": [
        "%%time\n",
        "MIN_COUNT = 2\n",
        "EN_TEXT.build_vocab(train_data, min_freq=MIN_COUNT)\n",
        "RU_TEXT.build_vocab(train_data, min_freq=MIN_COUNT)\n",
        "print(f'Length of EN vocabulary: {len(EN_TEXT.vocab):,}')\n",
        "print(f'Length of RU vocabulary: {len(RU_TEXT.vocab):,}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of EN vocabulary: 38,019\n",
            "Length of RU vocabulary: 80,913\n",
            "CPU times: user 3.08 s, sys: 13 ms, total: 3.1 s\n",
            "Wall time: 3.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVobsJJE8XnB"
      },
      "source": [
        "torch.save(dataset.examples, f'{folder_path}/examples.pkl', pickle_module=dill)\n",
        "torch.save(dataset.fields, f'{folder_path}/fields.pkl', pickle_module=dill)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD-R6Y-epPxx"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P5PWEo275QU"
      },
      "source": [
        "class Trainer(object):\n",
        "    def __init__(\n",
        "        self, model, criterion, optimizer, scheduler, clip):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.clip = clip\n",
        "        self.n_updates = 0\n",
        "\n",
        "    def get_lr(self):\n",
        "        return self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "    def step(self, samples, tf_ratio):\n",
        "        self.optimizer.zero_grad()\n",
        "        bsz = samples.src.size(1)\n",
        "        \n",
        "        outs = self.model(samples.src, samples.trg, tf_ratio)\n",
        "        loss = self.criterion(outs.view(-1, outs.size(2)), samples.trg.view(-1))\n",
        "\n",
        "        if self.model.training:\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n",
        "            self.optimizer.step()\n",
        "            self.n_updates += 1\n",
        "        return loss\n",
        "\n",
        "\n",
        "def save_model(save_vars, filename):\n",
        "    model_path = os.path.join(args.savedir, filename)\n",
        "    torch.save(save_vars, model_path)\n",
        "    print(f'model saved: {model_path}')\n",
        "\n",
        "\n",
        "def save_vocab(savedir, fields):\n",
        "    name, field = fields\n",
        "    save_path = os.path.join(savedir, f\"{name}_vocab.txt\")\n",
        "    with open(save_path, 'w') as fout:\n",
        "        for w in field.vocab.itos:\n",
        "            fout.write(w + '\\n')\n",
        "\n",
        "\n",
        "def save_field(savedir, fields):\n",
        "    name, field = fields\n",
        "    save_path = os.path.join(savedir, f\"{name}.field\")\n",
        "    with open(save_path, 'wb') as fout:\n",
        "        dill.dump(field, fout)\n",
        "    \n",
        "\n",
        "def train(args):\n",
        "    device = torch.device('cuda' if args.gpu  else 'cpu')\n",
        "\n",
        "    train_iter, valid_iter = data.BucketIterator.splits(\n",
        "        (train_data, valid_data), \n",
        "        batch_size=args.batch_size,\n",
        "        sort_within_batch=True,\n",
        "        sort_key= lambda x: len(x.src),\n",
        "        repeat=False,\n",
        "        device=device\n",
        "    )\n",
        "    \n",
        "    model = Seq2seqAttn(args, (EN_TEXT, RU_TEXT), device).to(device)\n",
        "    print(model)\n",
        "    print('')\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=RU_TEXT.vocab.stoi['<pad>'])\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
        "    trainer = Trainer(model, criterion, optimizer, scheduler, args.clip)\n",
        "   \n",
        "    epoch = 1\n",
        "    max_epoch = args.max_epoch or math.inf\n",
        "    max_update = args.max_update or math.inf\n",
        "    best_loss = math.inf\n",
        "\n",
        "    while epoch < max_epoch and trainer.n_updates < max_update \\\n",
        "        and args.min_lr < trainer.get_lr():\n",
        "\n",
        "        # training\n",
        "        with tqdm(train_iter, dynamic_ncols=True) as pbar:\n",
        "            train_loss = 0.0\n",
        "            trainer.model.train()\n",
        "            for samples in pbar:\n",
        "                bsz = samples.src.size(1)\n",
        "                loss = trainer.step(samples, args.tf_ratio)\n",
        "                train_loss += loss.item()\n",
        "\n",
        "                pbar.set_description(f\"epoch {str(epoch).zfill(3)}\")\n",
        "                progress_state = OrderedDict(\n",
        "                    loss=loss.item(),\n",
        "                    ppl=math.exp(loss.item()),\n",
        "                    bsz=len(samples),\n",
        "                    lr=trainer.get_lr(), \n",
        "                    clip=args.clip, \n",
        "                    num_updates=trainer.n_updates)\n",
        "                pbar.set_postfix(progress_state)\n",
        "        train_loss /= len(train_iter)\n",
        "\n",
        "        print(f\"| epoch {str(epoch).zfill(3)} | train \", end=\"\") \n",
        "        print(f\"| loss {train_loss:.{4}} \", end=\"\")\n",
        "        print(f\"| ppl {math.exp(train_loss):.{4}} \", end=\"\")\n",
        "        print(f\"| lr {trainer.get_lr():.1e} \", end=\"\")\n",
        "        print(f\"| clip {args.clip} \", end=\"\")\n",
        "        print(f\"| num_updates {trainer.n_updates} |\")\n",
        "        \n",
        "        valid_loss = 0.0\n",
        "        trainer.model.eval()\n",
        "        for samples in valid_iter:\n",
        "            bsz = samples.src.size(1)\n",
        "            loss = trainer.step(samples, tf_ratio=0.0)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "        valid_loss /= len(valid_iter)\n",
        "\n",
        "        print(f\"| epoch {str(epoch).zfill(3)} | valid \", end=\"\") \n",
        "        print(f\"| loss {valid_loss:.{4}} \", end=\"\")\n",
        "        print(f\"| ppl {math.exp(valid_loss):.{4}} \", end=\"\")\n",
        "        print(f\"| lr {trainer.get_lr():.1e} \", end=\"\")\n",
        "        print(f\"| clip {args.clip} \", end=\"\")\n",
        "        print(f\"| num_updates {trainer.n_updates} |\")\n",
        "\n",
        "        # saving model\n",
        "        save_vars = {\"train_args\": args, \n",
        "                     \"state_dict\": model.state_dict()}\n",
        "\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            save_model(save_vars, 'checkpoint_best.pt')\n",
        "        save_model(save_vars, \"checkpoint_last.pt\")\n",
        "\n",
        "        # update\n",
        "        trainer.scheduler.step(valid_loss)\n",
        "        epoch += 1"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "oGIiOHDK75QX",
        "outputId": "c3650747-6dc6-4792-8b63-11b08954711f"
      },
      "source": [
        "dataset_path = f'/content/drive/MyDrive/datasets/'\n",
        "parser = argparse.ArgumentParser('')\n",
        "train_opts(parser)\n",
        "model_opts(parser)\n",
        "args = parser.parse_args([\n",
        "                  \"--train\", f\"{dataset_path}sample_data/sample_train.tsv\",\n",
        "                  \"--val\",   f\"{dataset_path}sample_data/sample_valid.tsv\",\n",
        "                  \"--savedir\", f\"{dataset_path}/model\",\n",
        "                  \"--gpu\",\n",
        "])\n",
        "train(args)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4832 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Seq2seqAttn(\n",
            "  (encoder): EncRNN(\n",
            "    (embed): Embedding(38019, 200)\n",
            "    (rnn): LSTM(200, 1024, num_layers=2)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (decoder): DecRNN(\n",
            "    (embed): Embedding(80913, 200)\n",
            "    (rnn): LSTM(200, 1024, num_layers=2)\n",
            "    (w): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (attn): Attention()\n",
            "    (out_projection): Linear(in_features=1024, out_features=80913, bias=True)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 001: 100%|██████████| 4832/4832 [1:22:35<00:00,  1.03s/it, loss=7.3, ppl=1.48e+3, bsz=32, lr=0.25, clip=0.1, num_updates=4832]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch 001 | train | loss 7.698 | ppl 2.205e+03 | lr 2.5e-01 | clip 0.1 | num_updates 4832 |\n",
            "| epoch 001 | valid | loss 7.306 | ppl 1.49e+03 | lr 2.5e-01 | clip 0.1 | num_updates 4832 |\n",
            "model saved: /content/drive/MyDrive/datasets//model/checkpoint_best.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/4832 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "model saved: /content/drive/MyDrive/datasets//model/checkpoint_last.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 002:   1%|▏         | 71/4832 [01:12<1:21:16,  1.02s/it, loss=7.46, ppl=1.73e+3, bsz=32, lr=0.25, clip=0.1, num_updates=4903]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-61a886652149>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0;31m#   \"--max-epoch\", \"10\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m ])\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-3f85db9e9628>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# print('Outer: ', samples.src.shape, samples.trg.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mbsz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-3f85db9e9628>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, samples, tf_ratio)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLqINnbP75Qa"
      },
      "source": [
        "def load_field(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        return dill.load(f)\n",
        "\n",
        "\n",
        "def id2w(pred, field):\n",
        "    sentence = [field.vocab.itos[i] for i in pred]\n",
        "    if '<eos>' in sentence:\n",
        "        return ' '.join(sentence[:sentence.index('<eos>')])\n",
        "    return ' '.join(sentence)\n",
        " \n",
        "\n",
        "def translate(args):\n",
        "    device = torch.device('cuda' if args.gpu  else 'cpu')\n",
        "\n",
        "    load_vars = torch.load(args.model)\n",
        "    train_args = load_vars['train_args']\n",
        "    model_params = load_vars['state_dict']\n",
        "\n",
        "    dirname = os.path.dirname(args.model)\n",
        "\n",
        "    test_iter = data.Iterator(test_data, batch_size=args.batch_size,\n",
        "                    train=False, shuffle=False, sort=False, device=device) \n",
        " \n",
        "    model = Seq2seqAttn(train_args, (EN_TEXT, RU_TEXT), device).to(device)\n",
        "    model.load_state_dict(model_params)\n",
        "\n",
        "    model.eval()\n",
        "    ins_a, outs_a = [], []\n",
        "    for samples in test_iter:\n",
        "        preds = model(samples.src, tgts=None, maxlen=args.maxlen, tf_ratio=0.0)\n",
        "        preds = preds.max(2)[1].transpose(1, 0)\n",
        "        outs = [id2w(pred, RU_TEXT) for pred in preds]\n",
        "        ins = [id2w(item, EN_TEXT) for item in samples.src]\n",
        "        ins_a.extend(ins)\n",
        "        outs_a.extend(outs)\n",
        "        # print('\\n'.join(outs))\n",
        "    return zip(ins_a, outs_a)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujScKDxVANiu"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "translate_opts(parser)\n",
        "args = parser.parse_args([\n",
        "                          \"--model\", f\"{dataset_path}model/checkpoint_best.pt\",\n",
        "                          \"--input\", f'{dataset_path}sample_data/sample_test.txt',\n",
        "                          \"--gpu\"\n",
        "])\n",
        "res = translate(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3c4sqbkA1Y8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}